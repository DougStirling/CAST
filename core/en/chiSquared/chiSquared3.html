<!DOCTYPE HTML>
<html>
<head>
	<title>General chi-squared distribution</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="continuous distribution, chi-squared distribution, gamma distribution, degrees of freedom, probability density function">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Sum of squared standard normals</p>

<p>We now generalise from the distribution of a <strong>single</strong> squared \(\NormalDistn(0, 1)\) variable to the sum of squares of \(k\) independent ones.</p>

<div class="definition">
<p class='definitionTitle'>Definition</p>
<p>If \(\{Z_1, Z_2, \dots, Z_k\}\) are independent  variables with standard normal distributions, then \(Y = \sum_{i=1}^k {Z_i^2}\) is said to have a <strong>Chi-squared</strong> distribution with \(k\) degrees of freedom,</p>
\[
Y \;\;\sim\;\; \ChiSqrDistn(k\;\text{df})
\]</div>

<p>Since z-scores have a standard normal distribution, this also means that  if \(\{X_1, X_2, \dots, X_k\}\) are a random sample from a \(\NormalDistn(\mu, \sigma^2)\), distribution, then</p>
\[
\sum_{i=1}^k \frac{(X_i - \mu)^2}{\sigma^2}  \;\;\sim\;\; \ChiSqrDistn(k\;\text{df})
\]

<p>The properties of \(Y\) can be found by noting that</p>
<ul>
	<li>\(\{Z_1^2, Z_2^2, \dots, Z_k^2\}\) are independent \(\ChiSqrDistn(1)\) variables,</li>
	<li>The \(\ChiSqrDistn(1)\) distribution is identical to a \(\GammaDistn(\frac 1 2, \frac 1 2)\) distribution, and</li>
	<li>The sum of Gamma random variables <a href="javascript:showNamedPage('gamma3')">also has a Gamma distribution</a>, provided their second parameters are the same.</li>
</ul>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Relationship to the Gamma distribution</p>
		<p>The \(\ChiSqrDistn(k\;\text{df})\) distribution is identical to a \(\GammaDistn(\frac k 2, \frac 1 2)\) distribution</p>
\[
		\ChiSqrDistn(k\;\text{df}) \;\;\equiv\;\;  \GammaDistn(\frac k 2, \frac 1 2)
		\]</div>
	<div class="proof">
		<p>We stated earlier that if \(Y_1 \sim \GammaDistn(\alpha_1,\; \beta)\) and \(Y_2 \sim \GammaDistn(\alpha_2,\; \beta)\) are independent, then</p>
		\[
		Y_1 + Y_2 \;\;\sim\;\;  \GammaDistn(\alpha_1 + \alpha_2,\; \beta)
		\]
		<p>This can be easily generalised to the sum of \(k\) independent \(\GammaDistn(\alpha_i, \beta)\) variables:</p>
		\[
		\sum_{i=1}^{k} {Y_i} \;\;\sim\;\;  \GammaDistn(\sum_{i=1}^{k} {\alpha_i},\; \beta) \]
		<p>Since a Chi-squared random variable \(Y\) is the sum of \(k\) independent \(\GammaDistn(\frac 1 2, \frac 1 2)\) variables, it therefore also has a Gamma distribution,</p>
		\[
		\ChiSqrDistn(k\;\text{df}) \;\;\equiv\;\;  \GammaDistn(\frac k 2, \frac 1 2)
	\]	</div>
</div>
<p>The Chi-squared distribution's pdf can be found directly from that of the Gamma distribution.</p>
<div class="theoremProof">
	<div class="theorem">
<p class="theoremTitle">Probability density function</p>
<p>A random variable \(Y \sim \ChiSqrDistn(k\;\text{df})\) has probability density function</p>
\[
f(y) \;=\; \frac 1 {\Gamma({\large\frac k 2}) 2^{\large\frac k 2}} y^{\large{\frac k 2} - 1}e^{\large{-\frac y 2}} \qquad\text{if } y \gt 0
\]</div>

<div class="proof">
<p>Replacing \(\alpha = \frac k 2\) and \(\beta = \frac 1 2\) in the \(\GammaDistn(\frac k 2, \frac 1 2)\) distribution's pdf gives the pdf of the Chi-squared distribution.</p>
</div>

</div>
<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
