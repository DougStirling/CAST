<!DOCTYPE HTML>
<html>
<head>
	<title>Likelihood ratio test</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="hypothesis test, test, big model, small model, likelihood ratio test, poisson distribution">
	<meta name="dataset" content="Defective items">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Test statistic to compare \(\mathcal{M}_S\) with \(\mathcal{M}_B\)</p>

<p>We can now formally test the hypotheses</p>
<ul>
	<li>Null hypothesis, <strong>H<sub>0</sub></strong>: \(\mathcal{M}_S\) is the correct model for the data.</li>
	<li>Alternative hypothesis, <strong>H<sub>A</sub></strong>:  \(\mathcal{M}_S\) is not correct and \(\mathcal{M}_B\) must be used to model the data.</li>
</ul>
<p>We base this on a test statistic that is <strong>twice</strong> the logarithm of the likelihood ratio for the large and small models,</p>
\[
X^2 \;\;=\;\; 2\log(R) \;\;=\;\; 2\left(\ell(\mathcal{M}_B) - \ell(\mathcal{M}_S)\right)
\]
<p>We explained on the previous page that this is likely to be largest if \(\mathcal{M}_S\) is not correct. The following result (stated without proof) shows that it has (approximately) a standard distribution when the null hypothesis holds.</p>

<div class="theoremProof">
	<div class="theorem">
<p class="theoremTitle">Distribution of test statistic</p>
<p>If the data do come from \(\mathcal{M}_)\), and \(\mathcal{M}_B\) has \(k\) more parameters than \(\mathcal{M}_S\),</p>
\[
X^2 \;\;=\;\; 2\left( \ell(\mathcal{M}_B) - \ell(\mathcal{M}_S)\right) \;\;\underset{\text{approx}}{\sim} \;\; \ChiSqrDistn(k \text{ df})
\]</div>
</div>

<p class="heading">Likelihood ratio test</p>
<p>The test is therefore done by evaluating the test statistic, \(X^2\), from the data. The p-value is the probability of getting a value as large as this from the \(\ChiSqrDistn(k \text{ df})\) distribution.</p>
<p>The full procedure is described below:</p>
<ol>
	<li>Find the maximum likelihood estimates of all unknown parameters in \(\mathcal{M}_B\).</li>
	<li>Find the maximum likelihood estimates of all unknown parameters in \(\mathcal{M}_S\).</li>
	<li>Evaluate the test statistic, \(\chi^2 = 2\left( \ell(\mathcal{M}_B) - \ell(\mathcal{M}_S)\right)\).</li>
	<li>The degrees of freedom for the test are the difference between the numbers of unknown parameters in the two models.</li>
	<li>The p-value for the test is the upper tail probability of the \(\ChiSqrDistn(k \text{ df})\) distribution above the test statistic.</li>
	<li>Interpret the p-value as for other kinds of hypothesis test — small values give evidence that the null hypothesis, model \(\mathcal{M}_S\), does not hold.</li>
</ol>
<div class="questionSoln">
	<div class="question">
<p class="questionTitle">Example</p>
<p>The following table describes the number of defective items from a production line in each of 20 days.</p>
<div class="centred">
	<table border="0" cellpadding="5" cellspacing="0" class="centred" style="border:1px solid #999999; background-color:#FFFFFF;">
		<tr>
			<td style="text-align:right; padding-right:10px; width:25px;">1<br>
				2</td>
			<td style="text-align:right; padding-right:10px; width:25px;">3<br>
				4</td>
			<td style="text-align:right; padding-right:10px; width:25px;">2<br>
				3</td>
			<td style="text-align:right; padding-right:10px; width:25px;">2<br>
				5</td>
			<td style="text-align:right; padding-right:10px; width:25px;">5<br>
				2</td>
			<td style="text-align:right; padding-right:10px; width:25px;">4<br>
				3</td>
			<td style="text-align:right; padding-right:10px; width:25px;">5<br>
				1</td>
			<td style="text-align:right; padding-right:10px; width:25px;">2<br>
				4</td>
			<td style="text-align:right; padding-right:10px; width:25px;">0<br>
				2</td>
			<td style="text-align:right; padding-right:10px; width:25px;">2<br>
				6</td>
		</tr>
	</table>
</div>
<p>Assuming that the data are a random sample from a \(\PoissonDistn(\lambda)\) distribution, use a likelihood ratio test for whether the rate of defects was \(\lambda = 2\) per week.</p>
	</div>

<div class="solution">
<p>The hypotheses of interest are</p>
<ul>
	<li>Null hypothesis, <strong>H<sub>0</sub></strong>: \(\lambda = 2\)   (corresponding to \(\mathcal{M}_S\))</li>
	<li>Alternative hypothesis, <strong>H<sub>A</sub></strong>:  \(\lambda \ne 2\)  (corresponding to \(\mathcal{M}_B\))</li>
</ul>
<p>The log-likelihood for the Poisson model is</p>
\[
\ell(\lambda) \;\;=\;\; \left(\sum_{i=1}^{20} X_i\right) \log \lambda - n\lambda + K
\]
<p>where \(K\) is a constant that does not depend on \(\lambda\).</p>

<p style="font-weight:bold; font-size:larger">Big model, \(\mathcal{M}_B\)</p>
<p>For the big model, the maximum likelihood estimate of the unknown parameter is</p>
\[
\hat{\lambda} \;\;=\;\; \frac{\sum x_i}{n} \;\;=\;\; 2.9
\]
<p>The maximum possible value for the log-likelihood is</p>
\[
\ell(\mathcal{M}_B) \;\;=\;\; 58 \log(2.9) - 20 \times 2.9 \;\;=\;\; 3.7532 + K
\]
<p style="font-weight:bold; font-size:larger">Small model, \(\mathcal{M}_S\)</p>
<p>There are no unknown parameters for the small model, so the maximum possible value for the log-likelihood is</p>
\[
\ell(\mathcal{M}_S) \;\;=\;\; 58 \log(2) - 20 \times 2 \;\;=\;\; 0.2025 + K
\]
<p style="font-weight:bold; font-size:larger">Likelihood ratio test</p>
<p>The test statistic is</p>
\[
X^2 \;\;=\;\; 2\left(\ell(\mathcal{M}_B) - \ell(\mathcal{M}_S)\right) \;\;=\;\; 7.101
\]
<p>Since there is one more unknown parameter in the big model, this should be compared to the \(\ChiSqrDistn(1 \text{ df})\) distribution. Its upper tail probability above 7.101 is 0.008 and this is the p-value for the test.</p>
<p>Since the p-value is so small, we should conclude that there is strong evidence that \(\mathcal{M}_B\) fits the data better than \(\mathcal{M}_S\) — i.e. that \(\lambda \ne 2\).</p>
<hr width="75%">

<p class="heading">Illustration of likelihood ratio test</p>
<p>The diagram below illustrates the test.</p>
<div class="centred">
	<applet codebase="../../java" code="dataView.CastApplet.class" archive="coreCAST.jar" width="500" height="550">
		<script type="text/javascript">writeAppletParams();</script>
		<param name="appletName" value="estimationProg.PoissonLrtApplet">
		<param name="backgroundColor" value="FFFFFF">
		<param name="lambda" value="1.80 4.00 2.00">
		<param name="loglikelihoodAxis" value="-25 -17.5 -24 2">
		<param name="varName" value="Defective items">
		<param name="dataAxis" value="-0.5 6.5 0 1">
		<param name="probAxis" value="0 0.32 0 0.1">
		<param name="lambdaAxis" value="1.8 4 2 0.5">
		<param name="decimals" value="3 4">
		<param name="values" value="1 2 4 3 5 2 3 1 4 2 6 3 2 2 5 4 5 2 0 2">
		<param name="customText" value="Log-likelihood=Log-likelihood#Poisson probability function=Poisson probability function#Number of events=Number of events#Null hypothesis parameter=Null hypothesis parameter#Rate of events=Rate of events">
	</applet>
</div>
<p>The bottom of the diagram shows a stacked dot plot of the data and initially superimposes the probabilities for a \(\PoissonDistn(\lambda=2)\) model for the data.</p>
<p>The top of the diagram shows the log-likelihood for different values of \(\lambda\). When \(\lambda = 2\), the log-likelihood is 3.551 lower than its maximum possible value (which occurs at \(\hat{\lambda} = 2.9\)). The p-value is the probability of such a large difference and is found from the \(\ChiSqrDistn(1 \text{ df})\) distribution to be 0.0077. This provides very strong evidence that the underlying Poisson parameter is <strong>not</strong> 2.0.</p>
<p>Finally, use the slider to see how the results of the test would have changed if the null hypothesis value of the parameter, \(\lambda_0\), had been other values.</p>
</div>
</div>

<script type='text/javascript'>writePageEnd();</script>
</body>
</html>
