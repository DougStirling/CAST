<!DOCTYPE HTML>
<html>
<head>
	<title>Linear combinations, sums and means</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="normal distribution, mean of random sample, sum of random sample">
</head>


<body>
<script type="text/javascript">writePageStart();</script>
<p class="heading">Two independent normal variables </p>
<p><span class="theorem">For any two independent  random variables, \(X\) and \(Y\), with means \(\mu_X\) and \(\mu_Y\) and  variances  \(\sigma_X^2\) and \(\sigma_Y^2\),</span></p>
\[ \begin {align}
		E[aX + bY] &amp; = a\mu_X + b\mu_Y \\[0.5em]
		\Var(aX + bY) &amp; = a^2\sigma_X^2 + b^2\sigma_Y^2
		\end {align} \]
		<p>When \(X\) and \(Y\)have normal distributions, we can be more precise about the distribution's shape.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Linear function of independent normal variables</p>
		<p>If \(X\) and \(Y\) are independent random variables,</p>
\[ \begin {align}
X \;&amp;\sim\; \NormalDistn(\mu_X,\; \sigma_X^2) \\
Y \;&amp;\sim\; \NormalDistn(\mu_Y,\; \sigma_Y^2)
\end {align} \]
		<p>then</p>
\[
aX + bY \;\sim\; \NormalDistn(a\mu_X + b\mu_Y,\; a^2\sigma_X^2 + b^2\sigma_Y^2)
\]		</div>
</div>
<p class="heading">Random sample </p>
<p>This can be extended to the sum of values in a normal random sample.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Sum of a random sample</p>
		<p>If \(\{X_1, X_2, ..., X_n\}\) is a random sample of <em>n</em> values from a  \(\NormalDistn(\mu,\; \sigma^2)\) distribution then,</p>
\[
\sum_{i=1}^n {X_i} \;\sim\; \NormalDistn(n\mu,\; n\sigma^2)
\]	
<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>
<p>A similar result holds for the <strong>mean</strong> of a random sample from a normal distribution.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Mean of a random sample</p>
		<p>If \(\{X_1, X_2, ..., X_n\}\) is a random sample of <em>n</em> values from a  \(\NormalDistn(\mu,\; \sigma^2)\) distribution then,</p>
		\[
		\overline{X} \;\sim\; \NormalDistn\left(\mu,\; \frac {\sigma^2}{n}\right)
		\] </div>
</div>
<script type='text/javascript'>writePageEnd();</script>
</body>
</html>
