<!DOCTYPE HTML>
<html>
<head>
	<title>Random samples</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="joint probability function, discrete distribution, random sample, independence">
</head>


<body>
<script type="text/javascript">writePageStart();</script>
<p>The concept of a joint probability function for two discrete random variables generalises to \(n\) random variables.</p>

<div class="definition">
<p class='definitionTitle'>Definition</p>
<p>The <strong>joint probability function</strong> for \(n\) random variables \(\{X_1,X_2,\dots, X_n\}\) is</p>
\[
p(x_1, \dots, x_n) \;=\; P(X_1=x_1 \textbf{ and } \cdots \textbf{ and } X_n=x_n)
\]</div>

<p>Maximum likelihood can again be used to estimate any unknown parameters. The likelihood function is  the probability of observing the recorded data, treated as a function of the unknown parameter(s). For a single unknown parameter, \(\theta\),</p>
\[
L(\theta \; | \; x_1, x_2, \dots, x_n) \;=\; p(x_1, x_2, \dots, x_n \;| \; \theta)
\]
<p>The maximum likelihood estimate of the parameter is the value of the parameter that maximise this.</p>
<p class="heading">Independence and random samples</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Independence of n random variables</p>
		<p><span class="definition">Discrete random variables \(\{X_1,X_2,\dots, X_n\}\) are independent if</span> and only if</p>
		\[
		p(x_1, \dots, x_n) \;\;=\;\; p_{X_1}(x_1) \times \;\cdots \; \times p_{X_n}(x_n) \qquad \text{ for all } x_1,\dots,x_n
		\] </div>
</div>
<p>In particular, when all \(n\) variables are independent with the <strong>same</strong> distribution, they are  a <strong>random sample</strong> from this distribution. Their joint probability function was what we maximised earlier when estimating parameters from a random sample by maximum likelihood.</p>
<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
