<!DOCTYPE HTML>
<html>
<head>
	<title>Independence and random samples</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="continuous distribution, independence, random sample">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Independence</p>

<p>The definition that was given earlier for <a href="javascript:showNamedPage('randomSample1')">independence of two random variables</a> holds for both discrete and continuous random variables; it is repeated here.</p>
<div class="definition">
	<p class='definitionTitle'>Definition</p>
<p>Two  random variables, \(X\) and \(Y\), are independent if all events about the value of \(X\) are independent of all events about the value of \(Y\).</p>
</div>
<p>Independence of continuous random variables is usually deduced from the way that the variables are measured rather than from  mathematical calculations. For example,</p>
<ul>
	<li>If blood pressures are recorded from two patients admitted to hospital after heart attacks, we can argue that these variables should be unrelated and hence independent.</li>
</ul>
<p class="heading">Characterisation of independence</p>
<p>For values of independent continuous random variables, \(X\) and \(Y\), that are very close to \(x\) and \(y\) — no more than \(\delta x\) and \(\delta y\) above them,</p>

\[ \begin{align}
P(x \lt X \lt x+\delta x &amp;\textbf{ and } y \lt Y \lt y+\delta y) \\
&amp;=\;\; P(x \lt X \lt x+\delta x) \times P(y \lt Y \lt y+\delta y)
\end{align} \]

<p>Using an <a href="javascript:showNamedPage('continuousMeanVar1')">earlier approximation</a>, </p>

\[
P(x \lt X \lt x+\delta x \textbf{ and } y \lt Y \lt y+\delta y) \;\;\approx\;\; f_X(x)\;f_Y(y) \times  \delta x \; \delta y
\]

<p>where \(f_X(x)\) and  \(f_Y(y)\) are the probability density functions of \(X\) and \(Y\). Probabilities around \(x\) and \(y\) are therefore characterised by the product of the pdfs of the variables,</p>
\[
P(X \approx x \textbf{ and } Y \approx y) \;\; \propto \;\; f_X(x)\;f_Y(y)
\]
<p>This is closely related to the corresponding result for two independent discrete random variables,</p>
\[
P(X=x \textbf{ and } Y=y) \;\;=\;\; p_X(x) \times p_Y(y)
\]

<p class="heading">Random samples</p>
<p>The <a href="javascript:showNamedPage('randomSample2')">definition of a random sample</a> that was given earlier also holds for continuous distributions — a collection of \(n\) independent identically distributed  random variables from the same distribution is called a <strong>random sample</strong>.</p>
<p>Extending our earlier characterisation of independence of <strong>two</strong> continuous random variables, </p>
\[
		P(X_1 \approx x_1, X_2 \approx x_2, ..., X_n \approx x_n) \;\; \propto \;\; \prod_{i=1}^n f(x_i)
		\]
<p>This is again closely related to the corresponding formula for a random sample from a discrete distribution</p>
\[
		P(X_1 = x_1, X_2 = x_2, ..., X_n = x_n) \;\; = \;\; \prod_{i=1}^n p(x_i)
		\]
<script type='text/javascript'>writePageEnd();</script>
</body>
</html>
