<!DOCTYPE HTML>
<html>
<head>
	<title>Log-series distribution</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="log-series distribution, newton-raphson algorithm, maximum likelihood">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p>To illustrate the use of the Newton-Raphson algorithm to find maximum likelihood estimates, we will examine another standard distribution that is occasionally encountered, the <strong>log-series distribution</strong>.</p>

<div class="definition">
<p class='definitionTitle'>Definition</p>
<p>A discrete random variable \(X\) is said to have a <strong>log-series distribution</strong> if its probability function is</p>
\[
p(x) \;=\; \frac {-1} {\log(1-\theta)} \times \frac {\theta^x} x \quad\quad \text{for } x=1, 2, \dots
\]
<p>where \(0 \lt \theta \lt 1\).</p>
</div>

<p>This distribution is similar in shape to the geometric distribution, but the log-series distribution has greater spread with a higher probability at one and longer tail.  The distribution's mean and variance can be shown to be</p>
\[ \begin{align}
E[X] \;\;&amp;=\;\; \frac {-1} {\log(1-\theta)} \times \frac {\theta} {1 - \theta} \quad\quad \\[0.2em] \Var(X) \;\;&amp;=\;\; -\theta \frac {\theta + \log(1 - \theta)} {(1 - \theta)^2 \log^2(1 - \theta)}
\end{align} \]

<p class="heading">Maximum likelihood</p>
<p>If a random sample \({x_1, x_2, \dots, x_n}\) is collected from this distribution, what is the maximum likelihood estimate of \(\theta\)? The logarithm of the probability function is</p>
\[
\log \left(p(x)\right) \;=\; x \log(\theta) - \log \left( -\log(1 - \theta) \right) - \log(x)
\]
<p>so the likelihood function is</p>
\[
\ell(\theta) \;=\; \sum_{i=1}^n \log \left(p(x_i)\right) \;=\; {\sum x_i} \log(\theta) - n \times \log \left( -\log(1 - \theta) \right) + K
\]
<p>where \(K\) is a constant whose value does not depend on \(\theta\). The maximum likelihood estimate is the solution of</p>
\[
\ell'(\theta) \;=\; \frac {\sum x_i} {\theta} + \frac n {(1 - \theta)\log(1 - \theta)} \;=\; 0
\]
<p>Unfortunately this equation cannot be rearranged to obtain an explicit formula for \(\theta\), so a numerical method must be used to find the maximum likelihood estimate. The Newton Raphson algorithm also requires the second derivative of the log-likelihood,</p>
\[
\ell''(\theta) \;=\; -\frac {\sum x_i} {\theta^2} + \frac {n \left(1 + \log(1 - \theta) \right)} {(1 - \theta)^2\log^2(1 - \theta)}
\]
<p>The algorithm uses these derivatives iteratively to refine an initial estimate, \(\theta_0\),</p>
\[
\theta_{i+1} \;\; = \;\; \theta_i - \frac {\ell'(\theta_i)} { \ell''(\theta_i)}\]
<p>The method will be illustrated with a numerical example.</p>


<div class="example" title="Example: Data from a log-series distribution">
	<p class="exampleHeading">Example</p>

<p>Consider the following data set that is assumed to arise from a log-series distribution.</p>

<div class="centred">
<table border="0" cellpadding="5" cellspacing="0" class="centred" style="border:1px solid #999999; background-color:#FFFFFF;">
	<tr>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">3</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">5</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">4</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">8</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">10</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">2</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="width:15px; text-align:right; padding:4px 8px 4px 5px">2</td>
	</tr>
	<tr>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">8</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">6</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">13</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">6</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">2</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">3</td>
	</tr>
	<tr>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">2</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">6</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
		<td style="text-align:right; padding:4px 8px 4px 5px">1</td>
	</tr>
</table>
</div>

<p>The derivatives of the log-likelihood involve the values \(n = 30\) and \(\sum x = 95\). Iterations of the algorithm from an initial guess at the value of \(\theta = 0.7\) are shown below.</p>

<div class="centred">
<applet codebase="../../java" code="dataView.CastApplet.class" archive="coreCAST.jar" width="450" height="400">
<script type="text/javascript">writeAppletParams();</script>
<param name="appletName" value="estimationProg.NewtonRaphsonApplet">
<param name="nValues" value="30">
<param name="sumX" value="95">
<param name="iterations" value="10">
<param name="initialGuess" value="0.7">
<param name="customText" value="Initial guess=Initial guess#Show iterations=Show iterations#Iteration=Iteration">
</applet>
</div>

<p>Try different values for the initial guess at \(\theta\) (by typing other values into the text edit box and clicking <strong>Show iterations</strong>) to investigate the convergence of the algorithm. For most initial guesses, the algorithm converges fairly quickly to the maximum likelihood estimate, \(\hat{\theta} = 0.8628\).</p>
<hr width="75%">
<p>The following diagram  illustrates the Newton Raphson iterations graphically. The algorithm is equivalent to approximating the shape of the log-likelihood with a quadratic curve that has the same value, slope and curvature (1st and 2nd derivatives) as the log-likelihood at the current value of \(\theta\). The next iteration is the value of \(\theta\) that maximises this quadratic.</p>

<div class="centred">
	<applet codebase="../../java" code="dataView.CastApplet.class" archive="coreCAST.jar" width="500" height="600">
		<script type="text/javascript">writeAppletParams();</script>
		<param name="appletName" value="estimationProg.LogSeriesLikelihoodApplet">
		<param name="backgroundColor" value="FFFBF3">
		<param name="logSeries" value="0.600 1.000 0.700">
		<param name="loglikelihoodAxis" value="-65.5 -55.5 -64 2">
		<param name="varName" value="log-series data">
		<param name="dataAxis" value="0.5 13.5 1 1">
		<param name="paramAxis" value="0.6 1.0001 0.6 0.05">
		<param name="values" value="3 5 1 4 8 10 2 1 1 2 1 8 1 6 13 1 6 2 1 3 1 1 1 2 1 6 1 1 1 1">
		<param name="customText" value="Log-likelihood=Log-likelihood#Unknown parameter=Unknown parameter#Probability of success=Probability of success#Max likelihood=Max likelihood#Log-series probability function=Log-series probability function#Counts=Counts">
	</applet>
</div>

<p>The bottom half of the diagram shows the shape of the log-series distribution and the data set. The slider changes the value of the unknown parameter, \(\theta\).</p>
<p>The top half of the diagram displays the log-likelihood function. The green curve shows the quadratic curve with the same slope and curvature as those of the log-likelihood at the currently selected value of \(\theta\). The Newton Raphson algorithm effectively steps to the maximum of this approximating quadratic for its next iteration.</p>
<p>The next diagram is identical but zooms in to parameter values much closer to the maximum likelihood estimate.</p>
<div class="centred">
	<applet codebase="../../java" code="dataView.CastApplet.class" archive="coreCAST.jar" width="500" height="600">
		<script type="text/javascript">writeAppletParams();</script>
		<param name="appletName" value="estimationProg.LogSeriesLikelihoodApplet">
		<param name="backgroundColor" value="FFFBF3">
		<param name="logSeries" value="0.850 0.880 0.880">
		<param name="loglikelihoodAxis" value="-57.07 -56.97 -57.06 0.02">
		<param name="varName" value="log-series data">
		<param name="dataAxis" value="0.5 13.5 1 1">
		<param name="paramAxis" value="0.85 0.88 0.85 0.005">
		<param name="values" value="3 5 1 4 8 10 2 1 1 2 1 8 1 6 13 1 6 2 1 3 1 1 1 2 1 6 1 1 1 1">
		<param name="customText" value="Log-likelihood=Log-likelihood#Unknown parameter=Unknown parameter#Probability of success=Probability of success#Max likelihood=Max likelihood#Log-series probability function=Log-series probability function#Counts=Counts">
	</applet>
</div>
<p>Observe that the log-likelihood is more closely approximated by a quadratic, so the quadratic's maximum is close to the maximum likelihood estimate â€” once the algorithm gets close to the maximum likelihood estimate, it converges quickly.</p>
</div>
<script type='text/javascript'>writePageEnd();</script>
</body>
</html>
