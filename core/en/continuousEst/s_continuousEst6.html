<!DOCTYPE HTML>
<html>
<head>
	<title>Example: normal distribution mean</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="estimation, maximum likelihood, normal distribution, standard error, confidence interval">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p>This page applies maximum likelihood to a normal distribution.</p>

<div class="example">
	
	<p class="exampleHeading">Normal distribution with known σ</p>

<p>Consider a random sample,</p>
<p class="eqn">4.2   5.2   5.6   6.1   7.3   8.5</p>
<p>from a normal distribution with known \(\sigma\),</p>
\[
X \;\; \sim \; \; \NormalDistn(\mu, \;\sigma = 1.3)
\]
<p>Its log-likelihood is</p>
\[
\ell(\mu) \;\;=\;\; \sum_{i=1}^n {\log(f(x_i \;|\; \mu))} \;\;=\;\; -\frac 1 {2 \times 1.3^2} \times \sum_{i=1}^n {(x_i-\mu)^2} + K
\]
<p>where \(K\) is a constant that does not depend on \(\mu\). To find the maximum likelihood estimate of \(\mu\), we solve</p>
\[
\ell'(\mu) \;\;=\;\; \frac 1 {1.3^2} \times \sum_{i=1}^n {(x_i-\mu)} \;\;=\;\; 0
\]
<p>Giving \(\displaystyle \hat{\mu} \;\;=\;\; \frac {\sum {x_i}} n \;\;=\;\; \overline{x}\).</p>
<hr width="75%">
<p>We now illustrate the method graphically. The likelihood function, \(L(\mu)\), is the product of the normal distribution's pdf's at the data values — the product of the bar heights at the bottom of the next diagram.</p>
<p class="eqn"><img src="images/s_badNormal.png" width="532" height="447"/></p>
<p>The likelihood for the normal distribution with \(\mu = 4\) is low because the pdf is so small at the highest data values, f(7.3) and f(8.5). On the other hand, when \(\mu = \overline{x} = 6.15\), there are no small pdfs the likelihood function is maximised.</p>
<p class="eqn"><img src="images/s_goodNormal.png" width="532" height="447"/></p>
<p class="heading">Standard error</p>
<p>We can directly find the standard error of the MLE using the properties of sample means,</p>
\[
\se(\hat{\mu}) \;\;=\;\; \sqrt{\Var(\overline{X})} \;\;=\;\; \frac {\sigma} {\sqrt{n}} \;\;=\;\; \frac {1.3} {\sqrt n }\]
<p>Finding the standard error from the second derivative of \(\ell(\mu)\) gives</p>

\[
\se(\hat {\mu}) \;\;\approx\;\; \sqrt {- \frac 1 {\ell''(\hat {\mu})}} \;\;=\;\;
\sqrt {\frac {1.3^2} n}\]
<p>For this example, the asymptotic formula gives the <strong>exact</strong> standard error of the maximum likelihood estimator.</p>
<p class="heading">Confidence interval</p>
<p>For this example, the maximum likelihood estimator is the sample mean. Since sample means from normal distributions have <strong> exactly</strong> normal distributions,</p>
\[
\overline{X} \;\; \sim \; \; \NormalDistn(\mu,\;\; \sigma_{\overline{X}} = \frac {1.3} {\sqrt n})
\]
<p>the interval estimate</p>
\[
\overline{x} \;\; \pm \; \; 1.96 \times \frac {1.3} {\sqrt n}
\]
<p>has <strong>exactly</strong> 95% confidence level. (The confidence level is only approximate for MLEs based on other distributions.)</p>
</div>
<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
