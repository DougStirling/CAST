<!DOCTYPE HTML>
<html>
<head>
	<title>Expected values</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="discrete distribution, expected value">
</head>


<body>
<script type="text/javascript">writePageStart();</script>
<p class="heading">Expected values</p>
<p>The definition of a random variable's mean can be generalised to give the expected value of an arbitrary function of the random variable.</p>
<div class="definition">
	<p class='definitionTitle'>Definition</p>
	<p>The<strong> expected value </strong>of a function \(g(X)\) of a discrete random variable, \(X\), is defined to be</p>
	\[
	E\big[g(X)\big] = \sum_{\text{all } x} {g(x) \times p(x)}
\]
</div>

<p>As with the definition of the variable's mean, this definition 'weights' the possible values, g(x), with their probabilities of arising.</p>

<p>The following two results make it easier to evaluate expected values.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Linear function of a random variable</p>
		<p>If \(X\) is a discrete random variable and \(a\) and \(b\) are constants,</p>
		\[
		E\big[a + b \times X\big] \;\;=\;\; a + b \times E[X]
		\] </div>
	<div class="proof"> \[ \begin{align}
		E\big[a + b \times X\big] &amp; = \sum_{\text{all } x} {(a + b \times x) \times p(x)} \\[0.3em]
		&amp; = \sum_{\text{all } x} {\left( a \times p(x) \; + \; b \times x \times p(x) \right)} \\[0.3em]
		&amp; = a \times \sum_{\text{all } x} {p(x)} \; + \; b \times \sum_{\text{all } x} { x \times p(x)} \\
		&amp; = a \; + \; b \times E[X]
		\end{align} \]
		<p>since \(\sum {p(x)} = 1. \)</p>
	</div>
</div>
<p>We can also easily find the expected value of the sum of two functions of \(X\).</p>

<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Sum of two functions of X</p>
		<p>If \(X\) is a discrete random variable and \(g(X)\) and \(h(X)\) are functions of it,</p>
	\[
	E\big[g(X) + h(X)\big] \;\;=\;\; E\big[g(X)\big] + E\big[h(X)\big]
\]
</div>

	<div class="proof">
 \[ \begin{align}
	E\big[g(X) + h(X)\big] &amp; = \sum_{\text{all } x} {\big(g(X) + h(X)\big) \times p(x)} \\
	&amp; = \sum_{\text{all } x} {g(X) \times p(x)} \; + \; \sum_{\text{all } x} {h(X) \times p(x)} \\
	&amp; = E\big[g(X)\big] + E\big[h(X)\big]
\end{align} \] </div>

</div>


<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
