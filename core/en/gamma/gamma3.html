<!DOCTYPE HTML>
<html>
<head>
	<title>Some Gamma distribution properties</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="gamma distribution, mean, variance, erlang distribution, normal approximation">
</head>


<body>
<script type="text/javascript">writePageStart();</script>
<p>We now give formulae for the mean and variance of the Gamma distribution.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Mean and variance</p>
		<p>If a random variable \(X\) has a Gamma distribution with probability density function</p>
\[
	f(x) \;\;=\;\; \begin{cases} \dfrac {\beta^\alpha }{\Gamma(\alpha)} x^{\alpha - 1} e^{-x\beta}&amp; \text{if }x \gt 0 \\
	0 &amp; \text{otherwise}
	\end{cases} \]
	<p>then its mean and variance are</p>
		\[
		E[X] \;=\; \frac{\alpha}{\beta}
		\spaced{and} \Var(X) \;=\; \frac{\alpha}{\beta^2}
		\] </div>
	<div class="proof">
		<p>The mean is</p>
\[ \begin{align}
E[X] \;&amp;=\; \int_0^{\infty} {x \frac {\beta^\alpha }{\Gamma(\alpha)} x^{\alpha - 1} e^{-x\beta}} \;dx \\[0.4em]
&amp;=\; \frac {\beta^\alpha}{\Gamma(\alpha)} \int_0^{\infty} {x^{\alpha} e^{-x\beta}} \;dx
\end{align} \]
<p>We integrate this with the change of variable</p>
\[
y = \beta x \spaced{and} dy = \beta \;dx\]
		<p>so</p>
\[ \begin{align}
E[X] \;&amp;=\; \frac 1{\beta\; \Gamma(\alpha)} \int_0^{\infty} {y^{\alpha} e^{-y}} \;dy \\[0.4em]
&amp;=\; \frac {\Gamma(\alpha + 1)}{\beta\; \Gamma(\alpha)} \;=\; \frac {\alpha}{\beta}
\end{align} \]
		<p>In a similar way,</p>
\[ 
E[X^2] \;=\; \frac {\Gamma(\alpha + 2)}{\beta^2 \; \Gamma(\alpha)} \;=\; \frac {\alpha(\alpha + 1)}{\beta^2} \]
		<p>so</p>
\[ 
\Var(X) \;=\; E[X^2] - \left(E[X]\right)^2 \;=\; \frac {\alpha(\alpha + 1)}{\beta^2} - \frac{\alpha^2}{\beta^2} \;=\; \frac{\alpha}{\beta^2}
\]	</div>
</div>
<p>We <a href="javascript:showNamedPage('erlang2')">explained earlier</a> that the sum of  independent \(\ErlangDistn(k_1,\; \lambda)\) and \(\ErlangDistn(k_2,\; \lambda)\) random variables has an \(\ErlangDistn(k_1 + k_2,\; \lambda)\) distribution. The same holds for the sum of Gamma random variables, provided their second parameters are equal.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Additive property of Gamma distributions</p>
		<p>If \(X_1 \sim \GammaDistn(\alpha_1,\; \beta)\) and \(X_2 \sim \GammaDistn(\alpha_2,\; \beta)\) are independent, then</p>
		\[
		X_1 + X_2 \;\;\sim\;\;  \GammaDistn(\alpha_1 + \alpha_2,\; \beta)
		\] </div>
	<div class="proof">
		<p>We justified this earlier for integer values of \(\alpha\) in the context of the Erlang distribution, but cannot give the general proof here.</p>
	</div>
</div>
<p>The following result gives a normal approximation to the Gamma distribution when \(\alpha\) is large.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Asymptotic normal distribution</p>
		<p>The shape of the \(\GammaDistn(\alpha,\; \beta)\) distribution approaches that of a normal distribution as \(\alpha \to \infty\)</p>
	</div>
	<div class="proof">
		<p>If \(\{X_1, X_2, \dots\}\) are independent \(\GammaDistn(1,\; \beta)\) distribution, then \(\sum_{i=1}^{n}X_i \sim \GammaDistn(n,\; \beta)\). From the <a href="javascript:showNamedPage('randomSample5')">Central Limit Theorem</a>, the distribution of this sum approaches a normal distribution as \(n \to \infty\).</p>
	</div>
</div>
<script type='text/javascript'>writePageEnd();</script>
</body>
</html>
