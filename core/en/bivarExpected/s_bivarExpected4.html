<!DOCTYPE HTML>
<html>
<head>
	<title>Means and variances</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="bivariate distribution, mean, variance">
</head>


<body>
<script type="text/javascript">writePageStart();</script>
<p>The expected value of \(X\) — its mean — is the mean of its marginal distribution.</p>
\[ \begin{align}
E[X] \;=\; \mu_X  \;=\; \sum_{\text{all }x} {\sum_{\text{all }y}{x \times p(x,y)}} \;&amp;=\; \sum_{\text{all }x} {x \times \sum_{\text{all }y}{p(x,y)}} \\
&amp;=\; \sum_{\text{all }x} {x \times p_X(x)}
\end{align} \]
<p>Integration replaces summation in this proof for continuous random variables. In a similar way, the variance of \(X\) is the variance of its marginal distribution,</p>
\[
\Var(X) \;=\; E\left[(X-\mu_X)^2\right] \;=\; \sum_{\text{all }x} {(x-\mu_x)^2 \times p_X(x)}
\]
<p>The same results hold for the mean and variance of \(Y\).</p>
<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
