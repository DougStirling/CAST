<!DOCTYPE HTML>
<html>
<head>
	<title>Bias</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="estimation, bias, mean of random sample, variance of random sample, sample mean, sample variance">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Distribution of an estimator</p>

<p>If  \({X_1, X_2, \dots, X_n}\) is a random sample from a distribution involving a single unknown parameter \(\theta\), an estimator \(
\hat{\theta}(X_1, X_2, \dots, X_n)
\) is a function of these \(n\) random variables and also has a distribution. It is often simply written as \(
\hat{\theta}\).</p>
<p>The properties of an estimator depend on its distribution. For example, an estimator with a continuous distribution might have the pdf show below.</p>
<p class="eqn"><img class="svgImage" src="images/estimatorDistn.png" width="383" height="196"></p>
<p>For   \(
\hat{\theta}\) to be a <strong>good estimator</strong> of \(\theta\), its distribution should concentrated near \(\theta\).</p>
<p class="heading">Bias</p>
<p>A good estimator of  \(\theta\) should have a distribution whose &quot;centre&quot; is close to \(\theta\). This can be summarised by the distance of the estimator's mean from  \(\theta\).</p>

<div class="definition">
<p class='definitionTitle'>Definition</p>
<p>The <strong>bias</strong> of an estimator \(\hat{\theta}\) of a parameter \(\theta\) is defined to be</p>
\[
\Bias(\hat{\theta}) \;=\; E[\hat{\theta}] - \theta
\]
<p>If its bias is zero, \(\hat{\theta}\) is called an <strong>unbiased</strong> estimator of \(\theta\).</p>
</div>

<p>Many popular estimators are unbiased.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Sample mean</p>
		<p>If \({X_1, X_2, \dots, X_n}\) is a random sample from a distribution with mean \(\mu\), the sample mean, \(\overline{X}\), is  an unbiased estimator of the distribution mean, \(\mu\).</p>
		<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>
<p>A sample variance is <strong>also</strong> an unbiased estimator of a distribution's variance, \(\sigma^2\), but this is harder to prove.</p>

<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Sample variance</p>
		<p>If \({X_1, X_2, \dots, X_n}\) is a random sample from a distribution with variance \(\sigma^2\), the sample variance,</p>
\[
S^2 = \sum_{i=1}^n {\frac {(X_i - \overline{X})^2} {n-1}}
\]
<p>is an unbiased estimator of \(\sigma^2\).</p>
<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>
<p>Although the sample <strong>variance</strong> is unbiased, the sample <strong>standard deviation</strong> is a biased estimator.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Sample standard deviation</p>
		<p>The sample standard deviation, \(S\), is a <strong>biased</strong> estimator of a distribution's standard deviation, \(\sigma\).</p>
		<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>
<script type='text/javascript'>writePageEnd();</script>
</body>
</html>
