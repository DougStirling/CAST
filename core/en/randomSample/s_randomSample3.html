<!DOCTYPE HTML>
<html>
<head>
	<title>Functions of two variables</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="independence, linear combination">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Random variables defined from others</p>

<p>Any function of these two variables can be used to define another random variable.</p>
\[Z =g(X, Y)\]

<p>The shape of its distribution  depends on those of \(X\) and \(Y\), but we will only consider its mean and variance here. </p>
<p class="heading">Independent variables</p>
<p>We now give two results that hold provided \(X\) and \(Y\) are <strong>independent</strong>. The first result is stated without proof here, but will be used later.</p>

<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Product of independent random variables</p>
		<p>If two  discrete random variables, \(X\) and \(Y\), are independent,</p>
\[
E[XY] = E[X] \times E[Y]
\]
	<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>
<p>More important in practice is a <strong>linear</strong> combination of \(X\) and \(Y\),</p>
<p class="eqn">\(Z =aX + bY\) Â  where \(a\) and \(b\) are constants</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Linear combination of independent variables</p>
		<p>If the means of two independent discrete random variables, \(X\) and \(Y\), are \(\mu_X\) and \(\mu_Y\) and their variances are \(\sigma_X^2\) and \(\sigma_Y^2\), then the linear combination \((aX + bY)\) has mean and variance</p>
\[ \begin {align}
E[aX + bY] &amp; = a\mu_X + b\mu_Y \\[0.4em]
\Var(aX + bY) &amp; = a^2\sigma_X^2 + b^2\sigma_Y^2
\end {align} \]
	<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>

<p>Although the formula for the mean still holds if \(X\) and \(Y\) are <strong>not</strong> independent, the formula for the variance requires modification to cope with dependent random variables. </p>

<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
