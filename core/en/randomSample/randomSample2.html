<!DOCTYPE HTML>
<html>
<head>
	<title>Random samples</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="independence, random sample">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Two independent repetitions of a random experiment</p>

<p>One important situation that leads to independent random variables is when some random experiment is repeated twice in essentially the same way.</p>
<div class="example">
	<p class="exampleHeading">Examples</p>
	<ul>
		<li>Two different boxes, each containing 10 beetles, are given a weak dose of insecticide. \(X\) and \(Y\) are the numbers surviving for 20 minutes in the two boxes.</li>
		<li>\(X\) and \(Y\)<em> </em>are the numbers of patients admitted to a hospital's coronary unit with heart attacks in successive weeks.</li>
		<li>A die is rolled twice, with \(X\)<em> </em>and \(Y\)<em> </em>being the numbers that appear on the two rolls.</li>
	</ul>
</div>
<p>In these examples, not only can the two variables be assumed to be independent, but it is reasonable to assume that both have the same distribution. This allows us to dispense with the subscripts for their probability functions,</p>
\[
p_X(\cdot) \;=\; p_Y(\cdot) \;=\; p(\cdot)
\]

<p class="heading">Random sample</p>
<p>If this is extended to \(n\) independent repetitions of a random experiment, we get  \(n\) independent identically distributed random variables. This is often abbreviated to \(n\) <strong>iidrv</strong>'s and is also called a <strong>random sample</strong> from the distribution with probability function \(p(x)\).</p>

<div class="definition">
<p class='definitionTitle'>Definition</p>
<p>A <strong>random sample</strong> of  \(n\) values from a distribution is a collection of  \(n\) independent random variables, each of which has this distribution.</p>
</div>

<p>Random samples often arise in statistics, and the following theorem is central to their analysis.</p>

<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Probabilities for random samples</p>
		<p>The probability that the values in a discrete random sample are \(x_1, x_2, ..., x_n\) is</p>
		\[
		P(X_1 = x_1, X_2 = x_2, ..., X_n = x_n) \;\; = \;\; \prod_{i=1}^n p(x_i)
		\]
	</div>

	<div class="proof">
		<p>The result can be proved by induction. It clearly holds when  \(n=2\) from the definition of independence of two random variables.</p>
\[
P(X_1 = x_1 \textbf{ and } X_2 = x_2) \; = \; P(X_1 = x_1) \times P(X_2 = x_2)
\]
		<p>For a random sample of  \(n=3\)<em> </em>values,</p>
\[
P(X_1 = x_1 \textbf{ and } X_2 = x_2 \textbf{ and } X_3 = x_3) \; = \; P(X_1 = x_1 \textbf{ and } X_2 = x_2) \times P(X_3 = x_3)
\]

		<p>since \(X_3\) is independent of both \(X_1\) and \(X_2\). Therefore</p>
\[
P(X_1 = x_1 \textbf{ and } X_2 = x_2 \textbf{ and } X_3 = x_3) \; = \; P(X_1 = x_1) \times P(X_2 = x_2) \times P(X_3 = x_3)
\]
		<p>The proof for  \(n = 4\)  proceeds in a similar way, and so on.</p>
	</div>

</div>
<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
