<!DOCTYPE HTML>
<html>
<head>
	<title>Properties of sums and means</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	
	<link rel='stylesheet' href='../../structure/maths/mathStyles.css' type='text/css'>
	<script src='../../structure/videoControls/jquery.js'></script>
	<script src='../../structure/maths/theorems.js'></script>
	<script src='../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js'></script>

	<meta name="index" content="sum of random sample, mean of random sample">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Two independent random variables</p>

<p>From the result on the previous page about linear functions of two independent variables,</p>

\[\begin{align}
E[X_1 + X_2] \;\;&amp; =\;\; E[X_1] + E[X_2] \\[0.5em]
\Var(X_1 + X_2) \;\;&amp; =\;\; \Var(X_1) + \Var(X_2)
\end{align} \]

<p>If \(X_1\) and \(X_2\) also have the <strong>same</strong> distributions with mean \(\mu\) and variance \(\sigma^2\), then:</p>
\[\begin{align}
E[X_1 + X_2] \;\;&amp; =\;\; 2\mu \\
\Var(X_1 + X_2) \;\;&amp; =\;\; 2\sigma^2
\end{align} \]

<p class="heading">Random sample</p>
<p>This extends to the sum  of \(n\) independent identically distributed random variables â€” the sum of the values in a random sample.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Sum of values in a random sample</p>
		<p>If \(\{X_1, X_2, ..., X_n\}\) is a random sample of \(n\) values from a discrete distribution with mean \(\mu\) and variance \(\sigma^2\), then the sum of the values, \(\sum_{i=1}^n {X_i}\) has mean and variance</p>
\[\begin{align}
E\left[\sum_{i=1}^n {X_i}\right] &amp; = n\mu \\
\Var\left(\sum_{i=1}^n {X_i}\right) &amp; = n\sigma^2
\end{align} \]

	<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>
<p>Since the sample mean is simply the sum of the values divided by the constant \(n\), this result also provides us with formulae for the mean and variance of the sample mean.</p>
<div class="theoremProof">
	<div class="theorem">
		<p class="theoremTitle">Mean of a random sample</p>
		<p>If \(\{X_1, X_2, ..., X_n\}\) is a random sample of \(n\) values from a discrete distribution with mean \(\mu\) and variance \(\sigma^2\), then the sample mean has a distribution with mean and variance</p>
\[\begin{align}
E[\overline{X}] \;\;&amp; =\;\; \mu \\
\Var(\overline{X}) \;\;&amp; =\;\; \frac {\sigma^2} n
\end{align} \]	
<p class="theoremNote">(Proved in full version)</p>
	</div>
</div>


<script type='text/javascript'>writePageEnd();</script>
</body>
</html>
