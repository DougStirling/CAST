<html>
<head>
<title>8. Two Numerical Variables</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 8 &nbsp; Two Numerical Variables</h1>
<h2>8.1 &nbsp; Scatterplots</h2>
<h3>8.1.1 &nbsp; Bivariate data sets</h3>
<p>Many data sets contain two or more measurements from each individual. Even when the main interest is in one variable, the others can help to understand its distribution.</p>
<h3>8.1.2 &nbsp; Scatterplots</h3>
<p>The main display that shows the relationship between two variables is a scatterplot.</p>
<h3>8.1.3 &nbsp; Limitations of univariate displays</h3>
<p>Univariate displays don't show relationships between variables.</p>
<h3>8.1.4 &nbsp; Marginal distributions</h3>
<p>A scatterplot of two variables can be enhanced with box plots or histograms on the margins of a scatterplot.</p>
<h3>8.1.5 &nbsp; Time series</h3>
<p>When a single measurement is made at regular intervals, the data are called a time series. Time series data can be treated as bivariate, with time being the second variable.</p>
<h2>8.2 &nbsp; Understanding relationships</h2>
<h3>8.2.1 &nbsp; Strength of a relationship</h3>
<p>The main feature of interest in a scatterplot is the strength of the relationship between the two variables.</p>
<h3>8.2.2 &nbsp; Outliers</h3>
<p>An extreme value of one or both of the variables is an outlier. An unusual combination of values is also called an outlier.</p>
<h3>8.2.3 &nbsp; Clusters</h3>
<p>If the crosses on a scatterplot separate into clusters, different groups of individuals are suggested.</p>
<h3>8.2.4 &nbsp; Dangers of over-interpretation</h3>
<p>In small data sets, there may be considerable variability, so patterns should be strongly evident before they are reported.</p>
<h3>8.2.5 &nbsp; Explanatory and response variables</h3>
<p>One variable can often be classified as an explanatory variable that either causally affects the reponse variable, or is useful for predicting its value.</p>
<h2>8.3 &nbsp; Correlation</h2>
<h3>8.3.1 &nbsp; Units for X and Y</h3>
<p>A numerical description of the strength of a relationship should not be affected by rescaling the variables.</p>
<h3>8.3.2 &nbsp; Units-free variables (z-scores)</h3>
<p>Standardising a variable gives z-scores that do not depend on the units of the original variable. (The correlation coefficient will be defined in terms of z-scores for X and Y.)</p>
<h3>8.3.3 &nbsp; Correlation coefficient</h3>
<p>The correlation coefficient summarises the strength of the relationship between X and Y. It is +1 when the scatterplot crosses are on a straight line with positive slope, -1 when on a line with negative slope, and zero when X and Y are unrelated.</p>
<h3>8.3.4 &nbsp; Scatterplots and the value of r</h3>
<p>You should be able to estimate the value of r from looking at a scatterplot and imagine a scatter of crosses corresponding to any value of r.</p>
<h3>8.3.5 &nbsp; Nonlinear relationships</h3>
<p>The correlation coefficient is only a good measure of the strength of a relationship if the points in a scatterplot are scattered round a straight line, not a curve.</p>
<h3>8.3.6 &nbsp; R does not tell the whole story</h3>
<p>The correlation coefficient cannot identify curvature, outliers or clusters and can be misleading if these features are present. A scatterplot must always be examined too.</p>
<h2>8.4 &nbsp; Least squares</h2>
<h3>8.4.1 &nbsp; Predicting Y from X</h3>
<p>A line or curve is useful for predicting the value of Y from a known value of X.</p>
<h3>8.4.2 &nbsp; Linear models</h3>
<p>A straight line can often be used to predict one variable from another.</p>
<h3>8.4.3 &nbsp; Fitted values and residuals</h3>
<p>The difference between the actual value of Y and the value predicted by a line is called a residual. Small residuals are clearly desirable.</p>
<h3>8.4.4 &nbsp; Least squares</h3>
<p>The sum of squared residuals describes the accuracy of predictions from a line. The method of least squares positions the line to minimise the sum of squared residuals.</p>
<h3>8.4.5 &nbsp; Curvature and outliers</h3>
<p>A linear model is not appropriate if there are either curvature or outliers in a scatterplot of the data. Outliers should be carefully examined.</p>
<h3>8.4.6 &nbsp; Residual plots</h3>
<p>Outliers and curvature in the relationship are often displayed more clearly in a plot of residuals.</p>
<h3>8.4.7 &nbsp; Predicting Y and predicting X</h3>
<p>Least squares does not treat Y and X symmetrically. The best line for predicting Y from X is different from the best line for predicting X from Y.</p>
<h2>8.5 &nbsp; Nonlinear relationships</h2>
<h3>8.5.1 &nbsp; Transformations and correlation</h3>
<p>The correlation coefficient does not adequately describe the strength of a nonlinear relationship. Transforming the variables to linearise the relationship helps.</p>
<h3>8.5.2 &nbsp; Transformations and models</h3>
<p>If a relationship is nonlinear, a linear model can often be fitted to transformed response or explanatory variables.</p>
<h3>8.5.3 &nbsp; Quadratic models</h3>
<p>An alternative solution to nonlinearity is to fit a quadratic curve the data, again using the principle of least squares.</p>
<h3>8.5.4 &nbsp; Dangers of extrapolation</h3>
<p>Since the form of a relationship is unknown beyond the range of x-values in the data, it is always dangerous to extrapolate.</p>
</html>
