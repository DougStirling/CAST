<html>
<head>
  <title>7. Comparing Groups</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="../../../structure/printStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/summaryStyles.css" type="text/css">
  <script src="../../../structure/videoControls/jquery.js"></script>
  <script src="../../../structure/printFixes.js"></script>
</head>

<body id="body" onLoad="showPrintDialog(true)">
<div id='overlay'>
	<div id='dialogWindow'>
		<div class='printDialog'>
			<script type='text/javascript'>
				document.write("<div class='heading'>" + top.document.title + "</div>");
				if (top.url != null) {
					document.write("<p class='text'>A version of this chapter has already been generated in PDF format and we recommend that it is used for printing. The button below will download and display it.</p>");
					document.write("<p><button onClick='top.showPdf()'>Show PDF version of chapter</button></p>");
					document.write("<p class='text'>However downloading could be slow depending on your internet connection. If this is a problem, click the button below to print the chapter without downloading (but perhaps not formatted as well as the PDF version).</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>If you are <strong>not</strong> using the PDF version, the best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
				else {
					document.write("<p class='text'>Click the button below to print this chapter.</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>The best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
			</script>
			
			<p class='text'>If you don't want to print now,</p>
			<p><button onClick='top.showPrintDialog(false)'>Browse formatted chapter</button></p>
		</div>
	</div>
</div>
<h1 class="chapterName">Chapter 7 &nbsp; Comparing Groups</h1>
<h1 class="sectionName">7.1 &nbsp; Models for two groups</h1>
<div class='leftTocCol'>
<ol class='toc'>
<li>Interest in underlying population</li>
<li>Model for two groups</li>
<li>Parameters of the normal model</li>
</ol>
</div>
<div class='rightTocCol'>
<ol class='toc' start='4'>
<li>Parameter estimates</li>
<li>Difference between means</li>
</ol>
</div>
<br clear='all'>
<h2 class="pageName">7.1.1 &nbsp; Interest in underlying population</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Data from two groups</p>
<p>When data are  collected from two groups, we are usually interested in  differences
between the groups
<strong>in general</strong>. The <strong>specific</strong> individuals  are of
less interest. Questions are therefore about the characteristics of the populations
or processes that we assume <strong>underlie</strong> the
data.</p>
<p class="heading">Example</p>
<p class="eqn"><img src="../../../en/twoGroupModel/images/hypnosis.gif" width="523" height="299"> </p>
<p>The diagram below illustrates a possible model for the data above.</p>
<p class="eqn"><img src="../../../en/twoGroupModel/images/s_pdfs.gif" width="321" height="251"></p>
<p>Without an understanding of the distribution of <span style="position:relative; top:5px"><img src="../../../en/../images/symbol.xBarDiff.png" width="36" height="15" align="baseline"></span>,
it is impossible to properly interpret what the sample difference, 0.104&nbsp;kg,
tells you about the difference between the underlying population means.</p>




<h1 class="sectionName breakBefore">7.2 &nbsp; Distn of sums and differences</h1>
<div class='leftTocCol'>
<ol class='toc'>
<li>Means and sums of samples</li>
<li>Sum and difference</li>
</ol>
</div>
<div class='rightTocCol'>
<ol class='toc' start='3'>
<li>Sum and difference (cont)</li>
<li>Probabilities for sums and differences</li>
</ol>
</div>
<br clear='all'>
<h2 class="pageName">7.2.1 &nbsp; Means and sums of samples</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Sample mean and sum</p>
<p>The mean of a random
sample, <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline">,
has a distribution that is approximately normal if the sample size, <em>n</em>, is
large and alway has a
mean and standard deviation that depend on the population mean, µ, and standard deviation,
σ,</p>
<p class=eqn><span style="position:relative; top:6px"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></span> &nbsp;<span class="black">=&nbsp; &mu;</span></p>
<p class=eqn><span style="position:relative; top:5px"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></span> &nbsp;<span class="black">=</span>&nbsp; <span style="position:relative; top:12px"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></span> </p>
<p>Occasionally the sum of values in a random sample values is more useful than the
mean,</p>
<p class=eqn><img class="gif" width="220" height="18"></p>
<p>Its distribution is
a scaled version of the distribution of the mean &mdash; the same shape but different
mean and standard deviation.</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sumMean.gif" width="75" height="14"></p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sumSD.gif" width="89" height="21"></p>
<p class="heading">Mean vs Sum</p>
<p>As the sample size increases,</p>
<ul>
<li>the standard deviation of the mean decreases, but</li>
<li>the standard deviation of the sum <strong>increases</strong>.</li>
</ul>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sdInequality.gif" width="130" height="16"></p>




<h2 class="pageName">7.2.2 &nbsp; Sum and difference</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Sum and difference of two  variables</p>
<p>Applying the result about the sum of a random sample to a sample of size <em>n</em> = 2, <em>X</em><sub>1</sub>
and <em>X</em><sub>2</sub>,</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sum2Distn.gif" width="119" height="50"></p>
<p>If we generalise by allowing <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub> to
have different means, µ<sub>1</sub> and µ<sub>2</sub>, but the same σ,</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sum2Distn2.gif" width="146" height="47"> </p>
<p>A similar result holds for the difference between <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub>:</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/diff2Distn2.gif" width="146" height="47"></p>
<p>If <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub> are independent and have
normal distributions, their sum and difference are also normally distributed.</p>




<h2 class="pageName">7.2.3 &nbsp; Sum and difference (cont)</h2><!DOCTYPE HTML>


<p class="heading notPrinted">General result</p>
<p>The results generalise further to independent variables that may have different
means <strong>and</strong> standard deviations.</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sumDiffSD.gif" width="250" height="161"></p>
<p>The formulae for the standard deviations are more easily remembered in terms of
the <strong>variances</strong> of
the  quantities. For example,</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sum2Variance.gif" width="151" height="25"></p>




<h2 class="pageName">7.2.4 &nbsp; Probabilities for sums and differences</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Finding probabilities</p>
<p>To find the probability that a sum or difference satisfies an inequality, the
inequality should be translated into ones about a z-score, using the mean and standard
deviation of the quantity,</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/standardiseEqn.gif" width="95" height="31"></p>
<p>The standard normal distribution can then be used to find the  probabilities. The
examples below illustrate the method. </p>
<p class="heading">Example (total of several variables)</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/totalExample.gif" width="496" height="516"> </p>
<p class="heading">Example (sum of two variables with different sd)</p>
<p class=eqn><img class="gif" src="../../../en/sumDiff/images/sumExample.gif" width="496" height="516"> </p>




<h1 class="sectionName breakBefore">7.3 &nbsp; Comparing means in two groups</h1>
<div class='leftTocCol'>
<ol class='toc'>
<li>Distn of difference between means</li>
<li>SE of difference between means</li>
<li>CI for difference between means</li>
</ol>
</div>
<div class='rightTocCol'>
<ol class='toc' start='4'>
<li>Testing a hypothesis</li>
<li>One-tailed tests for differences</li>
</ol>
</div>
<br clear='all'>
<h2 class="pageName">7.3.1 &nbsp; Distn of difference between means</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Difference between  means</p>
<p>The difference between <strong>any</strong> two independent
quantities <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub> has a distribution
with</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupInf/images/meanSDDiff2.gif" width="113" height="51"> </p>
<p>Applying this to  the difference between the
means of two random samples,</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupInf/images/diffMeanSD.gif" width="340" height="163"> </p>
<dl>
<dt>If the distributions are normal in each group,&nbsp;...</dt>
<dd>... the  sample means are normal, so their difference
also has a normal distribution.</dd>
<dt>Otherwise,&nbsp;...</dt>
<dd>... the two sample means are approximately normal if the sample sizes are
large,  so their difference is also close to normal.</dd>
</dl>

<div class="centred"><div class="boxed">
<p>Irrespective of the distributions within the
two groups, <br>
<img class="gif" src="../../../en/twoGroupInf/images/normalDistn.gif" width="331" height="44"></p>
</div></div>





<h2 class="pageName">7.3.2 &nbsp; SE of difference between means</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Estimation error</p>
<p>The difference between the sample means, <span class="eqn"><span style="position:relative; top:5px"><img src="../../../en/../images/symbol.xBarDiff.png" width="36" height="15" align="baseline"></span></span>,
is a point estimate of the difference between the means of the underlying populations, <span class="black">µ<sub>2</sub>&nbsp;-&nbsp;µ<sub>1</sub></span>.
In order to properly interpret it, we must understand the distribution of
the estimation error.</p>
<p class=eqn><img class="gif" width="372" height="42"> </p>
<p>Replacing σ<sub>1</sub><sup>2</sup> and σ<sub>2</sub><sup>2</sup> by <em>s</em><sub>1</sub><sup>2</sup> and
<em>s</em><sub>2</sub><sup>2</sup> gives an approximate error distribution,</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupInf/images/estErrorDistn2.gif" width="172" height="42"> </p>
<p>The standard deviation of these errors is the <strong>standard error</strong> of
the estimator.</p>
<p class="heading">Examples</p>
<p align="center"><img src="../../../en/twoGroupInf/images/hypnosisError.gif" width="514" height="417"></p>
<p>where the degrees of freedom for the t-value are </p>
<p class=eqn><span class="black">&nu; &nbsp; = &nbsp; min (<em>n</em><sub>1</sub>&minus;1, &nbsp;<em>n</em><sub>2</sub>&minus;1)</span> </p>
<p class="gray">(A more complex formula is available that gives a higher
value for &nu;. It is slightly better but the difference is usually
negligible.)</p>
<p class="heading">Example</p>
<p align="center"><img src="../../../en/twoGroupInf/images/hypnosisCI.gif" width="514" height="401"> </p>
<p>As with all other hypothesis tests, a p-value near zero gives evidence that
the null hypothesis does not hold &mdash; evidence of a difference between the group
means. </p>
<p class="heading">Example</p>
<p align="center"><img src="../../../en/twoGroupInf/images/hypnosisTest.gif" width="514" height="468"> </p>
<p class="heading">Test statistic, p-value and conclusion</p>
<p>Consider a test for the hypotheses,</p>
<p class=eqn><span class="blue"><strong><font size="+1">H</font><sub>0</sub>&nbsp;:&nbsp;&nbsp;&nbsp;</strong>&mu;<strong><sub>1</sub> &nbsp;=&nbsp; </strong>&mu;<strong><sub>2</sub></strong><br><strong><font size="+1">H</font><sub>A</sub>&nbsp;:&nbsp;&nbsp;&nbsp;</strong>&mu;<strong><sub>1</sub> &nbsp;&gt;&nbsp; </strong>&mu;<strong><sub>2</sub></strong></span> </p>
<p>The alternative hypothesis is only supported by very small values of <span style="position:relative; top:5px"><img src="../../../en/../images/symbol.xBarDiff.png" width="36" height="15" align="baseline"></span>.
This also corresponds to small values of the test statistic <span class="em black">t</span> ,
so the p-value is the <strong>lower</strong> tail probability of the t distribution. </p>
<p class=eqn><img class="gif" width="453" height="265"> </p>
<p>A small  p-value is interpreted as giving evidence that H<sub>0</sub> is false, in a
similar way to all other kinds of hypothesis test.</p>
<p class="heading">Examples</p>
<p align="center"><img src="../../../en/twoGroupInf/images/bacteriaCarpetsTest.gif" width="514" height="468"> </p>
<p>Since our  model  involves only two parameters, π<sub>1</sub> and π<sub>2</sub>,
 the two groups are the same only if π<sub>2</sub> - π<sub>1</sub> = 0. The value
of π<sub>2</sub>&nbsp;-&nbsp;π<sub>1</sub> is usually unknown
but  can be estimated by <em>p</em><sub>2</sub>&nbsp;-&nbsp;<em>p</em><sub>1</sub>.
However   <em>p</em><sub>2</sub>&nbsp;-&nbsp;<em>p</em><sub>1</sub> is
a random quantity so its variability must
be taken into account when interpreting its value.</p>
<p class="heading">Example</p>
<p align="center"><img src="../../../en/twoGroupPropn/images/birthSex.gif" width="514" height="336"></p>
<p>Applying the  general results about the difference between two independent
random quantities:</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupPropn/images/meanSD.gif" width="554" height="120"> </p>
<p>Since the individual proportions are approximately normal (in large samples),
their difference is also approximately normal:</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupPropn/images/diffPDistn.gif" width="417" height="70"></p>




<h2 class="pageName">7.4.3 &nbsp; CI for difference in proportions</h2><!DOCTYPE HTML>


<p class="heading">Standard error of <em>p</em><sub>2</sub>&nbsp;-&nbsp;<em>p</em><sub>1</sub></p>
<p>The  standard deviation of <em>p</em><sub>2</sub>&nbsp;-&nbsp;<em>p</em><sub>1</sub> is
also its standard error when it<sub></sub> is
used to estimate π<sub>2</sub>&nbsp;-&nbsp;π<sub>1</sub>,</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupPropn/images/sdDiffEqn.gif" width="228" height="45"></p>
<p>In practice, π<sub>1</sub> and π<sub>2</sub> must be replaced by their sample
equivalents to estimate the standard error. </p>
<p class=eqn><img class="gif" src="../../../en/twoGroupPropn/images/sdDiffEqn2.gif" width="228" height="45"></p>
<p class="heading">Confidence interval for difference</p>
<p>Most 95% confidence intervals are of the form</p>
<p class="eqn"><em>estimate</em>   ±   1.96 &times; se(<em>estimate</em>)</p>
<p>perhaps with a refinement of using a slightly higher value than 1.96 (e.g.
a t-value) if the standard error is estimated. Applying this to our estimate
of π<sub>2</sub>&nbsp;-&nbsp;π<sub>1</sub>and using 2 instead of 1.96 gives the
approximate 95% confidence interval</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupPropn/images/diffCIEqn2.gif" width="278" height="48"></p>
<p class="heading">Example</p>
<p align="center"><img src="../../../en/twoGroupPropn/images/bingeCI.gif" width="514" height="373"> </p>
<p>The p-value is interpreted in the same way as for all previous tests. A p-value
close to zero is unlikely when <b>H<sub>0</sub></b> is true, but is more likely
when <b>H<sub>A</sub></b> holds. Small p-values therefore provide evidence of
a difference between the population probabilities. </p>
<p class="heading">One-tailed test</p>
<p>In a 1-tailed test, the alternative hypothesis is</p>
<p class=eqn><span class="blue"><strong><font size="+1">H</font><sub>A</sub>&nbsp;:&nbsp;&nbsp;&nbsp;</strong>&pi;<strong><sub>1</sub> &nbsp;&minus;&nbsp; </strong>&pi;<strong><sub>2</sub> &nbsp;&gt;&nbsp; 0</strong></span> &nbsp;&nbsp; <span class="red"><strong>or</strong></span> &nbsp;&nbsp; <span class="blue"><strong><font size="+1">H</font><sub>A</sub>&nbsp;:&nbsp;&nbsp;&nbsp;</strong>&pi;<strong><sub>1</sub> &nbsp;&minus;&nbsp; </strong>&pi;<strong><sub>2</sub> &nbsp;&lt;&nbsp; 0</strong></span></p>
<p>The test statistic is identical to that for a 2-tailed test and the p-value
is obtained in a similar way, but it is found from only a <strong>single</strong> tail
of the standard normal distribution. </p>
<p class="heading"><span class="black">Alternative test statistic</span></p>
<p>Since π<sub>1</sub> and
π<sub>2</sub> are equal if <b>H<sub>0</sub></b> is true, the overall proportion
of successes, <em>p</em>, can be used in the formula for the standard error
of <em>p</em><sub>2</sub>&nbsp;-&nbsp;<em>p</em><sub>1</sub>.</p>
<p class=eqn><img class="gif" src="../../../en/twoGroupPropn/images/diffSDEstEqn.gif" width="476" height="95"> </p>
<p>This refinement makes little difference in practice,
so the examples below use the 'simpler' formula that we gave earlier.</p>
<p class="heading">Two-tailed example</p>
<p align="center"><img src="../../../en/twoGroupPropn/images/birthSexTest.gif" width="541" height="476"></p>
<p>This is compared to a t distribution with <em>n</em>&nbsp;-&nbsp;1
degrees of freedom to find the p-value.</p>
<p class="heading">Example</p>
<p>The diagram below illustrates a 2-tailed test for equal means, based on <em>n</em> = 15
paired observations.</p>
<p class="eqn"><img src="../../../en/testPaired/images/s_example.gif" width="475" height="384"></p>
<p>From the p-value, we conclude that there is very strong evidence that the
means for <em>Y</em> and <em>X</em> are different.</p>





<h2 class="pageName">7.5.4 &nbsp; Pairing and experimental design</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Choice between paired data or two independent samples</p>
<p>It is sometimes possible to answer questions about the difference
between two means by collecting two alternative types of data.</p>
<dl>
<dt>Two independent samples</dt>
<dd>Measurements are made from two samples of individuals from the groups whose
means are to be compared. A 2-sample t-test can be used to compare the means.</dd>
<dt>One paired sample</dt>
<dd>The 'individuals' can be re-defined as pairs of related values from the two
groups and a single sample of these pairs can be collected. A paired t-test
can be performed on the differences to compare the means.</dd>
</dl>
<div class="centred"><div class="boxed"><p>If the individuals in the 2 groups can be paired so that the pairs
are relatively similar, a paired design gives more accurate results.</p></div></div>
<p class="heading">Matched pairs in experiments</p>
<p>In experiments to compare two treatments, it may be possible to group the
experimental units into pairs that are similar in some way. These are called <strong>matched
pairs</strong>.
If the two experimental units in each pair are randomly assigned to the two
treatments, the data can be analysed as described in this section.</p>
<p>The difference between the treatments is estimated more accurately than in
a completely randomised experiment.</p>




</html>
