<html>
<head>
<title>12. Describing Relationships</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 12 &nbsp; Describing Relationships</h1>
<h2>12.1 &nbsp; Correlation</h2>
<h3>12.1.1 &nbsp; Units for X and Y</h3>
<p>A numerical description of the strength of a relationship should not be affected by rescaling the variables.</p>
<h3>12.1.2 &nbsp; Units-free variables (z-scores)</h3>
<p>Standardising a variable gives z-scores that do not depend on the units of the original variable. (The correlation coefficient will be defined in terms of z-scores for X and Y.)</p>
<h3>12.1.3 &nbsp; Correlation coefficient</h3>
<p>The correlation coefficient summarises the strength of the relationship between X and Y. It is +1 when the scatterplot crosses are on a straight line with positive slope, -1 when on a line with negative slope, and zero when X and Y are unrelated.</p>
<h3>12.1.4 &nbsp; Scatterplots and the value of r</h3>
<p>You should be able to estimate the value of r from looking at a scatterplot and imagine a scatter of crosses corresponding to any value of r.</p>
<h3>12.1.5 &nbsp; Nonlinear relationships</h3>
<p>The correlation coefficient is only a good measure of the strength of a relationship if the points in a scatterplot are scattered round a straight line, not a curve.</p>
<h3>12.1.6 &nbsp; R does not tell the whole story</h3>
<p>The correlation coefficient cannot identify curvature, outliers or clusters and can be misleading if these features are present. A scatterplot must always be examined too.</p>
<h2>12.2 &nbsp; Least squares</h2>
<h3>12.2.1 &nbsp; Predicting Y from X</h3>
<p>A line or curve is useful for predicting the value of Y from a known value of X.</p>
<h3>12.2.2 &nbsp; Linear models</h3>
<p>A straight line can often be used to predict one variable from another.</p>
<h3>12.2.3 &nbsp; Fitted values and residuals</h3>
<p>The difference between the actual value of Y and the value predicted by a line is called a residual. Small residuals are clearly desirable.</p>
<h3>12.2.4 &nbsp; Least squares</h3>
<p>The sum of squared residuals describes the accuracy of predictions from a line. The method of least squares positions the line to minimise the sum of squared residuals.</p>
<h2>12.3 &nbsp; Simple diagnostics</h2>
<h3>12.3.1 &nbsp; Curvature and outliers</h3>
<p>A linear model is not appropriate if there are either curvature or outliers in a scatterplot of the data. Outliers should be carefully examined.</p>
<h3>12.3.2 &nbsp; Residual plots</h3>
<p>Outliers and curvature in the relationship are often displayed more clearly in a plot of residuals.</p>
<h3>12.3.3 &nbsp; Predicting Y and predicting X</h3>
<p>Least squares does not treat Y and X symmetrically. The best line for predicting Y from X is different from the best line for predicting X from Y.</p>
<h2>12.4 &nbsp; Nonlinear relationships</h2>
<h3>12.4.1 &nbsp; Transformations and correlation</h3>
<p>The correlation coefficient does not adequately describe the strength of a nonlinear relationship. Transforming the variables to linearise the relationship helps.</p>
<h3>12.4.2 &nbsp; Transformations and models</h3>
<p>If a relationship is nonlinear, a linear model can often be fitted to transformed response or explanatory variables.</p>
<h3>12.4.3 &nbsp; Quadratic models</h3>
<p>An alternative solution to nonlinearity is to fit a quadratic curve the data, again using the principle of least squares.</p>
<h3>12.4.4 &nbsp; Dangers of extrapolation</h3>
<p>Since the form of a relationship is unknown beyond the range of x-values in the data, it is always dangerous to extrapolate.</p>
<h2>12.5 &nbsp; Groups and regression</h2>
<h3>12.5.1 &nbsp; Additional variables in regression</h3>
<p>Correlation and least squares are used to describe the relationship between two numerical variables. Additional measurements from each individual can potentially help to refine our understanding of the relationship.</p>
<h3>12.5.2 &nbsp; Displaying groups</h3>
<p>Different symbols or colours can be used to represent a third categorical variable in a scatterplot.</p>
<h3>12.5.3 &nbsp; Regression with grouped data</h3>
<p>The relationship between Y and X can be separately described by a least squares line within each group. This should lead to improved prediction of the response if the relationship is different in different groups.</p>
<h3>12.5.4 &nbsp; Parallel regression lines</h3>
<p>If regression lines for the different groups are parallel, it is easy to summarise the group differences numerically and interpret these differences.</p>
<h3>12.5.5 &nbsp; Transformed variables and groups</h3>
<p>Transformations may linearise the relationship between the response and explanatory variables in each group and also give parallel regression lines.</p>
<h3>12.5.6 &nbsp; Grouping with a numerical variable</h3>
<p>A numerical variable can be used to split the individuals into groups.</p>
<h3>12.5.7 &nbsp; Scatterplot matrix with groups</h3>
<p>Groups can also be represented with different symbols or colours on a scatterplot matrix that describes the relationships between 3 or more other variables.</p>
</html>
