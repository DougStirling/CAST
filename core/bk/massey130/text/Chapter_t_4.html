<html>
<head>
<title>4. Bivariate Relationships</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 4 &nbsp; Bivariate Relationships</h1>
<h2>4.1 &nbsp; Scatterplots</h2>
<h3>4.1.1 &nbsp; Bivariate data sets</h3>
<p>Many data sets contain two or more measurements from each individual. Even when the main interest is in one variable, the others can help to understand its distribution.</p>
<h3>4.1.2 &nbsp; Scatterplots</h3>
<p>The main display that shows the relationship between two variables is a scatterplot.</p>
<h3>4.1.3 &nbsp; Limitations of univariate displays</h3>
<p>Univariate displays don't show relationships between variables.</p>
<h3>4.1.4 &nbsp; Marginal distributions</h3>
<p>A scatterplot of two variables can be enhanced with box plots or histograms on the margins of a scatterplot.</p>
<h3>4.1.5 &nbsp; Time series</h3>
<p>When a single measurement is made at regular intervals, the data are called a time series. Time series data can be treated as bivariate, with time being the second variable.</p>
<h2>4.2 &nbsp; Understanding relationships</h2>
<h3>4.2.1 &nbsp; Strength of a relationship</h3>
<p>The main feature of interest in a scatterplot is the strength of the relationship between the two variables.</p>
<h3>4.2.2 &nbsp; Outliers</h3>
<p>An extreme value of one or both of the variables is an outlier. An unusual combination of values is also called an outlier.</p>
<h3>4.2.3 &nbsp; Clusters</h3>
<p>If the crosses on a scatterplot separate into clusters, different groups of individuals are suggested.</p>
<h3>4.2.4 &nbsp; Dangers of over-interpretation</h3>
<p>In small data sets, there may be considerable variability, so patterns should be strongly evident before they are reported.</p>
<h3>4.2.5 &nbsp; Explanatory and response variables</h3>
<p>One variable can often be classified as an explanatory variable that either causally affects the response variable, or is useful for predicting its value.</p>
<h2>4.3 &nbsp; Correlation</h2>
<h3>4.3.1 &nbsp; Units for X and Y</h3>
<p>A numerical description of the strength of a relationship should not be affected by rescaling the variables.</p>
<h3>4.3.2 &nbsp; Correlation coefficient</h3>
<p>The correlation coefficient summarises the strength of the relationship between X and Y. It is +1 when the scatterplot crosses are on a straight line with positive slope, -1 when on a line with negative slope, and zero when X and Y are unrelated.</p>
<h3>4.3.3 &nbsp; Scatterplots and the value of r</h3>
<p>You should be able to estimate the value of r from looking at a scatterplot and imagine a scatter of crosses corresponding to any value of r.</p>
<h3>4.3.4 &nbsp; R does not tell the whole story</h3>
<p>The correlation coefficient cannot identify curvature, outliers or clusters and can be misleading if these features are present. A scatterplot must always be examined too.</p>
<h2>4.4 &nbsp; Least squares</h2>
<h3>4.4.1 &nbsp; Predicting Y from X</h3>
<p>A line or curve is useful for predicting the value of Y from a known value of X.</p>
<h3>4.4.2 &nbsp; Linear models</h3>
<p>A straight line can often be used to predict one variable from another.</p>
<h3>4.4.3 &nbsp; Fitted values and residuals</h3>
<p>The difference between the actual value of Y and the value predicted by a line is called a residual. Small residuals are clearly desirable.</p>
<h3>4.4.4 &nbsp; Least squares</h3>
<p>The sum of squared residuals describes the accuracy of predictions from a line. The method of least squares positions the line to minimise the sum of squared residuals.</p>
<h3>4.4.5 &nbsp; Curvature and outliers</h3>
<p>A linear model is not appropriate if there are either curvature or outliers in a scatterplot of the data. Outliers should be carefully examined.</p>
<h3>4.4.6 &nbsp; Residual plots</h3>
<p>Outliers and curvature in the relationship are often displayed more clearly in a plot of residuals.</p>
<h3>4.4.7 &nbsp; Predicting Y & predicting X (opt) (Optional (not examined))</h3>
<p>Least squares does not treat Y and X symmetrically. The best line for predicting Y from X is different from the best line for predicting X from Y.</p>
<h2>4.5 &nbsp; Coefficient of determination</h2>
<h3>4.5.1 &nbsp; Sums of squares</h3>
<p>Variability is often described in terms of sums of squares. The residual sum of squares summarises response variability that is unexplained by the explanatory variable. Sums of squares also describe total and explained variation.</p>
<h3>4.5.2 &nbsp; Coefficient of determination</h3>
<p>The relative sizes of the explained and residual sums of squares holds information about the strength of the relationship. The coefficient of determination describes the proportion of total variation that is explained.</p>
<h2>4.6 &nbsp; Contingency tables</h2>
<h3>4.6.1 &nbsp; Contingency tables</h3>
<p>Categorical data collected from different groups can be shown in a contingency table. It contains a simple frequency table for each group.</p>
<h3>4.6.2 &nbsp; Contingency table examples</h3>
<p>Contingency tables sometimes arise from experiments. Data collected from surveys are often presented in contingency tables.</p>
<h3>4.6.3 &nbsp; Proportions within groups</h3>
<p>It is easier to compare groups using the proportions within each group rather than the frequencies.</p>
<h3>4.6.4 &nbsp; Categorical variables and groups</h3>
<p>In some contingency tables, either the rows or columns can be used to split the individuals into groups.</p>
<h3>4.6.5 &nbsp; Marginal distributions</h3>
<p>The two marginal distributions are found by adding the joint frequencies (or proportions) across rows or down columns of a contingency table.</p>
<h3>4.6.6 &nbsp; Conditional distributions</h3>
<p>Conditional distributions are obtained by scaling the rows (or columns) of a contingency table to make them all sum to 1.0.</p>
<h3>4.6.7 &nbsp; Conditional vs marginal distns (opt) (Optional (not examined))</h3>
<p>Proportional Venn diagrams are a useful way to display joint distributions and to understand the relationships between conditional and marginal distributions.</p>
</body>
</html>
