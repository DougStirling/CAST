<html>
<head>
<title>17. Regression Inference</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 17 &nbsp; Regression Inference</h1>
<h2>17.1 &nbsp; Linear regression models</h2>
<h3>17.1.1 &nbsp; Interest in generalising from data</h3>
<p>Some bivariate data sets describe complete populations. Others are 'representative' of an underlying population or process.</p>
<h3>17.1.2 &nbsp; Distribution of Y for each X</h3>
<p>Bivariate data can be modelled by specifying a response distribution for each possible X.</p>
<h3>17.1.3 &nbsp; Normal linear model</h3>
<p>The response is often modelled with a normal distribution whose mean is a linear function of X and whose standard deviation is constant.</p>
<h3>17.1.4 &nbsp; Another way to describe the model</h3>
<p>A normal linear model can be described in terms of 'errors'. In samples from the model, approximately 95% of errors are within 2 standard deviations of zero, so about 95% of the points in a scatterplot are within this distance of the regression line.</p>
<h3>17.1.5 &nbsp; Model parameters</h3>
<p>The normal linear model has 3 unknown parameters. For many data sets, these parameters have meaningful interpretations.</p>
<h2>17.2 &nbsp; Estimating parameters</h2>
<h3>17.2.1 &nbsp; Estimating the slope and intercept</h3>
<p>A least squares line provides estimates of the linear model's slope and intercept. These estimates are random values — they vary from sample to sample.</p>
<h3>17.2.2 &nbsp; Estimating the error standard devn</h3>
<p>The third parameter of the normal linear model is the error standard deviation. It can be estimated using the residuals from the least squares line.</p>
<h3>17.2.3 &nbsp; Distn of least squares estimates</h3>
<p>The least squares estimate of the model's slope has a normal distribution that is centred on the true value.</p>
<h3>17.2.4 &nbsp; Standard error of least squares slope</h3>
<p>The distribution of the least squares slope may be estimated from a single data set.</p>
<h3>17.2.5 &nbsp; 95% confidence interval for slope</h3>
<p>A confidence interval for the model's slope can be obtained from its least squares estimate and its standard error.</p>
<h3>17.2.6 &nbsp; Properties of confidence interval</h3>
<p>Confidence intervals for the model's slope have the same properties as confidence intervals for population means or proportions.</p>
<h3>17.2.7 &nbsp; Influences on accuracy (opt) (Optional (not examined))</h3>
<p>The standard error of the least squares slope depends on the response standard deviation round the model line, the sample size and the standard deviation of X. Collecting data with a big spread of x-values gives more accurate estimates but there are disadvantages.</p>
<h2>17.3 &nbsp; Testing regression parameters</h2>
<h3>17.3.1 &nbsp; Importance of zero slope</h3>
<p>If the model's slope is zero, the response distribution does not depend on the explanatory variable. This special case is particularly meaningful in many studies.</p>
<h3>17.3.2 &nbsp; Testing whether slope is zero</h3>
<p>The p-value for testing whether a linear model's slope is zero is the probability that its least squares estimate is as far from zero as the recorded value.</p>
<h3>17.3.3 &nbsp; Strength of evidence and relationship</h3>
<p>It is important to distinguish the strength of a relationship (summarised by the correlation coefficient) and the strength of evidence for existence of a relationship (summarised by the p-value).</p>
<h3>17.3.4 &nbsp; Properties of p-values (opt) (Optional (not examined))</h3>
<p>As with other tests, all p-values between 0 and 1 are equally likely if the null hypothesis holds (model slope is zero), but p-values nearï¿½0 are more likely if the alternative hypothesis holds (model slope is non-zero).</p>
<h2>17.4 &nbsp; Predicting the response</h2>
<h3>17.4.1 &nbsp; Estimated response distn at X</h3>
<p>From estimates of the 3 linear model parameters, we can obtain an estimated response distribution at any x-value.</p>
<h3>17.4.2 &nbsp; Variability of estimate at X</h3>
<p>The predicted response at any X varies from sample to sample. The prediction is more variable at x-values far from the mean of the 'training' data.</p>
<h3>17.4.3 &nbsp; Estimating the mean vs prediction</h3>
<p>A distinction is made between estimating the mean response at X and predicting a new individual's response at X. Errors are larger (on average) when predicting a new individual's response.</p>
<h3>17.4.4 &nbsp; Confidence and prediction intervals</h3>
<p>A 95% confidence interval is used to estimate the mean response at X. A 95% prediction interval is similar, but gives a range of likely values for a new response value. The prediction interval is wider than the confidence interval.</p>
<h2>17.5 &nbsp; Exercises</h2>
<h3>17.5.1 &nbsp; Normal distribution of response at fixed X</h3>
<p>The exercise on this page gives a normal linear regression model and asks for the distribution of the response at a fixed value of the explanatory variable.</p>
<h3>17.5.2 &nbsp; Standard error of slope</h3>
<p>Any estimator's standard error gives information about its accuracy. The exercise on this page gives the standard error of a least squares line's slope and asks for a roughly calculated interval that is likely to include the underlying model's slope. (T values are not required in this exercise.)</p>
<h3>17.5.3 &nbsp; Confidence interval for slope</h3>
<p>In the two exercises on this page, confidence intervals for a regression model's slope should be calculated from the least squares slope and its standard error. The second exercise is a little harder -- it asks for various confidence levels.</p>
<h3>17.5.4 &nbsp; Influences on accuracy</h3>
<p>This exercise asks for the characteristics of a data set that will result in more accurate estimation of the linear model's slope.</p>
<h3>17.5.5 &nbsp; Test for zero slope</h3>
<p>This exercise gives the least squares slope and its standard error. The p-value for testing whether the regression slope is zero should be calculated and interpreted.</p>
</body>
</html>
