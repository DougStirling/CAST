<!DOCTYPE HTML>
<html>
<head>
  <title>7. Sampling and Variability</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="../../../structure/summaryStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/maths/mathStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/printStyles.css" type="text/css">
  <script src="../../../structure/videoControls/jquery.js"></script>
  <script src="../../../structure/maths/theorems.js"></script>
  <script src="../../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js"></script>
  <script src="../../../structure/printFixes.js"></script>
</head>

<body id="body" onLoad="showPrintDialog(true)">
<div id='overlay'>
	<div id='dialogWindow'>
		<div class='printDialog'>
			<script type='text/javascript'>
				document.write("<div class='heading'>" + top.document.title + "</div>");
				if (top.url != null) {
					document.write("<p class='text'>A version of this chapter has already been generated in PDF format and we recommend that it is used for printing. The button below will download and display it.</p>");
					document.write("<p><button onClick='top.showPdf()'>Show PDF version of chapter</button></p>");
					document.write("<p class='text'>However downloading could be slow depending on your internet connection. If this is a problem, click the button below to print the chapter without downloading (but perhaps not formatted as well as the PDF version).</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>If you are <strong>not</strong> using the PDF version, the best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
				else {
					document.write("<p class='text'>Click the button below to print this chapter.</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>The best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
			</script>
			
			<p class='text'>If you don't want to print now,</p>
			<p><button onClick='top.showPrintDialog(false)'>Browse formatted chapter</button></p>
		</div>
	</div>
</div>
<h1 class="chapterName">Chapter 7 &nbsp; Sampling and Variability</h1>
<h1 class="sectionName">7.1 &nbsp; Finite populations</h1>
<h2 class="pageName">7.1.1 &nbsp; Census or sample?</h2>

<p class="heading">Population and census</p>
	<p>We often want to find information about a particular group of individuals (people, 
		fields, trees, bottles of beer or some other collection of items). This target 
		group is called the <strong>population</strong>.</p>
	<p>Collecting measurements  from every item in the  population is called a <strong>census</strong>. A census is rarely feasible,  because of the  cost and time involved.</p>
	<p class="heading">Simple random sample</p>
	<p>We can usually obtain sufficiently accurate information by only 
	collecting information from a selection of units from the population &mdash; a <strong>sample</strong>. Although a sample gives less accurate information than a census, the savings in cost and time often outweigh this.</p>
	<p>The simplest way to select a representative sample  is  
		a <strong>simple random sample</strong>. In it, each unit has the same chance 
		of being selected and some random mechanism is used to determine whether any particular unit is 
		included in the sample.	</p>
	<p class="heading">Sampling from a population of <span class="red">values</span></p>
	<p>It is convenient 
		to define the population and sample to be sets of <strong>values</strong> (rather 
		than people or other items). This abstraction &mdash; a population of values and a 
		corresponding sample of values &mdash; can be applied to a wide range of applications.</p>
	<p class="eqn"><img src="../../../en/popSamp/images/s_popSamp.gif" width="550" height="267"></p>




<h2 class="pageName">7.1.2 &nbsp; Variability in a sample</h2>

<p class="heading notPrinted">Variability</p>
	<p>Sampling from a population results in sample-to-sample variability in the information that we obtain from the samples.</p>
	<p class="eqn"><img class="gif" src="../../../en/popSamp/images/samplingHistos.gif" width="428" height="336"></p>
	<p class="heading">Sample information about the population</p>
	<p>In practice, we only have a single sample and this provides  <strong>incomplete information about the population</strong>.</p>
	<p class="eqn"><img class="gif" src="../../../en/popSamp/images/samplingHistos2.gif" width="423" height="120"></p>
	<p class="heading">Effect of sample size</p>
	<p>Bigger samples mean more stable and reliable information about the underlying population.</p>




<h2 class="pageName">7.1.3 &nbsp; Sampling error</h2>

<p class=heading>Estimating means and proportions</p>
	<p>A random sample is often used to <strong>estimate</strong> some  numerical characteristic of the population, such as...</p>
	<ul>
		<li>The mean of some variable</li>
		<li>The proportion in some category</li>
	</ul>
	<p>The difference between an estimate and the population value being estimated is called 
		its <strong>sampling error</strong>. </p>
	<p class="eqn"><img src="../../../en/popSamp/images/s_propnMean.gif" width="494" height="394"></p>




<h2 class="pageName">7.1.4 &nbsp; Sampling error and sample size</h2>

<p class="heading notPrinted">Effect of sample size on sampling error</p>
	<p>The larger the sample size, the smaller the sampling error. However when the 
		population is large, sampling a small proportion of the population may still give 
		accurate estimates. </p>
	
<div class="centred"><div class="boxed">
<p>Sampling error depends much more strongly on the sample size than 
				on the proportion of the population that is sampled.</p>
</div></div>

	<p>For example, a sample of 10 from a population of 10,000 people will estimate 
		the proportion of males almost as accurately as a sample of size 10 from a population 
		of 100.</p>
	
<div class="centred"><div class="boxed">
<p>The cost savings from using a sample instead of a full census can 
				be huge.</p>
</div></div>

	



<h2 class="pageName">7.1.5 &nbsp; Sampling from finite populations ((optional))</h2>

<p class="heading">Different sampling schemes</p>
	<p><strong>Two 
			different</strong> ways to collect a random sample of <em>n</em> values from a finite population of size <em>N</em> are common. In both sampling schemes, each population value has the same chance of being in the sample.</p>
	<dl>
		<dt>Sampling with replacement (SWR)</dt>
		<dd>In SWR, the first selected value is <strong>returned to the population</strong> and the second value is randomly selected from all <i>N</i> population values. </dd>
		<dt>Sampling without replacement (SWOR)</dt>
		<dd>In SWOR, the first selected value is <strong>removed from the population</strong> and the second value is randomly selected from the remaining <i>N</i> - 1 population 
		values, etc.</dd>
	</dl>
	<p>Since a SWR may contain the same population value more than once, it covers less of the population than SWOR. SWOR therefore gives more accurate estimates of population characteristics.</p>
	<p class="heading">Large populations and/or small samples</p>
	<p>If the sample size, <i>n</i>, is much smaller than the population size, <i>N</i>, 
		there is little practical difference between SWR and SWOR &mdash; there would be little 
		chance of the same individual being picked twice in SWR.</p>




<h2 class="pageName">7.1.6 &nbsp; Selecting a random sample</h2>

<p class="heading">Selecting a sample manually (raffle tickets)</p>
	<ol>
		<li>Write the names (or other identification) of all population members on identical 
			pieces of paper,</li>
		<li>Mix them thoroughly in a box</li>
		<li>Select <em>n</em> pieces of paper (with or without replacement).</li>
	</ol>
	<p>This method is  rarely used in research applications.</p>
	<p class="heading">Selecting a  sample with random numbers</p>
	<p>To select a random sample without replacement using random numbers,</p>
	<ol>
		<li>Number all population members, starting from index 0.</li>
		<li>Generate a random index between 0 and the largest population index.</li>
		<li>If sampling <strong>without</strong> replacement and the generated index has already been selected, go back to step 2 and select another index.<br>
		</li>
		<li>Add the selected population member to the sample, then repeat steps 2. and 3. until a large enough sample has been selected.</li>
	</ol>
	<p class="heading">Random number between 0 and <em>k</em></p>
	<p>The easiest way to generate a random number between 0 and 357 is to use a spreadsheet such as Excel &mdash; it has a function designed for this purpose, &quot;=RANDBETWEEN(0, 357)&quot;. A computer-generated random value is strictly called a <em>pseudo-random</em> number.</p>
	<p>If a computer is not available, a sequence of random digits can be generated:</p>

<table border="0" cellpadding="0" cellspacing="0" style="padding-bottom:0px; margin-left:0px;"><tr>
<td>
	<ul>
		<li>Roll a 10-sided die several times.</li>
		<li>In a printed book of random digits, start at a random position in a random page, then use 
			a sequence of digits starting from there.</li>
	</ul></td>
<td style="padding-left:12px;"><img src="../../../en/popSamp/images/die.png" width="150" height="123"></td>
</tr></table>

	<p>A random number that is equally likely to have any value between 0 and 357 can be found by repeatedly generating 3-digit numbers (between 0 and 999) until a value between 0 and 357 is obtained.</p>




<h1 class="sectionName breakBefore">7.2 &nbsp; Abstract infinite populations</h1>
<h2 class="pageName">7.2.1 &nbsp; Data as representatives</h2>

<p class="heading notPrinted">Generalising from data</p>
	<p>Most data sets do <strong>not</strong> arise from randomly sampling individuals from a finite population. However we are still rarely interested in the specific individuals from whom data 
		were collected.</p>
	
<div class="centred"><div class="boxed">
<p>The recorded data are often 'representative' of something 
					more general.</p>
</div></div>

	<p>The main aim  is to <strong>generalise from the data</strong>.</p>
	<p class="eqn"><img src="../../../en/infPopn/images/dental.gif" width="559" height="209" class="summaryPict"></p>

  
  


<h2 class="pageName">7.2.2 &nbsp; Randomness of data</h2>

<p class=heading>Randomness of data</p>
	<p>Not only do we usually have little interest in the specific individuals from whom data were collected, but we must also acknowledge that our data would have been different if, by chance, we had selected different individuals or even made our measurements at a different time.</p>
	<p>We must acknowledge 
		this sample-to-sample variability when interpreting the data. The data are <strong>random</strong>.</p>
	
<div class="centred"><div class="boxed">
<p>All graphical and numerical summaries would 
					be different if we repeated data collection.</p>
</div></div>

	<p>This randomness in the data must be taken into account when we interpret graphical and numerical summaries. Our conclusions should not be dependent on features  that are specific to our particular data but would (probably) be different if the data were collected again.</p>
	<p>The more data that we collect, the more accurately our  data will reflect population characteristics, but randomness always exists.</p>




<h2 class="pageName">7.2.3 &nbsp; Model to explain randomness</h2>

<p class=heading>Data that are <span class="red">not</span> sampled from a finite population</p>
	<p>There is   no real finite population underlying most data sets   from which the values can be treated 
		as being sampled. The randomness in such data must be explained in a different way.</p>
	<p class=heading>Sampling from an abstract  population</p>
	<p>&quot;Random sampling from a population&quot; is  also used to explain variability even when there is no <strong>real</strong> finite population from which the data were sampled.</p>
	<p>We imagine an <strong>abstract</strong> population of <strong>all values that might have been obtained</strong> if the data collection had been repeated. We can then treat the observed data as a random sample from this abstract population.</p>
	<p>Defining such an underlying population therefore not only explains sample-to-sample variability but also gives us a focus for generalising from  our specific data.</p>




<h2 class="pageName">7.2.4 &nbsp; Infinite populations (distributions)</h2>

<p class=heading>Distributions</p>
	<p>When an abstract population is imagined to underlie a data set, it  often
contains an infinite number of values. For example, consider the lifetimes of
a sample of light bulbs. The population of <strong>possible</strong> failure
times contains <strong>all</strong> values greater than zero, and this includes
an infinite number of values. Moreover, some of these possible values will be
more likely than others.</p>
	<p>This kind of underlying population is called a <strong>distribution</strong>.</p>
	<p class=heading>Positions of cow in a field</p>
	<p>Consider the positions of a cow in a field at 6 different times where all locations are equally likely.</p>
	<p class="eqn"><img src="../../../en/infPopn/images/s_cows.gif" width="400" height="377"></p>
	<p>The population here contains all possible positions and is therefore infinite.</p>
	<p>The idea of a distribution also allows for some possible values to be more likely than others &mdash; the cow may be more likely to be in some particular part of the field.</p>


  


<h2 class="pageName">7.2.5 &nbsp; Information from a sample</h2>

<p class="heading">Sampling from a population</p>
	<p>Sampling from an underlying population (whether finite or infinite) gives us a mechanism to explain the randomness of data. The underlying population also gives us a <strong>focus</strong> for generalising from our sample data &mdash; the distribution of values in the population is fixed and does not depend on the specific sample data.</p>
	<p class="heading">Unknown population</p>
	<p>Unfortunately the population underlying most data sets is unknown and, in practice, we only have a <strong>single sample</strong>. However this single sample does throw light on the population distribution.</p>
	<p>The diagram below describes a sample from a categorical distribution. Although the underlying population is unknown, the sample proportion of successes, <em>p</em>, is an <strong>estimate</strong> of the unknown proportions of successes in the population (denoted by π).</p>
	<p class="eqn"><img src="../../../en/infPopn/images/s_unknownP.gif" width="326" height="301"></p>




<h1 class="sectionName breakBefore">7.3 &nbsp; Probability &amp; probability density</h1>
<h2 class="pageName">7.3.1 &nbsp; Finite populations</h2>

<p class="heading notPrinted">Probabilities for a finite population</p>
	<p>Random sampling from populations is described using <strong>probability</strong>. 
		If one value is sampled from a finite population of <em>N</em> distinct values, 
		we say that </p>
	<ul>
		<li>each population value has probability <sup>1</sup>/<sub><em>N</em></sub> of 
			being selected.</li>
		<li>there is zero probability of obtaining a value that is not in the population.</li>
	</ul>
	<p>Many populations contain values that occur more than once. When sampling from <strong>any</strong> population,</p>
	<div class="centred"><div class="boxed">
		<p>The probability that a single sampled value is either <em>x, <em>y</em>, ...</em> is the <strong>proportion 
			of population values that are either <em>x</em>, <em>y</em>, ... </strong>.</p>
	</div></div>
	<p>For numerical populations, the most useful form  of this result is:</p>
	<div class="centred"><div class="boxed">
		<p>Prob( <em>a</em> &lt; <em>X</em> &lt; <em>b</em> ) &nbsp; = &nbsp; propn of values between <em>a</em> and <em>b</em>.</p>
	</div></div>




<h2 class="pageName">7.3.2 &nbsp; Probabilities with infinite populations</h2>

<p class="heading">Probability and population proportion</p>
	<p>When sampling from any population, whether finite or infinite,</p>
	<div class="centred"><div class="boxed">
		<p>The probability of sampling any value or range of values equals the <strong>proportion of these values in the population</strong>.</p>
	</div></div>
	<p class="heading">Probability and long-term proportion</p>
	<p>An alternative but equivalent way to think about probability arises when we can imagine repeatedly selecting more and more values from the population (e.g. repeating an experiment). The probability of any value or range of values is the <strong>limiting proportion of these values as the sample size increases</strong>.</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_largeNos.gif" width="493" height="308"></p>
	<p>The equivalence of the two definitions is called the <strong>law of large numbers</strong>.</p>




<h2 class="pageName">7.3.3 &nbsp; Bar charts of discrete probabilities</h2>

<p class="heading">Describing   categorical and discrete populations</p>
	<p>Categorical and discrete samples can be described graphically with bar charts of the proportions for the distinct values. Since probabilities are defined to be population proportions, the underlying population can also be described by a bar chart.</p>
	<p class="eqn"><img class="gif" src="../../../en/probDensity/images/barChart.gif" width="206" height="194"></p>
	<p class="heading">Bar charts and the law of large numbers</p>
	<p>The law of large numbers states that sample proportions approach  the underlying probabilities as the sample size increases. This means that a sample bar chart will be close in shape to the unknown population bar chart if the sample size is big enough.</p>




<h2 class="pageName">7.3.4 &nbsp; Probability density functions</h2>

<p class="heading notPrinted">Histograms and probability density functions</p>
	<p>The situation is a little more complicated for continuous numerical populations and samples. A standard histogram could be used to describe the population in the same way that it might be used for a sample:</p>
	<p class="eqn"><img class="gif" src="../../../en/probDensity/images/histogram.gif" width="192" height="154"></p>
	<p>However with an infinite population, we can narrow the histogram classes beyond what would be reasonable for a finite sample. Indeed, class widths can be reduced indefinitely, resulting in a smooth histogram called a <strong>probability density function</strong>. This is often abbreviated to a <strong>pdf</strong>.</p>
	<p class="eqn"><img class="gif" src="../../../en/probDensity/images/pdf.gif" width="192" height="154"></p>
	<p>Probability density functions are still essentially histograms and share all properties of histograms.</p>




<h2 class="pageName">7.3.5 &nbsp; Normal distributions</h2>

<p class="heading">Shape of a probability density function</p>
	<p>A probability density function  is usually a fairly smooth curve, though a single sample histogram  provides limited information about its likely shape.</p>
	<p class=eqn><img src="../../../en/probDensity/images/unknownPopn.gif" alt="sample &mdash;> popn?" width="362" height="236" class="summaryPict"> </p>
	<p class="heading">Normal distributions</p>
	<p>One  flexible group of  continuous probability density functions is the family of <strong>normal 
		distributions</strong>. Normal distributions:</p>
	<ul>
		<li>Are symmetric.</li>
		<li>Have a parameter called µ that is the mean of the population.</li>
		<li> Have a parameter σ that is the population's standard deviation.
</li>
	</ul>
	<p>Changing the parameters µ and σ changes where the distribution is centred and its spread, but its shape remains otherwise the same.</p>
	<p>The parameters are often <strong>estimated</strong> from a sample. Details will be given later, but the resulting normal pdf will be close in shape to a histogram of the sample data.</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_bestFit.gif" width="404" height="202"></p>




<h2 class="pageName">7.3.6 &nbsp; Probability and area under the pdf</h2>

<p class=heading>Probabilities from a histogram</p>
	<p>In the histogram of any finite sample or population, the area above any class <a href="javascript:showNamedPage('density5')">is 
		the proportion of values in the class</a>.</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_histoArea.gif" width="455" height="254"></p>
	<p class="heading">Probabilities from a probability density function</p>
	<p>Since a probability density function (pdf)  is a type of histogram, it satisfies the same property.</p>
	<div class="centred"><div class="boxed">
		<p>The probability that a sampled value is within two values, P(<em>a</em>&nbsp;&lt;&nbsp;<em>X</em>&nbsp;&lt;&nbsp;<em>b</em>), equals the area under the pdf.</p>
	</div></div>
	<p>This is the key to interpreting pdfs.</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_pdfArea.gif" width="402" height="212"></p>




<h2 class="pageName">7.3.7 &nbsp; Properties of probability ((optional))</h2>

<p>For any events, <em>A</em> and <em>B</em>, the following properties always hold.</p>
	<p class="heading">Probabilities are always between 0 and 1</p>
	<div class="centred"><div class="boxed">
		<p>0  ≤  P(<em>A</em>)  ≤  1</p>
	</div></div>
	<p class="heading">Meaning of probabilities 0 and 1</p>
	<div class="centred"><div class="boxed">
		<p>If the event <em>A</em> cannot happen then P(<em>A</em>)  =  0</p>
		<p>If the event <em>A</em> is certain to happen then P(<em>A</em>)  =  1</p>
	</div></div>
	<p class="heading">Probability that an event does not happen</p>
	<div class="centred"><div class="boxed">
		<p>P(<em>A</em> does not happen)  =  1 - P(<em>A</em>)</p>
	</div></div>
	<p class="heading">Addition law</p>
	<p>When two events cannot happen together, they are said to be <strong>mutually 
		exclusive</strong>. If <em>A</em> and <em>B</em> are mutually exclusive,</p>
	<div class="centred"><div class="boxed">
		<p>P(<em>A</em> or <em>B</em>)  =  P(<em>A</em>) + P(<em>B</em>)</p>
	</div></div>
	<p>If the events <em>A</em> and <em>B</em> are <strong>not</strong> mutually exclusive,</p>
	<div class="centred"><div class="boxed">
		<p>P(<em>A</em> or <em>B</em>)  &lt;  P(<em>A</em>) + P(<em>B</em>)</p>
	</div></div>
	<p class="heading">Independence</p>
	<p>When sampling  <strong>with replacement</strong> from a finite population, the choice of each value does not depend on the values previously 
		selected. The successive values are then called <strong>independent</strong>. This also holds when sampling from an infinite population (distribution).</p>
	<p>On the other hand, if sampling without replacement from a finite population, 
		successive sample values are <strong>not</strong> independent since the second value 
		selected cannot be the same as the first value, so knowing the first value affects 
		the probabilities when the second value is selected.</p>




<h1 class="sectionName breakBefore">7.4 &nbsp; Simulation (optional)</h1>
<h2 class="pageName">7.4.1 &nbsp; Probability models and simulation</h2>

<p>Probability describes situations where a random sample is selected from a population. It  is also used to model a 
	variety of <strong>other</strong> situations involving randomness.</p>
<p class=heading>Tennis match</p>
	<p>A simple model for a tennis match between two players, A and B, assumes that:</p>
	<div class="centred"><div class="boxed">
		<ul>
			<li>Probability of A winning  serve = π<sub>1</sub></li>
			<li>Probability of B winning  serve = π<sub>2</sub></li>
			<li>The results of successive points are independent</li>
			<li>The standard years of tennis</li>
		</ul>
	</div></div>
	<p>A more complex model might introduce more parameters to relax the assumption of independence.</p>
	<p class=heading>Simulation</p>
	<p>For any values of  π<sub>1</sub> and  π<sub>2</sub>, we could randomly generate the results of successive points until a match was complete.</p>
	<p>This generates an <strong>instance</strong> of the model and is called a <strong>simulation</strong>.</p>
	




<h2 class="pageName">7.4.2 &nbsp; Simulation: Will the best team win?</h2>

<p class="heading notPrinted">Repetitions of  a simulation</p>
	<p>Repeating a simulation and observing the 
		variability in the results can give insight into the randomness of the system's 
		behaviour.</p>
	<p class=heading>Model for sport league</p>
	<p>Consider a sports league of 10 teams in which each team plays each other twice and:</p>

<div class="centred"><table border="0" class="centred" cellpadding="2" cellspacing="0">
  <tr>
    <td>&nbsp;Points from a match =&nbsp;&nbsp;&nbsp;</td>
    <td style="border-left:1px solid #000000">3 &nbsp;if team wins<br>&nbsp;1 &nbsp;if team draws<br>0 &nbsp;if team loses</td></tr>
</table></div>

	<p>We will model the league with a simple model for the results of individual matches. In it, team A has over twice the probability of winning than losing, but all other teams are equally matched.</p>
	<ul>
		<li>The results of all matches are independent</li>
		<li>P(draw) = 0.2 in all matches</li>
		<li>P(team A wins its matches) = 0.55 and P(A loses) = 0.25</li>
		<li>All other teams are equally matched with P(win) = P(lose) = 0.4.</li>
	</ul>
	<p class=heading>Simulation</p>
	<p>This model can be used to randomly generate the results of all 90 matches in the league.</p>
	<p class=eqn><img src="../../../en/probSim/images/s_league1.gif" width="455" height="360"></p>
	<p>Repeating the simulation 100 times gives the following results:</p>
	<p class=eqn><img src="../../../en/probSim/images/s_league2.gif" width="421" height="312"></p>
	<p>Despite team A being so much better than the other teams, the simulation shows that it has little more than 50% chance of ending the season on top of the league.</p>




<h2 class="pageName">7.4.3 &nbsp; Is there evidence of skill in a league?</h2>

<p class=heading>English Premier Soccer League in 2008/9</p>
	<p>The table below shows the points gained by all teams in the English Premier 
		Soccer League at the end of the 2008/9 season.</p>

		<div class="centred"><table width=260 border=0 cellspacing="0" class="centred">
			<tr>
				<td width=30>&nbsp;</td>
				<td width=200><strong>Team</strong></td>
				<td width=30><strong>Pts</strong></td>
			</tr>
			<tr>
				<td style="border-top:1px solid #999999;">1</td>
				<td  style="border-top:1px solid #999999;"bgcolor="white">Manchester United</td>
				<td  style="border-top:1px solid #999999;"bgcolor="white">90</td>
			</tr>
			<tr>
				<td>2</td>
				<td bgcolor="white">Liverpool</td>
				<td bgcolor="white">86</td>
			</tr>
			<tr>
				<td>3</td>
				<td bgcolor="white">Chelsea</td>
				<td bgcolor="white">83</td>
			</tr>
			<tr>
				<td>4</td>
				<td bgcolor="white">Arsenal</td>
				<td bgcolor="white">72</td>
			</tr>
			<tr>
				<td>5</td>
				<td bgcolor="white">Everton</td>
				<td bgcolor="white">63</td>
			</tr>
			<tr>
				<td>6</td>
				<td bgcolor="white">Aston Villa</td>
				<td bgcolor="white">62</td>
			</tr>
			<tr>
				<td>7</td>
				<td bgcolor="white">Fulham</td>
				<td bgcolor="white">53</td>
			</tr>
			<tr>
				<td>8</td>
				<td bgcolor="white">Tottenham Hotspur</td>
				<td bgcolor="white">51</td>
			</tr>
			<tr>
				<td>9</td>
				<td bgcolor="white">West Ham United</td>
				<td bgcolor="white">51</td>
			</tr>
			<tr>
				<td>10</td>
				<td bgcolor="white">Manchester City</td>
				<td bgcolor="white">50</td>
			</tr>
			<tr>
				<td>11</td>
				<td bgcolor="white">Wigan Athletic</td>
				<td bgcolor="white">45</td>
			</tr>
			<tr>
				<td>12</td>
				<td bgcolor="white">Stoke City</td>
				<td bgcolor="white">45</td>
			</tr>
			<tr>
				<td>13</td>
				<td bgcolor="white">Bolton Wanderers</td>
				<td bgcolor="white">41</td>
			</tr>
			<tr>
				<td>14</td>
				<td bgcolor="white">Portsmouth</td>
				<td bgcolor="white">41</td>
			</tr>
			<tr>
				<td>15</td>
				<td bgcolor="white">Blackburn Rovers</td>
				<td bgcolor="white">41</td>
			</tr>
			<tr>
				<td>16</td>
				<td bgcolor="white">Sunderland</td>
				<td bgcolor="white">36</td>
			</tr>
			<tr>
				<td>17</td>
				<td bgcolor="white">Hull City</td>
				<td bgcolor="white">35</td>
			</tr>
			<tr>
				<td>18</td>
				<td bgcolor="white">Newcastle United</td>
				<td bgcolor="white">34</td>
			</tr>
			<tr>
				<td>19</td>
				<td bgcolor="white">Middlesburgh</td>
				<td bgcolor="white">32</td>
			</tr>
			<tr>
				<td style="border-bottom:1px solid #999999;">20</td>
				<td style="border-bottom:1px solid #999999;" bgcolor="white">West Bromwich Albion</td>
				<td style="border-bottom:1px solid #999999;" bgcolor="white">32</td>
			</tr>
		</table></div>

	<p class="heading">Evidence of skill? </p>
	<p>A quarter of the matches in 2008/9 were draws, so we will conduct a simulation with a model in which all teams are equally matched and:</p>
	<ul>
		<li>P(draw)  =  0.25</li>
		<li>P(win)  =  P(lose)  =  0.375</li>
	</ul>
	<p>From each simulated league, we will summarise the spread of points at the end of the season using both their range and their standard deviation. After 100 simulated leagues, these measures of spread are shown below.</p>
	<p class="eqn"><img src="../../../en/probSim/images/s_leagueSpread.gif" width="476" height="352"></p>
	<p>The actual spread of points in the 2008/9 league was much higher than those that appeared in the simulations with equally matched teams, indicating that there was indeed a difference between the skill levels of the best and worst teams in the league.</p>
	



<h2 class="pageName">7.4.4 &nbsp; Assessing unusual features in data</h2>

<p class="heading notPrinted">Interpreting a graphical summary of a sample</p>
	<p>Simulations can also help us to assess features such as outliers, clusters or skewness in a data set 
		by examining how often they appear in random samples from a population <strong>without</strong> such features.</p>
	<p>In particular, we can examine variability in samples from a normal 
		distribution that closely matches the shape of the data set. </p>
	<p class="eqn"><img src="../../../en/probSim/images/s_skewnessSim.gif" width="381" height="305"></p>
	<p>The amount of skewness  in the the actual data (top) is rarely seen in simulated normal samples (such as that shown above). This informally suggests that the the population underlying the data really is skew and not symmetric.</p>




<h2 class="pageName">7.4.5 &nbsp; Random numbers ((advanced))</h2>

<p class="heading notPrinted">Random values</p>
	<p>Simulations are conducted by generating random 
		values from the probability distributions in the model.</p>
	
<div class="centred"><div class="boxed">
<p>A computer program should normally be used to generate 
				random values. The program Excel contains functions that can be used.</p>
</div></div>

	<p>Generating categorical and numerical values 
		is usually based on random values that are equally likely to take any value between 0 and 1. Such a value is said to come from 
		a rectangular (or uniform) distribution between 0 and 1 and has the probability 
		density function shown below.</p>
	<p class="eqn"><img class="gif" src="../../../en/probSim/images/uniform01.gif" width="185" height="169"></p>
	<p>A value can be generated from a rectangular distribution with the Excel function &quot;=RAND()&quot; or, by hand, by  generating a sequence of
	random digits (e.g. by rolling a 10-sided die).</p>




<h2 class="pageName">7.4.6 &nbsp; Generating categorical values (advanced) ((advanced))</h2>

<p class="heading notPrinted">Generating a categorical value</p>
	<p>A random category can be generated from a rectangularly distributed random value, <span class="em black">r</span> .</p>
	<p>If P(<em>success</em>)  is denoted by the symbol <span class="black">π</span>, 
		then a <em>success</em> will be generated if <span class="em black">r</span>  is less than <span class="black">π</span>. This can be generalised as illustrated in the diagram below:</p>
	<p class="eqn"><img src="../../../en/probSim/images/s_randomCat.gif" width="340" height="274"></p>




<h2 class="pageName">7.4.7 &nbsp; Generating numerical values ((advanced))</h2>

<p class="heading notPrinted">Generating a continuous numerical value</p>
	<p>There are several algorithm that can efficiently generate random values from continuous distributions. For example, the Excel function &quot;=NORMSINV(RAND())&quot; generates a random value from a normal distribution with µ = 0 and σ = 1.</p>
	<div class="centred"><div class="boxed"><p>The following method is simple to explain but is not recommended for general use.</p></div></div>
	<p>Consider the diagram below which encloses the distribution's probability density 
		function with a rectangle.</p>
	<p class="eqn"><img class="gif" src="../../../en/probSim/images/envelopeGenerator.gif" width="246" height="173"></p>
	<p>A random position within the rectangle is generated with a random rectangular horizontal and vertical positions. If it lies within the density function, the x-coordinate is the generated value. Otherwise more positions within the rectangle are generated until a point is found within the density function.</p>
	<p class="eqn"><img src="../../../en/probSim/images/s_envelopeReject.gif" width="413" height="234"></p>
	<p class="eqn"><img src="../../../en/probSim/images/s_envelopeAccept.gif" width="413" height="234"></p>





<h1 class="sectionName breakBefore">7.5 &nbsp; Distribution of sample mean</h1>
<h2 class="pageName">7.5.1 &nbsp; Parameters and statistics</h2>

<p class="heading">Sampling mechanism</p>
	<p>The mechanism of sampling from a population explains randomness in data.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/s_samplingHistos.gif" width="223" height="184"></p>
	<p>In practice, we must use  a <strong>single</strong> sample to find information about the population.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/s_oneHisto.gif" width="221" height="70"></p>
	<p class="heading">Parameters and statistics</p>
	<p>We usually focus attention on a small number of numerical characteristics.</p>
	<ul>
		<li>Populations are summarised by values called <strong> parameters</strong>.</li>
		<li>The corresponding sample values are <strong>sample statistics</strong> and provide <strong>estimates</strong> of the parameters.</li>
	</ul>
	<p class="eqn"><img src="../../../en/randomMean/images/s_oneMean.gif" width="221" height="70"></p>
	<p class="heading">Variability of sample statistics</p>
	<p>The variability in random samples also implies sample-to-sample variability in sample statistics.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/s_samplingMeans.gif" width="223" height="183"></p>




<h2 class="pageName">7.5.2 &nbsp; Variability of sample mean</h2>

<p class="heading notPrinted">Distribution of the sample mean</p>
	<p>The mean of a random sample of <em>n</em> values is a random quantity. Its
distribution  is centred on the population mean but its spread is lower then
that of the population distribution.</p>


<h2 class="pageName">7.5.3 &nbsp; Standard devn of sample mean</h2>

<p class="heading notPrinted">Centre and spread of the sample mean's distribution</p>
	<ul>
		<li>The sample mean has a distribution that is centred on the 
			population mean.</li>
		<li>Its variability decreases as the sample size increases. </li>
	</ul>
<p>We can be more precise. If the population has mean µ and standard deviation σ, then  the   mean of a sample of <em>n</em> values, <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline">, 
		has a distribution with mean and standard deviation:</p>
<div class="centred">
	<table border="0" cellpadding="0" cellspacing="0" class="centred">
		<tr>
			<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
			<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</td>
		</tr>
	</table>
</div>
<div class="centred">
	<table border="0" cellpadding="0" cellspacing="0" class="centred">
		<tr>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
			<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
		</tr>
	</table>
</div>


<h2 class="pageName">7.5.4 &nbsp; Means from normal populations</h2>

<p class="heading">Shape of the mean's distribution</p>
	<p><strong>Whatever</strong> the shape of the population distribution,</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</span> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
		</table>
	</div>
	<p>However skewness in the population distribution 
		leads to some <strong>skewness in the distribution of the mean</strong>.</p>
	<p class="heading">Samples from normal populations</p>
	<p>When the population distribution is normal, the sample mean 
	also has a normal distribution.</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></td>
				<td valign="middle">&nbsp; ~ &nbsp;<font face="Arial, Helvetica, sans-serif">normal</font> (μ , &nbsp;</td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
				<td valign="middle">)</td>
			</tr>
		</table>
	</div>
	<br>
	<p class=eqn><img src="../../../en/randomMean/images/s_normalMean.gif" width="428" height="344"></p>




<h2 class="pageName">7.5.5 &nbsp; Large-sample normality of means</h2>

<p class="heading">Means from non-normal populations</p>
	<p>Irrespective of the shape of the population distribution,</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</span> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
		</table>
	</div>
	<p>If the population is not a normal distribution, the sample mean does not 
		have a normal distribution. However  the <strong>Central Limit 
		Theorem</strong> states that...</p>
<div class="centred"><div class="boxed"><p>For most non-normal population distributions, the distribution of 
				the sample mean becomes close to normal when the sample size increases.</p></div></div>
<p class="eqn"><img src="../../../en/randomMean/images/s_gammaMean.gif" width="428" height="344"></p>




<h2 class="pageName">7.5.6 &nbsp; Distribution of mean from a sample</h2>

<p class="heading">Need for multiple values to assess variability</p>
	<p>We usually need to make two or more measurements of a variable 
		to get any information about its variability. A single value contains no information about the quantity's variability.</p>
<p class="heading">Achieving the impossible?</p>
<p>Fortunately, <strong>we do not need multiple sample</strong> means to assess the variability of a sample mean. Its distribution can be estimated from a <strong>single sample</strong> using </p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</td>
			</tr>
		</table>
	</div>
<div class="centred">
	<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
	</table>
	</div>
	<p>The distribution of the mean can be approximated with a normal distribution with this mean and standard deviation, if we replace µ 
	and σ with <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"> and <em>s</em>.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/pagesPrinted.gif" width="540" height="469" class="summaryPict"></p>




<h2 class="pageName">7.5.7 &nbsp; Requirement of independence</h2>

<p class="heading">Independent random samples</p>
	<p>The formula for the standard deviation of a sample mean,</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
		</table>
	</div>
<p>is only accurate if the sample values are <strong>independent</strong>.</p>
<p class="heading">Dependent random samples</p>
	<p>When  sample values are correlated with each other, they are said to be <strong>dependent</strong> and the formula</p>
	<p class="eqn"><img class="gif" src="../../../en/randomMean/images/estSDMean.gif" width="64" height="32"></p>
	<p> can badly underestimate the variability (and hence accuracy) of the sample 
		mean of dependent random samples.</p>
	<p>Always check that a random sample is independently selected from the whole 
		population before using the formula for the standard deviation of the sample mean.</p>




<h2 class="pageName">7.5.8 &nbsp; Sampling from finite populations ((advanced))</h2>

<p class="heading">Sampling with replacement from finite populations</p>
	<p>When  a random sample is selected <strong>with replacement</strong> from a finite 
		population, the sample values are independent and the standard 
		deviation of the sample mean is again</p>

<div class="centred"><table border="0" cellpadding="0" cellspacing="0" class="centred">
		<tr>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
			<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </span></td>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
		</tr>
	</table></div>

	<p>Note however that the population  standard deviation, σ, 
		uses divisor <em>N</em>, the number of values in the population, rather than (<em>N</em>&nbsp;-&nbsp;1).	</p>
	<p class=eqn><img class="gif" src="../../../en/randomMean/images/popnSdFinite.gif" width="114" height="49"></p>
<p class="heading">Sampling without replacement from finite populations</p>
	<p>When a sample is selected <strong>without replacement</strong>, successive values are no longer independent &mdash; if a large value is selected, it cannot be selected again, so the next value will tend 
	to be lower.</p>
	<p>For sampling without replacement, a different formula should be used for the standard deviation of the sample mean:</p>
	<p class=eqn><img class="gif" src="../../../en/randomMean/images/sdMeanSWOR.gif" width="138" height="45"></p>
	<p>The quantity (<em>N </em>- <em>n</em>) / (<em>N</em> - 1) is called the <strong>finite 
		population correction factor</strong>. It can usually be ignored if only a small fraction of the population is sampled (say under 5%).</p>




<h1 class="sectionName breakBefore">7.6 &nbsp; Normal distributions</h1>
<h2 class="pageName">7.6.1 &nbsp; Importance of normal distributions</h2>

<p class="heading">Normal distribution parameters</p>
	<p>The <a href="javascript:showNamedPage('probDensity5')">family of 
		normal distributions</a> consists of symmetric bell-shaped distributions that 
		are defined by two parameters, µ 
		and σ, the distribution's mean and standard deviation.</p>
	<p class="heading">Normal distributions as models for data</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_bestFit.gif" width="404" height="202"></p>
	<p>The sample data rarely gives enough information for us to be <strong>sure</strong> that the underlying population is  normal, but a normal model is often used unless there is <strong>obvious</strong> non-normality in the data.</p>
<p>Even if the sample data are obviously skew, a normal distribution may be a reasonable
model for a nonlinear transformation of the values (e.g. a log transformation).</p>
<p class="heading">Distribution of summary statistics</p>
	<p>A more important reason for the importance of the normal distribution in statistics 
		is that...</p>
	
<div class="centred"><div class="boxed">
<p>Many summary statistics have normal distributions (at least approximately).</p>
</div></div>

	<p>The Central Limit Theorem shows that the mean of a random sample has a distribution that is close to normal when the sample size is moderate or large, <strong>irrespective 
	of the shape of the distribution of the individual values</strong>. The following are also 
	approximately normal when the sample size is moderate or large...</p>
	<ul>
		<li>A sample proportion</li>
		<li>The slope and intercept of a least squares line</li>
		<li>The difference between the means of two samples</li>
	<li>The difference between two proportions</li></ul>




<h2 class="pageName">7.6.2 &nbsp; Shape of normal distributions</h2>

<p class="heading notPrinted">Effect of normal parameters on distribution</p>
	<p>Distributions from the normal family have different locations and spreads, 
		but other aspects of their shape are the same. Indeed, if the scales on the horizontal 
		and vertical axes are suitably chosen, ...</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_normalAxes.gif" width="514" height="295"></p>





<h2 class="pageName">7.6.3 &nbsp; Sketching a normal distribution</h2>

<p class="heading">A common diagram for <span class="red">all</span> normal 
		distributions</p>
	<p>All normal distributions have basically the same shape.</p>
	<ul>
		<li>The distribution almost disappears at 3σ 
			from µ</li>
		<li>The probability (area) further than 2σ 
			from µ 
			is small &mdash; only about <sup>1</sup>/<sub>20</sub> of the total area.</li>
	</ul>
	<p>This should allow you to sketch a normal distribution, given any values of µ and σ.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_sketch.gif" width="505" height="237"></p>




<h2 class="pageName">7.6.4 &nbsp; Some normal probabilities</h2>

<p class="heading notPrinted">Some probabilities for normal distributions</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_empiricalRule.gif" width="499" height="553"></p>
	<p>A more precise version of the middle probability is</p>
	<ul>
		<li>P&nbsp;(within 1.96σ 
			of µ) 
			&nbsp;=&nbsp; 0.95</li>
	</ul>
	<p class="heading">70-95-100 rule of thumb and the normal distribution</p>
	<p>These probabilities are the basis of the <a href="javascript:showNamedPage('centerSpread7')">70-95-100 
		rule of thumb</a> for 
		'bell-shaped' data sets.</p>
	<ul>
		<li>About 70% of values are within <em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
		<li>About 95% of values are within 2<em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
		<li>Almost all values are within 3<em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
	</ul>




<h2 class="pageName">7.6.5 &nbsp; Z-scores</h2>

<p class="heading">Standard deviations from the mean</p>
	<p>Any x-value can be expressed as a number of standard deviations from the mean &mdash; its <strong>z-score</strong>.</p>
	<p class=eqn><img src="../../../en/normalDistn/images/s_zScore.gif" width="498" height="145"></p>
	<p>or equivalently, </p>
	<p class=eqn><span class="black"><em>x</em> &nbsp;=&nbsp; &mu; &nbsp;+&nbsp; <em>z</em> &times; &sigma;</span> </p>
	<p class="heading">Probabilities and z-scores</p>
	<p>Any  probability (area) relating to a normally distributed random variable, <em>X</em>, can be expressed in terms of z-scores:</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_zProb.gif" width="502" height="298"></p>
	<p>Note in particular that:</p>
	<ul>
		<li>P(-1 &lt; z &lt; +1) &nbsp;is approx&nbsp;0.68</li>
		<li>P(-2 &lt; <em> z </em> &lt; +2) &nbsp;is approx&nbsp;0.95</li>
		<li>P(-3 &lt; <em>z</em> &lt; +3) &nbsp;is approx&nbsp;0.997</li>
	</ul>




<h2 class="pageName">7.6.6 &nbsp; Finding normal probabilities</h2>

<p class="heading">Distribution of z-scores</p>
	<p>Calculating a z-score from a value, <em>x</em>, is  called <strong>standardising</strong> it.</p>
	<div class="centred">
		<table border="0" cellspacing="0" cellpadding="10" class="centred">
			<tr>
				<th style="margin:0px; padding:0px" valign="middle"><span class="black">standardised value,</span>&nbsp;&nbsp;&nbsp;</th>
				<td style="margin:0px; padding:0px" valign="middle"><img class="gif" src="../../../en/normalDistn/images/standardiseEqn2.gif" width="103" height="31"></td>
			</tr>
		</table>
	</div>
<p>If <em>X</em> has a normal distribution, then <i>Z</i> has a <strong>standard 
		normal distribution</strong> with mean µ&nbsp;=&nbsp;0 
	and standard deviation σ&nbsp;=&nbsp;1. </p>
	<p class="heading">Probabilities for the standard normal distribution</p>
	<p>After translating a probability about <em>X</em> into one about a z-score, it is easier to evaluate it.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_xProb.gif" width="509" height="436"></p>
	<p>Areas under the standard normal curve can be evaluated in Excel and most statistical programs. Statistical tables can also be used (see later).</p>




<h2 class="pageName">7.6.7 &nbsp; Other probabilities</h2>

<p class="heading">Evaluating other probabilities</p>
	<p>Other probabilities about normal distributions can be found using the following properties:</p>
	<ul>
		<li>The total area under a normal p.d.f. is 1</li>
		<li>The probability of a value in any interval is the area under the normal p.d.f. above this interval.</li>
	</ul>
	<p class="heading">Probability of higher value</p>
	<p class=eqn><img src="../../../en/normalDistn/images/normalAreas.gif" width="550" height="115"></p>
	<p class="heading">Probability of value between two others</p>
	<p class=eqn><img src="../../../en/normalDistn/images/normalAreas2.gif" width="506" height="241"></p>
	<p>In both cases, the conversion can be done either before or after translating the 
		required probability from x-values to z-scores.</p>




<h2 class="pageName">7.6.8 &nbsp; Normal tables</h2>

<p class="heading notPrinted">Standard normal probabilities without a computer</p>
	<p>Probabilities about z-scores can be found <strong>without a computer</strong>. Most 
		introductory statistics textbooks contain printed tables with left-tail probabilities 
	for the standard normal distribution. </p>
	<p class=eqn><img src="../../../en/normalDistn/images/table.gif" width="482" height="176" alt="pdf = table"> </p>
	<p>These tables can be used after the required probability has been translated 
		into a problem relating to the standard normal distribution.</p>




<h2 class="pageName">7.6.9 &nbsp; Finding normal quantiles</h2>

<p class="heading">Finding an x-value from a probability</p>
	<dl>
		<dt>Quartiles</dt>
		<dd>The <strong>quartiles</strong> of a  distribution are the three values such that there is probability <sup>1</sup>/<sub>4</sub>, <sup>2</sup>/<sub>4</sub> and <sup>3</sup>/<sub>4</sub> of being lower.</dd>
		<dt>Percentiles</dt>
		<dd>The <em>r</em>'th percentile of the distribution is the value with probability <sup><em>r</em></sup>/<sub>100</sub> of being lower.</dd>
		<dt>Quantiles</dt>
		<dd>These are generalised by the term <strong>quantile</strong>. The value with probability <em>p</em> of being lower is called the quantile of the distribution corresponding to probability <em>p</em>.</dd>
	</dl>
	<p class="heading">Finding quantiles</p>
	<p>To find the x-value for which there is probability <em>p</em> of a normal distribution being lower,</p>
	<ul>
		<li>Find the z-score for which there is probability <em>p</em> of being less.</li>
		<li>Translate the z-score to an x-value</li>
	</ul>
	<p>The first step of this process can be done with Excel (or other statistical software) or statistical tables can be used. For example, the 
		diagram below shows how to find the z-score such that there is probability 
		0.9 of being less.</p>
	<p class=eqn><img src="../../../en/normalDistn/images/invTable.gif" width="482" height="176" class="summaryPict"> </p>
	<p>Translating from a z-score to the corresponding x-value is done with the 
		formula,</p>
	<p class=eqn><span class="black"><em>x</em> &nbsp;=&nbsp; &mu; &nbsp;+&nbsp; <em>z</em> &sigma;</span> </p>




<h2 class="pageName">7.6.10 &nbsp; Normal probability plots ((advanced))</h2>

<p class="heading">Do the data come from a normal distribution?</p>
	<p>A histogram  may indicate that a sample is unlikely to come from a normal distribution, but a <strong>normal probability plot</strong> can indicate more subtle departures from a normal distribution.</p>
	<ol>
		<li>Sort the data values into order, <em>x</em><sub>(1)</sub>&nbsp;&lt;&nbsp;<em>x</em><sub>(2)</sub>&nbsp;&lt;&nbsp;...&nbsp;&lt;&nbsp;<em>x</em><sub>(<em>n</em>)</sub></li>
		<li>Find ordered values that are spaced out as you would <strong>expect</strong> from a normal distribution, <em>q</em><sub>1</sub>&nbsp;&lt;&nbsp;<em>q</em><sub>2</sub>&nbsp;&lt;&nbsp;...&nbsp;&lt;&nbsp;<em>q</em><sub><em>n</em></sub>. 
			The quantiles of the normal distribution corresponding to probabilities <sup>1</sup>/<sub>(<em>n</em>+1)</sub>, <sup>2</sup>/<sub>(<em>n</em>+1)</sub>, ..., <sup><em>n</em></sup>/<sub>(<em>n</em>+1)</sub> are commonly used.</li>
		<li>Plot <em>x</em><sub>(<em>i</em>)</sub> against <em>q</em><sub><em>i</em></sub></li>
	</ol>
	<p>If the data set is from a normal distribution, the data should be spaced out in a similar way to the normal quantiles, so the crosses in the normal probability 
		plot should lie close to a straight line.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_probPlot.gif" width="359" height="357"></p>
	<p class="heading">How much curvature is needed to suggest non-normality?</p>
	<p>This is a difficult question to answer and we will not address it here.</p>





<h1 class="sectionName breakBefore">7.7 &nbsp; Distribution of sample proportion</h1>
<h2 class="pageName">7.7.1 &nbsp; Proportion and probability</h2>

<p class="heading">A sample proportion has a distribution</p>
	<p>If a categorical data set is modelled as a random sample from a categorical 
		population, the sample proportions   must be treated as 
		random quantities &mdash; they vary from sample to sample.</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_samplingPropns.gif" width="446" height="365"></p>
	<p>The population proportion in a category  is called 
		its <strong>probability</strong>, and is often denoted by π. 
		The corresponding sample proportion is usually denoted by <em>p</em>. </p>
	<div class="centred">
		<div class="centred">
			<table class="centred" border="0" cellspacing="0" cellpadding="4">
				<tr>
					<th>&nbsp; </th>
					<th align="CENTER">Sample Statistic</th>
					<th align="CENTER">Population Parameter</th>
				</tr>
				<tr>
					<th align="left">Mean</th>
					<td align="CENTER" style="border-top:1px solid #999999;"><img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></td>
					<td align="CENTER" style="border-top:1px solid #999999;">µ</td>
				</tr>
				<tr>
					<th align="left">Standard deviation</th>
					<td align="CENTER" style="border-top:1px solid #999999;"><em>s</em></td>
					<td align="CENTER" style="border-top:1px solid #999999;">σ</td>
				</tr>
				<tr>
					<th align="left">Proportion/probability</th>
					<td align="CENTER" style="border-top:1px solid #999999; border-bottom:1px solid #999999;"><em>p</em></td>
					<td align="CENTER" style="border-top:1px solid #999999; border-bottom:1px solid #999999;">π</td>
				</tr>
			</table>
		</div>
	</div>
<p>In practice, we only have a single sample and must use it to get information about the underlying population.</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_onePropn.gif" width="442" height="140"></p>




<h2 class="pageName">7.7.2 &nbsp; Properties of counts and proportions</h2>

<p class="heading">Properties of a sample proportion</p>
	<p>A sample proportion  from a random sample
	of size <i>n</i> has a distribution that ... </p>
	<ul>
		<li>is centred on the underlying population probability,
			π, and</li>
		<li>has a spread that decreases as the sample size <i>n</i> increases.</li>
	</ul>
	<p class="heading">Count and proportion of successes</p>
	<p>Although the sample proportion in a category, <span class="em black">p</span> , 
		is a good summary statistic, the raw count of sample values in the category, <span class="em black">x</span> <span class="black">&nbsp;=&nbsp;<em>np</em></span>, 
		contains equivalent information and is often easier to use. They have distributions with the same shape (other than the scaling constant <i><span class="black">n</span></i>).</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_propnDist.gif" width="550" height="286"></p>




<h2 class="pageName">7.7.3 &nbsp; Binomial distribution</h2>

<p class="heading">General notation</p>
	<p>In a categorical population, we choose one category of interest and call it <em><strong>success</strong></em>; all other categories are collectively called <em><strong>failures</strong></em>. The population proportion of successes is denoted by <span class="black">π</span>.</p>
	<p>When a random sample of <i><span class="black">n</span></i> values is selected, 
		we denote the number of successes by <span class="em black">x</span>  and the proportion of successes by <span class="em black">p</span> <span class="black">&nbsp;=&nbsp;<em><span style="vertical-align:20%">x</span></em>/<em><span style="vertical-align:-20%">n</span></em></span>. </p>
	<p class="heading">Distribution of a sample proportion</p>
	<p>The number of successes, <span class="em black">x</span> , 
		has a 'standard' discrete distribution called a <strong>binomial distribution</strong> which has two parameters, <span class="em black">n</span>  and <span class="black">π</span>.</p>
	<p>In practical applications, <span class="em black">n</span>  is a known constant, but <span class="black">π</span> may be unknown. The sample proportion, <span class="em black">p</span> , 
		has a distribution with the same shape, but is scaled by <span class="em black">n</span> .</p>
	<ul>
		<li>The distribution of <em>p</em> is centred on π.</li>
		<li>The spread of the distribution of <em>p</em> decreases as <em>n</em> increases.</li>
		<li>The distribution is symmetric when π 
			= 0.5, but becomes more skew as π 
			approaches 0 or 1.</li>
	</ul>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_binomials.gif" width="466" height="515"></p>




<h2 class="pageName">7.7.4 &nbsp; Binomial probability examples</h2>

<p class="heading">Assumptions underlying the binomial distribution</p>
	<ul>
		<li>Each observation has the same probability, <span class="black">π</span>, 
			of being a 'success'.</li>
		<li>Each of the <span class="em black">n</span>  observations is independently obtained.</li>
		<li>We record the number (or proportion) of successes in the <span class="em black">n</span>  observations.</li>
	</ul>
	<p class="heading">Evaluating binomial probabilities</p>
	<p>They may be obtained using ... </p>
	<ul>
		<li>a computer (preferred),</li>
		<li>a mathematical formula, or</li>
		<li>tables of binomial probabilites.</li>
	</ul>
	<p class="heading">A range of counts</p>
	<p>Finding the probability that the number of successes is within an interval involves adding the binomial probabilities for all integer values in the interval.</p>
	<p>Think carefully about the wording of the interval &mdash; does it include the values at the end? Adding or subtracting <sup>1</sup>/<sub>2</sub> to the endpoints of the interval makes it clearer. (This is also particularly useful when using the normal approximations that are described in the following pages.)</p>
	<div class="centred"><table border="0" class="centred" cellpadding="3" cellspacing="0">
<tr>
<th align="center" scope="col">In words...</th>
<th align="center" scope="col">&nbsp;&nbsp;&nbsp;&nbsp;In terms of X&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th align="center" scope="col">&nbsp;&nbsp;&nbsp;&nbsp;Using <sup>1</sup>/<sub>2</sub>&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">More than 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">X &gt; 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">X&nbsp;&gt;&nbsp;5.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">Greater than or equal to 5</td>
<td align="center" bgcolor="#FFFFFF">X ≥ 5</td>
<td align="center" bgcolor="#FFFFFF">X &gt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">No more than 5</td>
<td align="center" bgcolor="#FFFFFF">X ≤ 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 5.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">At least 5</td>
<td align="center" bgcolor="#FFFFFF">X ≥ 5</td>
<td align="center" bgcolor="#FFFFFF">X &gt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">Fewer than 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">5 or fewer</td>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">X ≤ 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">X &lt; 5.5</td>
</tr>
</table></div>
<p>The following example illustrates the use of <sup>1</sup>/<sub>2</sub> in this way.</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_binomExample_c.gif" width="550" height="272"></p>





<h2 class="pageName">7.7.5 &nbsp; Normal approximation to binomial</h2>

<p class="heading">Mean and standard deviation of <em>x</em> and <em>p</em></p>
	<p>The mean and standard deviation are given below for the proportion of successes <span class="em black">p</span> , and number of successes,<span class="em black"> x</span> <span class="black">&nbsp;=&nbsp;<em>np</em></span></p>
	<p class=eqn><img class="gif" src="../../../en/randomPropn/images/normalApprox.gif" width="389" height="126"> </p>
	<p>The fact that both <span class="em black">x</span>  and <span class="em black">p</span>  are approximately normally distributed in large samples is justified below.</p>
	<p class="heading">Proportions and means</p>
	<p>If we assign a code of '1' to the successes and '0' to the failures in the 
		random sample, then the resulting values are called an <strong>indicator variable</strong>. Its mean is identical to the proportion of successes. </p>
	<p class=eqn><img class="gif" src="../../../en/randomPropn/images/propnAsMeanEqn.gif" width="397" height="100"> </p>
	<p>Since the proportion of successes in a sample is a kind of mean, its distribution is close to a normal distribution if the sample size is large enough.<br>
	</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_normalApprox.gif" width="502" height="375"></p>




<h2 class="pageName">7.7.6 &nbsp; Normal approximation examples</h2>

<p class="heading notPrinted">Use of the normal approximation to the binomial distribution</p>
	<p>To avoid adding large numbers of binomial probabilities, the normal approximation can be used to find the probability that a binomial variable is within a certain range when the sample size, <span class="em black">n</span> , is large.</p>
	<p>A common rule-of-thumb for when this kind of normal approximation can be used is:</p>
	
	<div class="centred"><div class="boxed percent50">
		<p><em>n</em>π &gt; 5 &nbsp; &nbsp;and &nbsp; &nbsp; <em>n</em>(1-π) &gt; 5 </p>
	</div></div>
	
	<p>An example is given below:</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_normalApproxEx_c.gif" width="550" height="460"></p>
	<p>Note the translation of the range of values into one involving <sup>1</sup>/<sub>2</sub>. It is called a <strong>continuity correction</strong> in this context.</p>





<h1 class="sectionName breakBefore">7.8 &nbsp; Sampling in practice</h1>
<h2 class="pageName">7.8.1 &nbsp; Stratified sampling</h2>

<p>A simple random sample of individuals from a population is the easiest sampling scheme to understand, but other sampling schemes may give more accurate estimates of population characteristics.</p>
	<p class="heading">Grouping of individuals</p>
	<p>If the individuals in the population can be split into different groups (called <strong>strata</strong> in sampling terminology), it is often better to take a 
		simple random sample <strong>within each separate group</strong> than to sample 
		randomly from the whole population. This is called a <strong>stratified random 
			sample</strong>.</p>
	<p>The  proportion sampled from the different strata are usually fixed to be the same as the proportions of individuals in the strata in the population. In a simple random sample, the proportions sampled from the strata might not match the population proportions, so a stratified random sample should be more 'representative'.</p>
	<p class="eqn"><img src="../../../en/sampPractice/images/s_stratified.gif" width="418" height="351"></p>




<h2 class="pageName">7.8.2 &nbsp; Cluster sampling</h2>

<p class="heading">Sampling frame</p>
	<p>Before taking a simple random sample or stratified random sample, a complete 
		list of all individuals in the target population must be available. This is called a <strong>sampling 
			frame</strong>.</p>
	<p class="heading">Cluster sampling</p>
	<p>If a complete sampling frame is not available, it may be possible to group the target individuals into reasonably 
	small groups, called <strong>clusters</strong>, for which a complete list is available.</p>
	<p>Clusters are similar to the strata that are used for stratified sampling, but 
		are usually much smaller. For example, a cluster might contain all of the houses in a street, or all of the individuals in a household. It is not necessary to know beforehand how many individuals are in each of the clusters.</p>
	<p>For cluster sampling, a <strong>simple random sample of clusters</strong> is 
		selected, with all individuals in these clusters selected.</p>
	<p class="heading">Cost advantages</p>
	<p>Even when a complete sampling frame is available, cluster sampling might be 
		used to reduce the cost of sampling (or to increase the sample size for the same 
		cost) since it is often cheaper to record information from individuals in the 
		same cluster than from different parts of the sampling frame.</p>
	<p class="heading">Accuracy of cluster sampling</p>
	<p>The disadvantage of cluster sampling is that estimates are usually less accurate than the corresponding estimates from 
	a simple random sample of the same size.</p>
	<p>However the cost advantages would permit a larger sample size, so cluster sampling may give the best estimates <strong>for a fixed cost</strong>.</p>




<h2 class="pageName">7.8.3 &nbsp; Two-stage sampling</h2>

<p class="heading">Sampling from large populations</p>
	<p>Two-stage sampling is a sampling scheme that is related to cluster sampling, 
		but is of most use for large populations when the individuals are very widely 
		separated in some sense. For example, many polls are conducted to obtain <strong>national</strong> information about voting intentions or consumer purchases, and there is a high 
		cost associated with travelling between different regions.</p>
	<p>In two-stage sampling, the population is separated into groups of adjacent 
		individuals called <strong>primary sampling units</strong>. These primary sampling 
		units are typically large &mdash; for example a country might be split into 20 or more 
		regions. A small number of these are selected according to some sampling scheme, 
		then individuals are sub-sampled within each selected primary unit.</p>
	<p>Costs are reduced by limiting sampling to a small number of primary units. 
		For example, if individuals are only sampled from within say 5 regions, travelling 
		and accommodation costs will be considerably reduced.</p>
	

<h2 class="pageName">7.8.4 &nbsp; Sampling and non-sampling errors</h2>

<p class="heading">Estimation</p>
	<p>The aim of sampling is usually to <strong>estimate</strong> one or more population 
		values (parameters) from a sample. Because we do not have complete information about the population, the estimate is unlikely to be <strong>exactly</strong> same as the value that we are estimating, 
		so we call the difference the <strong>error</strong> in the estimate. There are 
		different kinds of error.</p>
	<p class="heading">Sampling error</p>
	<p>We have presented four different ways to sample from a population</p>
	<ul>
		<li>Simple random sample</li>
		<li>Stratified sample</li>
		<li>Cluster sample</li>
		<li>Two-stage sample</li>
	</ul>
	<p>Each of these involves randomness in the sample-selection process. The error caused by randomness in the sampling process is called <strong>sampling 
			error</strong>.</p>
	<p class="heading">Non-sampling error</p>
	<p>When sampling from some types of population &mdash; especially human populations 
		&mdash; problems often arise when conducting one of the above sampling schemes. For 
		example, some sampled people are likely to refuse to participate in your study.</p>
	<p>Such difficulties also result in errors and these are called <strong>non-sampling 
		errors</strong>. Non-sampling errors can be much higher than sampling errors 
		and are much more serious. </p>
	<ul>
		<li>Unlike sampling errors, the likely size of non-sampling errors cannot be estimated 
			from a single sample &mdash; it is extremely difficult to assess their likely size.</li>
		<li>Non-sampling errors often distort estimates by pulling them in one direction. 
			The estimates are then called <strong>biased</strong>.</li>
	</ul>
	<p>It is therefore important to design a survey to minimise the risk of non-sampling 
		errors.</p>




<h2 class="pageName">7.8.5 &nbsp; Coverage and non-response errors</h2>

<p class=heading>'Missing' responses</p>
	<p>The first two types of non-sampling error are caused by failure to obtain information 
		from some members of the target population.</p>
	<p class=heading>Coverage error</p>
	<p><strong>Coverage error</strong> occurs when the sample is not selected from 
		the target population, but from only part of the target population. As a result, 
		the estimates that are obtained do not describe the whole target population &mdash; 
		only a subgroup of it.</p>
	<p class=heading>Non-response error</p>
	<p>In many surveys, some selected individuals do not respond. This may be caused by ... </p>
	<ul>
		<li>Failure to contact the individuals.</li>
		<li>Refusal to participate in the study.</li>
		<li>Refusal to answer particular questions.</li>
	</ul>
	<p>If non-response is related to the questions being asked, estimates from the 
		survey are likely to be biased.</p>




<h2 class="pageName">7.8.6 &nbsp; Interviewer and instrument errors</h2>

<p class=heading>'Inaccurate' responses</p>
	<p>The next two types of non-sampling error are caused by inaccurate information 
		being obtained from the sampled individuals.</p>
	<p class=heading>Instrument error</p>
	<p><strong>Instrument error</strong> usually results from poorly designed
		questions. Different wording of questions can lead to different answers being 
		given by a respondent. The wording of the question may be such as to elicit some
		particular response (a <strong>leading</strong> question) or it may simply be carelessly
		worded so that it is misinterpreted by some respondents. </p>
	<p class=heading>Interviewer error</p>
	<p><strong>Interviewer error</strong> occurs when some characteristic of the interviewer, such
		as age or sex, affects the way in which respondents answer questions.</p>




<h2 class="pageName">7.8.7 &nbsp; Survey design issues</h2>

<p>There are various different ways to collect information from human populations. 
	Each method has its advantages and disadvantages.</p>
	<p class=heading>Telephone</p>
	<ul>
		<li>Non-response can be high.</li>
		<li>Coverage error is small.</li>
		<li>The number of questions must be kept very small.</li>
		<li>Inexpensive, so sample sizes can be greater.</li>
	</ul>
	<p class=heading>Mailed questionnaire</p>
	<ul>
		<li>Non-response is very high.</li>
		<li>Costs are higher than in a telephone survey.</li>
		<li>Mailed questionnaires can contain more questions than telephone surveys.</li>
	</ul>
	<p class=heading>Interviewer</p>
	<ul>
		<li>Lowest non-response and other sampling errors.</li>
		<li>Interviewers must be well trained to reduce interviewer error.</li>
		<li>Most expensive.</li>
		<li>Questionnaires can be fairly long.</li>
	</ul>
	<p>Houses are rarely selected at random. Often streets are randomly selected and every
		5th or 10th house in the street is approached. This is called a <strong>systematic
			sample</strong>. </p>
	<p class=heading>Street corner</p>
	<p>Some surveys are conducted by approaching people in busy shopping centres or
		similar public places. </p>
	<ul>
		<li>Large coverage errors.</li>
		<li>Least expensive and therefore widely used.</li>
		<li>Questionnaires must be small.</li>
	</ul>
	<p>To reduce coverage errors, a <strong>quota sample</strong> is often used. Each 
		interviewer is told to interview fixed numbers of old, young, male, female, etc. 
		respondents to match the 
		corresponding proportion in the target population.</p>
	<p class=heading>Self-selected</p>
	<p>Phone-in or mail-in surveys are often conducted by radio stations and magazines. The
		respondents are usually so unrepresentative that the results are meaningless. These types
		of survey should be avoided. </p>




<h1 class="sectionName breakBefore">7.9 &nbsp; Control charts</h1>
<h2 class="pageName">7.9.1 &nbsp; Introduction</h2>

<p class="heading">Statistics for complex problems</p>
	<p>In practice, problems are rarely  well-defined and there may be various 
		different ways to collect data to throw light on them.</p>
	<ul>
		<li>How do we reduce hospital waiting lists?</li>
		<li>How do you design an ultrasonic sound generator to repel mice?</li>
	</ul>
	<p>Collection and analysis of data to help attack the problem usually suggest 
		further questions for which further data are required. Several cycles of data 
		collection and analysis are usually needed, with considerable input from an expert 
		in the problem area between each cycle of the process. </p>
	<p class="heading">Continuous quality improvement</p>
	<p>In business 
		and industry, statistics is an important part of the long-term <strong>monitoring</strong> of performance. We may simply want to ensure that systems continue to perform at their current 
		levels, or the aim may be to <strong>improve</strong> aspects of the system. 
		The latter is often called <strong>continuous quality improvement</strong> or <strong>total quality management</strong>.</p>
	<p>Problems in a process are usually detected by collecting and analysing <strong>data</strong> about the performance of the system. This section describes the use of <strong>control charts</strong> as a way to monitor processes.</p>




<h2 class="pageName">7.9.2 &nbsp; Run charts</h2>

<p class=heading>Inherent variability</p>
	<p>A certain level of variability in any process is unavoidable. We say that this 
		'acceptable' level of variability is a result of <strong>common causes</strong> (or <strong>random causes</strong>) and if it is the only source of variability, 
		the process is said to be <strong>in control</strong>. </p>
	<p class=heading>Systematic changes</p>
	<p>Our aim is to detect changes to the output that are <strong>not</strong> the 
		result of common causes. Such systematic changes are said to be the result of <strong>special causes</strong> (or <strong>assignable causes</strong>) and 
		could result in... </p>
	<ul>
		<li>movement in the process mean (either abruptly or steadily over time),</li>
		<li>single outliers, or</li>
		<li>changes to the process variability</li>
	</ul>
	<p>Systematic changes usually indicate problems with the quality of the output and the process is said to be <strong>out of control</strong>. </p>
	<p class=heading>Run chart</p>
	<p>A <strong>control chart</strong> plots   measurements describing the process in time order &mdash; a type of time series plot. We hope to use it to quickly detect problems and adjust the process to maintain quality. If a single value is recorded at each time, the control chart is called a <strong>run chart</strong>. (Other control charts plot sample means and ranges.)</p>
<p>The challenge is to detect systematic 
		changes in the control chart (due to special causes) over the background level of 
		variability (due to common causes).</p>
	<p>In the example below, the manager has determined that an output measurement should 'almost always' be between 2,000 and 2,080 with variability in this range considered to be due to common causes. Two out of the last four values were above the upper limit, suggesting a problem with the process that should be investigated and fixed.</p>
	<p class="eqn">																										<img src="../../../en/controlChart/images/s_outliers.gif" width="553" height="302"></p>




<h2 class="pageName">7.9.3 &nbsp; Control limits</h2>

<p class="heading">Control limits</p>
	<p>The simplest rule suggesting a special cause is any value that is outside
		two <strong>control limits</strong>. Values outside the control limits suggest
that the process is <strong>out of control</strong> &mdash;
		they <strong>trigger</strong> an examination of the process for a special cause. </p>
	<p>Control limits are usually based on the mean and standard deviation of the 
		process when it is in control. The 70-95-100 rule of thumb states that in many 
		distributions, </p>
	<ul>
		<li>Approximately two thirds of the values are within 1 standard deviation of the mean.</li>
		<li>Approximately 95% of the values are within 2 standard deviations of the mean.</li>
		<li>Nearly all of the values are within 3 standard deviations of the mean.</li>
	</ul>
	<p class=eqn><img class="gif" src="../../../en/controlChart/images/bands.gif" width="578" height="264"></p>
	<p>By setting the upper and lower control limits to be 3 standard deviations
		on either side of the process mean, we avoid many 'false alarms' when the process is
		in control. This is important since values outside the control limits would trigger an examination of the 
		production process &mdash; possibly a costly exercise.</p>
	<p class="heading">Shape of the distribution</p>
	<p>The 70-95-100 rule of thumb is most accurate for reasonably symmetric, bell-shaped distributions, though values more than 3 standard deviations from the mean are rare for all distributions. However these control limits should be avoided for very skew distributions &mdash; consider transforming  the data before producing 
	a run chart.</p>




<h2 class="pageName">7.9.4 &nbsp; Other signals of being out-of-control</h2>

<p class="heading">Additional triggers for an out-of-control process </p>
	<p>The most commonly used indication of a process being out-of-control is a  
		value outside the upper and lower control limits (more than three standard deviations 
		away from the centre line). This is sensitive to changes to the process mean 
		or increases in the process variability. </p>
	<p>Additional triggers have been proposed that are also sensitive to systematic
		changes in a process. These are all based
		on successive values within 1, 2 or 3 standard deviations from the centre (Zones C, B or A).	</p>
	<p class="eqn"><img src="../../../en/controlChart/images/s_triggers.gif" width="550" height="589"></p>




<h2 class="pageName">7.9.5 &nbsp; False alarms</h2>

<p class="heading">False alarms </p>
	<p>Although the individual patterns that we use as triggers occur rarely in a process
		that is in control, they do occur occasionally. Indeed, the proportion of values
		from a stable process that triggers each of the
		criteria is typically about 1 in 200, so if all five criteria are used, a reasonable
		number of <strong>false alarms</strong> will occur. </p>
	<p>Clearly a single exceptional value is not conclusive proof that the process is
out of control. However it is appropriate to examine carefully the operation of the process
to look for an assignable cause for this value (and adjust the process if such a cause
is discovered).
And a <strong>series</strong> of such values does indicate that the process is out of control. </p>





<h2 class="pageName">7.9.6 &nbsp; Examples of run charts</h2>

<p class="heading">Obtaining control limits</p>
	<p>It is important to evaluate control limits from the mean and standard
		deviation of values from the process <strong>when it is in control</strong>.
		The process should be monitored carefully (to avoid special causes) for this training period. </p>
	<p class="eqn"><img src="../../../en/controlChart/images/s_runExample.gif" width="555" height="515"></p>




<h2 class="pageName">7.9.7 &nbsp; Control charts for means</h2>

<p class=heading>Samples instead of individual values</p>
	<p>Although control charts for individual values are sometimes used, it is more
		common to examine <strong>samples</strong> from a process at regular intervals
		rather than individual values.</p>
	<p class=heading>Control chart for means</p>
	<p>This avoids the problem that the 70-95-100 rule of thumb is poor for skew distributions &mdash; sample means have distributions that are closer to normal than individual values. If the sample size is <em>n</em>,</p>
	<p class=eqn><span style="position:relative; top:5px"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></span> &nbsp;<span class="black">=</span>&nbsp; <span style="position:relative; top:12px"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></span>
	<p>The control limits for a control chart of sample means are therefore... </p>
	<p class=eqn><span style="position:relative; top:-12px"><img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"> <span class="black">&nbsp;&plusmn;&nbsp; 3</span></span><img src="../../../en/../images/symbol.sOverRootN.png" width="26" height="31" align="baseline"> </p>
	<p>where <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"> and <em>s</em> are estimates of the mean and standard deviation of individual values when the 
		process is in control. These control limits should be distinguished carefully 
		from the corresponding control limits for individual values, </p>
	<p class=eqn><img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"> <span class="black">&nbsp;&plusmn;&nbsp; 3<em>s</em></span> </p>
	<p>Since the control limits used in a control chart for means are closer to <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"> than those in a control chart for individual values, the chart is more sensitive 
		to changes in the process mean over time.</p>
	<p class=heading>Training data</p>
	<p>In the example below, the control limits use the mean, <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline">, and standard deviation, <em>s</em>, from a training period of five  samples to set control limits for individual values.</p>
	<p class="eqn"><img src="../../../en/controlChart/images/s_meanExample.gif" width="555" height="313"> </p>
	<p>where</p>
	<p class=eqn><img class="gif" src="../../../en/controlChart/images/sdConstantEqn.gif" width="265" height="72"> </p>




<h2 class="pageName">7.9.8 &nbsp; Control charts for ranges</h2>

<p class="heading">Detecting changes to process variability</p>
	<p>A control chart of sample means is used to detect shifts in the 'centre' of 
		a process. In a similar way, a control chart to assess whether the process <strong>variability</strong> has changed can be based on the spread of successive samples. </p>
	<p>The most commonly used control chart for process variability is based on the <strong>sample ranges</strong>.</p>
<p class="eqn"><img src="../../../en/controlChart/images/s_range.gif" width="550" height="312"> </p>
	<p>By separately targetting the process centre and variability with  control charts for means
and  ranges, we can get better indications of any changes in the performance
of the process, and we can therefore intervene more promptly to correct potential drops
in quality. </p>




<h2 class="pageName">7.9.9 &nbsp; Finding the cause of problems</h2>

<p class="heading notPrinted">Finding the <span class="red">cause</span> of problems</p>
	<p>Control charts (and other collected data) may indicate problems with a system. 
		However, after detection of a problem, its <strong>cause</strong> must be 
		identified in order to rectify it. This is usually a non-trivial exercise 
		and the following tools often help.</p>
<p class="heading">Brainstorming</p>
	<p>In a <strong>brainstorming</strong> session, all team 
		members contribute short phrases that are written on either a large sheet of paper 
		or individual scraps of paper (post-it notes are good). The points should be written 
		down without discussion or editing, and all team members should be encouraged 
		to contribute.</p>
	<p>Once these ideas have been written down, they must be structured or grouped 
		in some way.</p>
	<p class="heading">Cause-and-effect diagrams</p>
	<p>After possible causes for a problem have been contributed in a brainstorming 
		session, they can be structured in a <strong>cause-and-effect</strong> diagram (also called  a <strong>fishbone</strong> diagram).</p>
	<p class="eqn"><img src="../../../en/controlChart/images/fishbone4.gif" width="484" height="377" class="summaryPict"></p>
<p>This structuring of possible causes helps to focus attention on the most likely 
		causes and on ones that may be altered in the 'Do' step in the Plan-Do-Check-Act 
		cycle.</p>




</body>
</html>
