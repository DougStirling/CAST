<html>
<head>
<title>14. Advanced Regression</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 14 &nbsp; Advanced Regression</h1>
<h2>14.1 &nbsp; Linear model assumptions</h2>
<h3>14.1.1 &nbsp; Assumptions in a normal linear model</h3>
<p>The normal linear model involves assumptions of linearity, constant variance, normal error distribution and independence of different observations. Residuals can be examined to assess whether these assumptions are appropriate for a particular data set.</p>
<h3>14.1.2 &nbsp; Curvature &mdash; transforming X</h3>
<p>If the relationship between Y and X is nonlinear, a transformation of X may linearise the relationship.</p>
<h3>14.1.3 &nbsp; Curvature and non-constant variance</h3>
<p>Transforming the response may remove curvature in the relationship, but also affects whether the error standard deviation is constant. Fortunately, the same transformation of Y often removes curvature and non-constant standard deviation.</p>
<h3>14.1.4 &nbsp; Transformations and prediction ((advanced))</h3>
<p>If a normal linear model describes the relationship between a transformation of the response and a transformation of the explanatory variable, predictions can be made by fitting the linear model to the transformed data, then performing the inverse transformation on the prediction.</p>
<h3>14.1.5 &nbsp; Outliers and leverage</h3>
<p>An outlier is a response value that is unusually large or small. An extreme residual suggests an outlier and standardised residuals can be used to assess it. However if the outlier corresponds to an extreme x-value (a high leverage point) it may not show up as a large residual.</p>
<h3>14.1.6 &nbsp; Non-normal errors ((optional))</h3>
<p>The errors in a normal linear model are assumed to have normal distributions. Violation of this assumption is less important than nonlinearity, non-constant variance or outliers, but a probability plot of the residuals can be used to assess normality.</p>
<h3>14.1.7 &nbsp; Correlated errors ((optional))</h3>
<p>The errors in a normal linear model are assumed to be independent. In data where the observations are recorded sequentially, successive errors are sometimes found to be correlated. Correlated errors can arise whatever the x-variable, but are most often seen when the x-variable is time itself.</p>
<h2>14.2 &nbsp; Logistic regression</h2>
<h3>14.2.1 &nbsp; Categorical responses</h3>
<p>With a categorical response and numerical explanatory variable, stacked bar charts at each X are an effective display.</p>
<h3>14.2.2 &nbsp; Fitted values and predictions</h3>
<p>Using a straight line to describe how the proportion in a category depends on X is not appropriate. A curve is required.</p>
<h3>14.2.3 &nbsp; Logistic curve</h3>
<p>A 'logistic' curve can be used to model how a proportion depends on X.</p>
<h3>14.2.4 &nbsp; Obtaining a good fit</h3>
<p>A logistic curve is fitted to an example data set.</p>
</body>
</html>
