<html>
<head>
<title>7. Estimation</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 7 &nbsp; Estimation</h1>
<h2>7.1 &nbsp; Introduction to estimation</h2>
<h3>7.1.1 &nbsp; Interest in populations</h3>
<p>When data are collected, we are usually more interested in the unknown population distribution from which we assume that the data were generated.</p>
<h3>7.1.2 &nbsp; Interest in parameters</h3>
<p>A few numerical summaries of a population distribution (parameters) often capture its most interesting characteristics. The corresponding sample statistics provide estimates.</p>
<h3>7.1.3 &nbsp; Applications of estimation</h3>
<p>This page gives a few examples where sample statistics are used to estimate important population parameters.</p>
<h3>7.1.4 &nbsp; Estimation error</h3>
<p>The difference between the population parameter and a sample estimate is called the error in the estimate.</p>
<h3>7.1.5 &nbsp; Distribution of errors</h3>
<p>Estimation errors vary from sample to sample and have distributions.</p>
<h3>7.1.6 &nbsp; Standard error and bias</h3>
<p>A good estimator has errors that are close to zero. The error distribution should ideally be centred on zero (unbiased) and have low standard deviation (standard error). The standard error is the standard deviation of both the estimator and the estimation error.</p>
<h3>7.1.7 &nbsp; Interval estimates</h3>
<p>An interval estimate is a range of values within which we are 'confident' that the unknown population parameter lies.</p>
<h2>7.2 &nbsp; Standard error of mean</h2>
<h3>7.2.1 &nbsp; Error distribution for mean</h3>
<p>When using a sample mean to estimate a population mean, the errors have a distribution with mean zero. The standard deviation of the errors (standard error) is the standard deviation of the sample mean.</p>
<h3>7.2.2 &nbsp; Standard error when σ is known</h3>
<p>If the population standard deviation is known, the standard error can be evaluated.</p>
<h3>7.2.3 &nbsp; Interpreting the standard error</h3>
<p>The estimation error has about 95% probability of being within 2 standard errors of zero and is almost certainly within 3 standard errors.</p>
<h3>7.2.4 &nbsp; Standard error when σ is unknown</h3>
<p>In most practical applications, the population standard deviation is unknown. The standard error of the sample mean can be approximated by replacing the population standard deviation by the sample standard deviation in its formula.</p>
<h3>7.2.5 &nbsp; Standard error vs standard deviation</h3>
<p>It is important to distinguish between the interpretation (and value) of the standard error (SE) and standard deviation (SD).</p>
<h3>7.2.6 &nbsp; Using SEs to compare estimators</h3>
<p>If there are two alternative estimators of a parameter, the estimator with lower standard error is usually better. The sample mean is shown to be a better estimator of the centre of a normal population than the sample median. </p>
<h3>7.2.7 &nbsp; More about bias</h3>
<p>Unbiased estimators are usually preferred. The sample median is shown to be a biased estimator of the mean of a skew distribution.</p>
<h2>7.3 &nbsp; Confidence interval for mean</h2>
<h3>7.3.1 &nbsp; Confidence interval from standard error</h3>
<p>The estimation error for any unbiased estimator, has approximately 0.95 probability of being between -2SE and +2SE. An approximate 95% confidence interval for the parameter is therefore the estimate ± 2SE.</p>
<h3>7.3.2 &nbsp; Confidence interval for mean, known σ</h3>
<p>If the population standard deviation is known, the standard error can be found exactly. A 95% confidence interval is the sample mean ± twice this. (Or more exactly, 1.96 times the standard error.)</p>
<h3>7.3.3 &nbsp; Confidence level</h3>
<p>A simulation shows that 95% confidence intervals are random — they vary from sample to sample. About 95% of samples give confidence intervals that include the true parameter.</p>
<h3>7.3.4 &nbsp; Confidence level if σ is replaced by s</h3>
<p>In practice, the population standard deviation is usually unknown. If the population SD is simply replaced by its sample equivalent, the interval estimate has a lower confidence level than 95%.</p>
<h3>7.3.5 &nbsp; Confidence interval for mean, unknown σ</h3>
<p>To get a 95% confidence level, a t-value from tables must replace the constant 1.96.</p>
<h3>7.3.6 &nbsp; Properties of 95% confidence interval</h3>
<p>A simulation demonstrates that the resulting 95% confidence intervals have probability 0.95 of including the population mean.</p>
<h3>7.3.7 &nbsp; Examples</h3>
<p>Some examples of 95% confidence intervals for population means are given and interpreted.</p>
<h2>7.4 &nbsp; Estimating proportions</h2>
<h3>7.4.1 &nbsp; General framework for estimation</h3>
<p>The methodology for describing the accuracy of a sample mean using standard errors and confidence intervals can also be used for other parameter estimates.</p>
<h3>7.4.2 &nbsp; Estimating a proportion</h3>
<p>A sample proportion estimates the corresponding population proportion, π. There is likely to be an error in this estimate and these errors have a distribution.</p>
<h3>7.4.3 &nbsp; Error distribution</h3>
<p>The estimation errors have a type of binomial distribution that is scaled to have mean zero. Its standard deviation is the standard error of the proportion.</p>
<h3>7.4.4 &nbsp; Normal approximation to error distribution</h3>
<p>If the sample size is high enough, the error distribution is approximately normal. This page gives a few examples for which the error distribution is found.</p>
<h3>7.4.5 &nbsp; Confidence interval for proportion</h3>
<p>A 95% confidence interval for a population proportion is the sample proportion ± twice its standard deviation. Its confidence level is only approximately 95% and guidelines are given for the minimum sample size.</p>
<h3>7.4.6 &nbsp; Properties of 95% CI for proportion</h3>
<p>If samples are repeatedly taken, about 95% of them result in 95% confidence intervals that include the population proportion. Guidelines are given for the minimum sample size to make the confidence level close to 95%.</p>
<h3>7.4.7 &nbsp; Confidence interval examples</h3>
<p>95% confidence intervals for proportions are found and interpreted for several data sets.</p>
<h2>7.5 &nbsp; More about estimation</h2>
<h3>7.5.1 &nbsp; Margin of error</h3>
<p>The margin of error for a survey is related to a confidence interval. It is close to a 95% CI when p is 0.5, but underestimates the accuracy of small or large sample proportions.</p>
<h3>7.5.2 &nbsp; Sample size for estimating mean</h3>
<p>Given a target width for a 95% confidence interval, it is possible to determine the necessary sample size to achieve this accuracy.</p>
<h3>7.5.3 &nbsp; Sample size for estimating proportion</h3>
<p>In a similar way, given a target width for a 95% confidence interval for a proportion, it is possible to determine the necessary sample size.</p>
<h3>7.5.4 &nbsp; Other confidence levels</h3>
<p>All earlier confidence intervals had 95% confidence level. Replacing 1.96 (or 2) with other values gives interval estimates with different confidence levels.</p>
<h2>7.6 &nbsp; Models for two groups</h2>
<h3>7.6.1 &nbsp; Interest in underlying population</h3>
<p>As with single-group data, the populations underlying two-group data sets are usually of more interest than the specific sample data.</p>
<h3>7.6.2 &nbsp; Model for two groups</h3>
<p>Two-group data sets are often modelled as separate random samples from two normal populations.</p>
<h3>7.6.3 &nbsp; Parameters of the normal model</h3>
<p>The normal model has four parameters — the means and standard deviations in the two groups.</p>
<h3>7.6.4 &nbsp; Parameter estimates</h3>
<p>The parameters of the normal model can be estimated by the sample means and standard deviations in the two groups.</p>
<h3>7.6.5 &nbsp; Difference between means</h3>
<p>The difference between the population means is of particular interest. The difference between the sample means provides an estimate. It varies from sample to sample and has a distribution.</p>
<h2>7.7 &nbsp; Comparing means in two groups</h2>
<h3>7.7.1 &nbsp; Distn of difference between means</h3>
<p>The difference between the means of two samples from normal populations has a normal distribution whose mean and s.d. can be found from the population means and s.d.s. This is the approximate distribution even when the populations are non-normal.</p>
<h3>7.7.2 &nbsp; SE of difference between means</h3>
<p>When the difference between the sample means is used to estimate the difference between the underlying population means, there is likely to be an error. The error distribution is approximately normal with mean 0. A formula for its standard deviation is given.</p>
<h3>7.7.3 &nbsp; CI for difference between means</h3>
<p>A 95% confidence interval is given for the difference between two population means. Its properties are demonstrated.</p>
<h2>7.8 &nbsp; Comparing two proportions</h2>
<h3>7.8.1 &nbsp; Modelling two proportions</h3>
<p>Two-group categorical data can be modelled as samples from two categorical populations with different probabilities of 'success'.</p>
<h3>7.8.2 &nbsp; Distribution of difference in proportions</h3>
<p>The difference between two sample proportions has a distribution that is approximately normal and whose parameters can be estimated using earlier results about the mean and standard deviation of differences.</p>
<h3>7.8.3 &nbsp; CI for difference in proportions</h3>
<p>The standard deviation of the difference between two sample proportions can be estimated. From this, a 95% confidence interval is developed for the difference between two probabilities.</p>
<h2>7.9 &nbsp; Paired data</h2>
<h3>7.9.1 &nbsp; Paired data</h3>
<p>Paired data are a type of bivariate data in which two similar measurements are made from each individual. We are usually interested in testing whether the means of both measurements are the same.</p>
<h3>7.9.2 &nbsp; Analysis of differences</h3>
<p>For paired data, differences between the two measurements hold all information about whether the means of both variables are the same.</p>
</html>
