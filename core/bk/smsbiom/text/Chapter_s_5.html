<!DOCTYPE HTML>
<html>
<head>
  <title>5. Statistical Models</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="../../../structure/summaryStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/maths/mathStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/printStyles.css" type="text/css">
  <script src="../../../structure/videoControls/jquery.js"></script>
  <script src="../../../structure/maths/theorems.js"></script>
  <script src="../../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js"></script>
  <script src="../../../structure/printFixes.js"></script>
</head>

<body id="body" onLoad="showPrintDialog(true)">
<div id='overlay'>
	<div id='dialogWindow'>
		<div class='printDialog'>
			<script type='text/javascript'>
				document.write("<div class='heading'>" + top.document.title + "</div>");
				if (top.url != null) {
					document.write("<p class='text'>A version of this chapter has already been generated in PDF format and we recommend that it is used for printing. The button below will download and display it.</p>");
					document.write("<p><button onClick='top.showPdf()'>Show PDF version of chapter</button></p>");
					document.write("<p class='text'>However downloading could be slow depending on your internet connection. If this is a problem, click the button below to print the chapter without downloading (but perhaps not formatted as well as the PDF version).</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>If you are <strong>not</strong> using the PDF version, the best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
				else {
					document.write("<p class='text'>Click the button below to print this chapter.</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>The best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
			</script>
			
			<p class='text'>If you don't want to print now,</p>
			<p><button onClick='top.showPrintDialog(false)'>Browse formatted chapter</button></p>
		</div>
	</div>
</div>
<h1 class="chapterName">Chapter 5 &nbsp; Statistical Models</h1>
<h1 class="sectionName">5.1 &nbsp; Scatterplots</h1>
<h2 class="pageName">5.1.1 &nbsp; Bivariate data sets</h2>

<p class="heading">The data matrix</p>
	<p>Many datasets contain several measurements from each <strong>individual</strong> (or plant, item
		or other unit). Each measurement type is called a <strong>variable</strong>. </p>
	<p class=eqn> <img class="gif" src="../../../en/structures/images/dataMatrix.gif" width="258" height="283"> </p>
	<p>A data set with more than one variable is called <strong>multivariate</strong>.
One with two
variables is called <strong>bivariate</strong>.</p>




<h2 class="pageName">5.1.2 &nbsp; Limitations of univariate displays</h2>

<p class="heading notPrinted">Scatterplots are needed to display  relationships</p>
	<p>The relationship between two variables cannot be determined from examination
 of the two variables in isolation. The two datasets shown in the scatterplots
below have the <strong>same marginal distributions</strong> for X and Y, but the variables are related
in very different ways.</p>
<p class="eqn"><img src="../../../en/scatterplot/images/s_sameMargins.gif" width="509" height="211"></p>





<h2 class="pageName">5.1.3 &nbsp; Marginal distributions</h2>

<p class="heading notPrinted">Marginal distributions</p>
<p><span class="full_text">Although 
		they do not contain information about the relationship between the variables, 
	a display of the marginal distributions can be usefully <strong>added</strong> to a scatterplot to enhance it, perhaps highlighting skewness in X and Y.</span></p>
<p class="eqn"><img src="../../../en/scatterplot/images/s_margins.gif" width="354" height="272"></p>






<h2 class="pageName">5.1.4 &nbsp; Time series</h2>

<p class="heading">Time-ordering of univariate data</p>
	<p>Some data sets are apparently univariate, but the measurements are made sequentially 
		in time.  A data set of this form is called a <strong>time series</strong>.</p>
	<p>The time at which each measurement was made may be treated as an additional 
		numerical variable, and the measurement can then be plotted against time. 
		This type of scatterplot is often called a <strong>time series plot</strong>.</p>
	<p class="eqn"><img src="../../../en/scatterplot/images/s_timeSeries.gif" width="504" height="300"></p>





<h1 class="sectionName breakBefore">5.2 &nbsp; Understanding relationships</h1>
<h2 class="pageName">5.2.1 &nbsp; Strength of a relationship</h2>

<p class="heading notPrinted">Strength of relationship</p>
<p>The most important information that a scatterplot shows is the <strong>strength</strong> of the relationship between the variables. The closer the points to a straight line or curve, the stronger the relationship.</p>
<p>If higher values of one variable tend to be associated with higher values
 of the other variable, the crosses on the scatterplot will be in a band with
positive slope and the relationship is said to be <strong>positive</strong>. If high values of one variable tend to be associated with low values of the 
	other variable, we say that there is a <strong>negative</strong> relationship.</p>
<p class="eqn"><img src="../../../en/relationship/images/s_types.gif" width="398" height="323"></p>





<h2 class="pageName">5.2.2 &nbsp; Outliers</h2>

<p>The strength of the relationship between two variables is usually the most 
  important information that we gain from a scatterplot but a scatterplot may display other features.</p>
<p class="heading">Outliers</p>
<p>Values that seem 'different' from the rest of the data are called <strong>outliers</strong>.</p>
<p>An outlier may be an extreme value of one or other variable, but an individual
may be an outlier even though neither X nor Y is unusual on its own. One point
is an outlier in each of the three data sets below.</p>
<p class="eqn"><img class="gif" src="../../../en/relationship/images/outliers.gif" width="312" height="157">       <img class="gif" src="../../../en/relationship/images/outliers2.gif" width="142" height="158"></p>
<p>The point is an
outlier in the righthand data set  because it lies well above the main group
of points &mdash; its y-value is much higher than others with similar x-values.</p>
<p class=heading>Importance of outliers</p>
<p>Outliers are features of a data set that <strong>must</strong> be carefully 
	checked. An outlier is often caused by a recording or transcription error, 
	so...</p>

<div class="centred"><div class="boxed">
<p>First check that the values of the variables 
			are correctly recorded.</p>
</div></div>

<p>Sometimes an outlier arises because an individual is fundamentally different 
	from the others.  Identifying what makes the individual different  often gives considerable insight into the data.</p>

<div class="centred"><div class="boxed">
<p>The individuals should be further examined (perhaps 
			collecting further information from them) to try to assess whether the 
			outlier individual has distinct characteristics.</p>
</div></div>

<p>An outlier that is either extreme or that has other distinctive characteristics 
	would often be deleted from the data set, but should be mentioned in a report 
	about the data.</p>




<h2 class="pageName">5.2.3 &nbsp; Clusters</h2>

<p class="heading notPrinted">Clusters</p>
	<p>Sometimes the cloud of crosses separates into two or more groups which are 
		called <strong>clusters</strong>. As with outliers, clusters provide important 
		information that should be further investigated.</p>
	<p class="eqn"><img src="../../../en/relationship/images/s_clusters.gif" width="241" height="222"></p>
	<p>The individuals should be  examined (perhaps collecting further 
		information from them) to  assess whether the clusters correspond to
 individuals with distinct characteristics. For example, the clusters may correspond
 to males and females, or  two different species of plant.</p>




<h2 class="pageName">5.2.4 &nbsp; Explanatory and response variables</h2>

<p class=heading>Causal relationships</p>
	<p>In many bivariate data sets, the relationship between the two variables is 
		not symmetric. From the nature of the variables and the way that the data were collected, it may be clear that one variable, X, can potentially influence the other, Y, but that the opposite is impossible.</p>
	<p class="eqn"><img class="gif" src="../../../en/causal/images/reln1.gif" width="297" height="65"></p>
<p>In such data, the variable X is called the <strong>explanatory variable</strong> and Y is called the <strong>response</strong>.</p>
	<p class=heading>Experiments</p>
	<p>In an experiment,  the person conducting the experiment controls the values
of the explanatory variable. A well-designed experiment
always ensures that the relationship between the explanatory variable and response
is causal.</p>
<p class=heading>Observational studies</p>
	<p>If the person collecting the data has no control over either of the variables,
and simply records a pair of values from each individual, then the data are called <strong>observational</strong>.
If one variable is an earlier measurement than the other, we may also
be able to treat it as an explanatory variable and the later variable as the
response. </p>
<p>Even if the relationship is not causal, we are sometimes interested in <strong>predicting</strong> the
value of one variable from the other. The variable being predicted would then
be treated as the response.</p>




<h1 class="sectionName breakBefore">5.3 &nbsp; Least squares</h1>
<h2 class="pageName">5.3.1 &nbsp; Linear models</h2>

<p class="heading">Equation to describe a regression line</p>
	<p>A regression line could be drawn 'by eye' through a scatterplot, 
		but we restrict attention to simple mathematical functions</p>
	<p class=eqn><span class="black"><em>y</em> &nbsp;=&nbsp; <em>&fnof;</em> (<em> x</em> )</span></p>
	<p>since they are  easier and more objective to use.</p>
<p class="heading">Linear model</p>
	<p>Some relationships must be described by curves, but a straight line 
		is an adequate description of many bivariate data sets.</p>
	<p class=eqn><span class="black"><em>y</em> &nbsp;=&nbsp; <em>b</em><sub>0</sub> + <em>b</em><sub>1 </sub><em>x</em></span> </p>
	<p>The constant <em>b</em><sub>0</sub> is  the <strong>intercept</strong> of
the line and describes the <em>y</em>-value when <em>x</em> is zero. The constant <em>b</em><sub>1</sub> is
the line's <strong>slope</strong>; it 
		describes the change in <i>y</i> when <i>x</i> increases by one. </p>
<p class="eqn"><img src="../../../en/leastSqrs/images/s_slopeIntercept.gif" width="238" height="197"></p>
	<p>The predicted response at any <em>x</em>-value is</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.yHat.png" width="10" height="17" align="baseline"></td>
				<td valign="middle">&nbsp; =&nbsp; <em>b</em><sub>0</sub> + <em>b</em><sub>1 </sub><em>x</em></td>
			</tr>
		</table>
	</div>
	

<h2 class="pageName">5.3.2 &nbsp; Fitted values and residuals</h2>

<p class="heading">Fitted values</p>
	<p>To assess how well a particular linear model fits any one of our data points, (<em>x<sub>i</sub></em>,&nbsp;<em>y<sub>i</sub></em>), 
	we might consider how well the model would predict the y-value of the point, </p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.yiHat.png" width="11" height="18" align="baseline"></td>
				<td valign="middle">&nbsp;=&nbsp; <em>b</em><sub>0</sub> + <em>b</em><sub>1 </sub><em>x<sub>i</sub></em></td>
			</tr>
		</table>
	</div>
	<p>These predictions  are called <strong>fitted 
		values</strong>. </p>
	<p class="heading">Residuals</p>
	<p>The difference between the <em>i</em>'th fitted values  and its actual 
		y-value is called its <strong>residual</strong>. </p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><em>e<sub>i</sub></em>&nbsp;&nbsp;=&nbsp;&nbsp;<em>y<sub>i</sub></em> &minus; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.yiHat.png" width="11" height="18" align="baseline"></td>
			</tr>
		</table>
	</div>
	<p>The residuals describe the 'errors' that would have resulted from using the
 model to predict <em>y</em> from the <em>x</em>-values of our data points.</p>
<p class="eqn"><img src="../../../en/leastSqrs/images/s_resid.gif" width="351" height="207"></p>
	
	<p>Note that the residuals are the <strong>vertical distances of the crosses to the line</strong>.</p>
	
	



<h2 class="pageName">5.3.3 &nbsp; Least squares</h2>

<p class="heading">Aim of small residuals</p>
	<p>The residuals from a linear model (vertical distances from the crosses 
		to the line) indicate how closely the model's predictions  match the actual responses in the data. </p>
	<p class="eqn"><img src="../../../en/leastSqrs/images/s_allResids.gif" width="354" height="310"> </p>
	<p>'Good' values for <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub> can be
objectively chosen to be the values that minimise the residual sum of squares.
This is the <strong>method
of least squares</strong> and the values of <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub> are
called  <strong>least squares 
		estimates</strong>.</p>
<p>The diagram below respresents the squared residuals as blue squares. The least squares estimates minimise the total blue area.</p>
	<p class="eqn"><img src="../../../en/leastSqrs/images/s_sqrResids.gif" width="359" height="316"> </p>




<h2 class="pageName">5.3.4 &nbsp; Quadratic models</h2>

<p class="heading notPrinted">Adding a quadratic term</p>
	<p>An alternative solution to the problem of curvature is to extend the simple 
		linear model with the addition of a quadratic term, </p>
	<p class=eqn><span class="black"><em>y</em>&nbsp;&nbsp;=&nbsp;&nbsp;<em>b</em><sub>0</sub>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>1 </sub><em>x</em>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>2 </sub><em>x</em><sup>2</sup></span> </p>
	<p>Fitted values and residuals are defined (and interpreted) in a similar way 
		to those for a linear model,</p>
	<p class=eqn><span class="black"><span style="position:relative; top:4"><img src="../../../en/../images/symbol.yiHat.png" width="11" height="18" align="baseline"></span>&nbsp;&nbsp;=&nbsp;&nbsp;<em>b</em><sub>0</sub>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>1 </sub><em>x<sub>i</sub></em>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>1 </sub><em>x<sub>i</sub></em><sup>2</sup></span> <br>
			<span class="black"><em>e<sub>i</sub></em>&nbsp;&nbsp;=&nbsp;&nbsp;<em>y<sub>i</sub></em> &minus; <span style="position:relative; top:4"><img src="../../../en/../images/symbol.yiHat.png" width="11" height="18" align="baseline"></span></span> </p>
	<p>As in a linear model, the quadratic model's residuals are the vertical distances 
		between the crosses in a scatterplot and the curve. We again use <strong>least 
			squares</strong> to estimate the unknown parameters &mdash; choose values of the 
		three parameters to minimise the residual sum of squares, </p>
	<p class=eqn><img class="gif" src="../../../en/curvature/images/residSsqEqn.gif" width="369" height="28"> </p>
	<p class="eqn"><img src="../../../en/curvature/images/s_quadraticModel.gif" width="374" height="327"></p>




<h1 class="sectionName breakBefore">5.4 &nbsp; Linear regression models</h1>
<h2 class="pageName">5.4.1 &nbsp; Interest in generalising from data</h2>

<p class="heading notPrinted">Bivariate data: population or sample?</p>
<p>In most bivariate data sets, we have no interest in the specific individuals from
which the data are collected. The individuals are 'representative' of a larger population
or process, and our main interest is in this underlying population. </p>
<p class="heading">Example</p>
<p>Data  were collected by biologists from 15 lakes
in central Ontario to assess how zinc concentrations in an aquatic plant were related
to zinc concentrations in the lake sediment.</p>
<p class="eqn"><img src="../../../en/regnModel/images/s_sampleScatter.gif" width="403" height="316"></p>
<p>The biologists want to <strong>generalise</strong> from
these specific lakes (and sediment samples) to describe the relationship between
zinc concentrations in sediments and plants in a way that might be used to predict
plant zinc from sediment samples in <strong>other
similar </strong> lakes.</p>




<h2 class="pageName">5.4.2 &nbsp; Normal linear model</h2>

<p class="heading notPrinted">Normal linear model for the response</p>
<p>The most commonly used regression
model is a <strong>normal linear model</strong>. It  involves: </p>
<dl>
<dt><strong>Normality</strong></dt>
<dd>At each value of <i>X</i>, <i>Y</i> has a normal distribution.</dd>
<dt><strong>Constant variance</strong></dt>
<dd>The standard deviation of <i>Y</i> is the same for all values of <i>X</i>.</dd>
<dt><strong>Linearity</strong></dt>
<dd>The mean of <i>Y</i> is linearly related to <i>X</i>.</dd>
</dl>
<p>The last two properties of the normal linear model can be expressed as </p>
<p class=eqn><span class="black">&sigma;<sub><em>y</em></sub> &nbsp;=&nbsp; &sigma;</span> </p>
<p class=eqn><span class="black">&mu;<sub><em>y</em></sub> &nbsp;=&nbsp; &beta;<sub>0</sub> &nbsp;+&nbsp; &beta;<sub>1</sub><em>x</em></span> </p>
<p>The diagram below illustrates these three properties of the normal linear model:
the distributions at different x-values have  normal distributions with the same
spread and the mean increases linearly with <em>x</em>.</p>
<p class=eqn><img src="../../../en/regnModel/images/s_pdfs2.gif" width="362" height="385"></p>
<p class="heading">Note: only the response is modelled</p>
<p>A normal linear model does not try to explain the distribution of x-values. In
experimental data, they are fixed by the experimenter. In observational data, the
x-values are usually random, but the regression model only explains how the y-values
are related to them and treats them as constants.</p>
<div class="centred"><div class="boxed"><p>The regression model only describes the <strong>conditional</strong> distribution
of <em>Y</em> at each <em>X</em>.</p></div></div>




<h2 class="pageName">5.4.3 &nbsp; Model parameters</h2>

<p class="heading notPrinted">Slope and intercept</p>
<p>A normal linear model, </p>
<p class=eqn><span class="black">&mu;<sub><em>y</em></sub> &nbsp;=&nbsp; &beta;<sub>0</sub> &nbsp;+&nbsp; &beta;<sub>1</sub><em>x</em></span> </p>
<p class=eqn><span class="black">&sigma;<sub><em>y</em></sub> &nbsp;=&nbsp; &sigma;</span> </p>
<p>involves 3 parameters, β<sub>0</sub>, β<sub>1</sub> and σ. The model's slope,
β<sub>1</sub>,
and intercept, β<sub>0</sub>, can be interpreted in a similar way to the slope
and intercept of a least squares line.</p> 
<dl>
<dt>Slope</dt>
<dd>Increase in the mean response per unit increase in <i>X</i>.</dd>
<dt>Intercept</dt>
<dd>Mean response when <em>X</em> = 0.</dd>
</dl>

<p class="heading" style="margin-bottom:5px; margin-top:35px">Examples of interpretation</p>
<div class="centred">
	<table class="centred" border="0" cellpadding="8" cellspacing="0">
		<tr>
			<th align="CENTER" width="300">Context</th>
			<th width="33%" align="CENTER">Interpretation of β<sub>1</sub></th>
			<th width="33%" align="CENTER">Interpretation of β<sub>0</sub></th>
		</tr>
		<tr bgcolor="#FFFFFF">
			<td width="300" style="border:1px solid #999999;"><i>Y</i> = Yield of wheat per acre <br>
				<i>X</i> = Fertiliser (kg per m<sup>2</sup>)</td>
			<td width="33%" style="border:1px solid #999999; border-left:0px;">Increase in mean yield per acre for
				each additional kg/m<sup>2</sup> of fertiliser</td>
			<td width="33%" style="border:1px solid #999999; border-left:0px;">Mean yield per acre if no fertiliser
				is used</td>
		</tr>
		<tr bgcolor="#FFFFFF">
			<td width="300" style="border:1px solid #999999; border-top:0px;"><i>Y</i> = Exam mark <br>
				<i>X</i> = Hours of study by student before exam</td>
			<td width="33%" style="border-bottom:1px solid #999999; border-right:1px solid #999999;">Increase in expected mark for each additional
				hour of study</td>
			<td width="33%" style="border-bottom:1px solid #999999; border-right:1px solid #999999;">Expected mark if there is no study</td>
		</tr>
		<tr bgcolor="#FFFFFF">
			<td width="300" style="border:1px solid #999999; border-top:0px;"><i>Y</i> = Hospital stay (days) <br>
				<i>X</i> = Age of patient</td>
			<td width="33%" style="border-bottom:1px solid #999999; border-right:1px solid #999999;">Average extra days in hospital per extra
				year of age</td>
			<td width="33%" style="border-bottom:1px solid #999999; border-right:1px solid #999999;">Average days in hospital at age 0. Not particularly
				meaningful here. </td>
		</tr>
	</table>
</div>


<h1 class="sectionName breakBefore">5.5 &nbsp; Estimating parameters</h1>
<h2 class="pageName">5.5.1 &nbsp; Estimating the slope and intercept</h2>

<p class="heading">Least squares</p>
<p>In practical situations, we must estimate β<sub>0</sub>,
β<sub>1</sub> and σ from a data set that we believe satisfies the normal linear model.</p>

<div class="centred"><div class="boxed">
<p>The best estimates of β<sub>0</sub> and β<sub>1</sub> are the slope and
intercept of the least squares line, <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub></p>
</div></div>

<p>Since<em> b</em><sub>0 </sub>and <em>b</em><sub>1</sub> are functions of a
data set that we assume to be a random sample from the normal linear model, <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub> are
themselves random quantities and have distributions.</p>
<p class="heading">Simulated example</p>
<p>The diagram below represents a regression model with a grey band. A sample
of 20 values has been generated from this model and the least squares line (shown
in blue) has been fitted to the simulated data. The least squares line provides
estimates of the slope and intercept but they are not exactly equal to the underlying
model values.</p>
<p class="eqn"><img src="../../../en/regnEst/images/s_lsAndModel.gif" width="406" height="357"></p>
<p>A different sample would give 20 different  points and a different least squares
line, so the least squares slope and intercept are random.</p>




<h2 class="pageName">5.5.2 &nbsp; Distn of least squares estimates</h2>

<p class="heading notPrinted">Distribution of the least squares slope and intercept</p>
<p>The least squares line<sub></sub> varies from sample
to sample &mdash; it is random.</p>
<p class="eqn"><img src="../../../en/regnEst/images/s_randomLines.gif" width="550" height="290"></p>
<p>The least squares estimates <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub> of
the two linear model parameters β<sub>0</sub> and β<sub>1</sub> therefore also
vary from sample to sample and have normal distributions that are centered
on β<sub>0</sub> and β<sub>1</sub> respectively.</p>
<p class="eqn"><img src="../../../en/regnEst/images/s_slopeInterceptDistn.gif" width="541" height="321"></p>




<h2 class="pageName">5.5.3 &nbsp; Standard error of least squares slope</h2>

<p class="heading notPrinted">Standard error of slope</p>
<p>When <em>b</em><sub>1 </sub> is used as an estimate of β<sub>1</sub>, the
estimation error has a normal distribution,</p>
<p class=eqn><span class="black"><strong>error in estimate of &beta;<sub>1</sub></strong> &nbsp; = &nbsp; (<em>b</em><sub>1</sub> &minus; &beta;<sub>1</sub>) &nbsp; ~ &nbsp; <font face="Arial, Helvetica, sans-serif">normal</font> ( 0, &nbsp;&sigma;<sub><em>b</em><sub>1</sub></sub> )</span> </p>
<p>This standard deviation is the  <strong>standard error</strong> of
the estimate,</p>
<p class=eqn><img class="gif" src="../../../en/regnEst/images/sdSlopeEqn.gif" width="227" height="42"> </p>
<p>where <em>s</em><sub>x </sub> is the standard deviation of  <em>X. </em>Since
σ is unknown, we must replace it with an estimate from
the data to obtain a numerical value for the standard error,</p>
<p class=eqn><img class="gif" src="../../../en/regnEst/images/errorSdEst.gif" width="95" height="41"> </p>
<p class=heading>Example</p>
<p align="center"><img src="../../../en/regnEst/images/radiationCancer.gif" width="550" height="377" class="summaryPict"></p>
<p>The estimated error distribution  gives in indication of how close our least
squares estimate, <em>b</em><sub>1</sub> = 9.27, is likely to be to the population
regression slope, &beta;<sub>1</sub>.</p>




<h2 class="pageName">5.5.4 &nbsp; 95% confidence interval for slope</h2>

<p class="heading notPrinted">Confidence interval for the slope</p>
<p>When the least squares slope, <em>b</em><sub>1</sub>, is used to estimate
β<sub>1</sub>,
the error  has a normal distribution,</p>
<p class=eqn><span class="black"><strong>error in estimate of &beta;<sub>1</sub></strong> &nbsp; = &nbsp; (<em>b</em><sub>1</sub> &minus; &beta;<sub>1</sub>) &nbsp; ~ &nbsp; <font face="Arial, Helvetica, sans-serif">normal</font> ( 0, &nbsp;&sigma;<sub><em>b</em><sub>1</sub></sub> )</span> </p>
<p>This suggests a 95% confidence interval of
the form </p>
<p class=eqn><img class="gif" src="../../../en/regnEst/images/slopeCIFormula2.gif" width="124" height="24"></p>
<p>In practice, we must replace σ in the formula for the standard error with
an estimate (based on the sum of squared residuals),</p>
<p class=eqn><img class="gif" src="../../../en/regnEst/images/sdSlopeEqn2.gif" width="234" height="52"> </p>
<p>so the constant 1.96 must be replaced by a larger
value from the t distribution with
(<em>n</em>&nbsp;-&nbsp;2) degrees of freedom. </p>

<div class="centred"><div class="boxed"><p><strong>A 95% confidence interval for the slope is</strong></p>
<p class=eqn><img class="gif" src="../../../en/regnEst/images/slopeCIFormula.gif" width="121" height="26"></p></div></div>
<p>Most statistical software will evaluate <em>b</em><sub>1</sub> and its standard
error for you when you fit a normal linear model, so it is fairly easy to evaluate
the confidence interval in practice &mdash; you will not need to use any of the formulae
above!</p>
<p class="heading">Example</p>
<p>For the example on the previous page, the least squares estimate of the slope
and its standard error were:
</p>
<p class="eqn"><em>b</em><sub>1</sub> = 9.27,        se (<em>b</em><sub>1</sub>)
= 1.42</p>
<p>Since there were <em>n</em> = 9 data points, <em>t</em><sub><em>n</em> &minus; 2</sub> =
t<sub>7</sub> = 2.365,  so a 95%
confidence interval for the slope is </p>
<p class=eqn><img class="gif" src="../../../en/regnEst/images/radiationCI.gif" width="284" height="39"></p>
<p>We are 95% confident that the expected number of deaths per 100,000
is between 5.9 and 12.6 higher for each unit increase in the exposure index.</p>




<h2 class="pageName">5.5.5 &nbsp; Properties of confidence interval</h2>

<p class="heading notPrinted">Properties of 95% confidence interval</p>
<p>Since a confidence interval for the slope, β<sub>1</sub>, is evaluated from
random sample data, it will vary from sample to sample. In 95% of such samples,
the 95% confidence interval will include the true population slope, but in 5%
of samples it will not.</p>

<div class="centred"><div class="boxed">
<p>We cannot tell whether or not our single data set is one of the 'lucky'
ones.</p>
</div></div>

<p class="heading">Simulation</p>
<p class="eqn"><img src="../../../en/regnEst/images/s_ciSimulation.gif" width="437" height="344"></p>




<h1 class="sectionName breakBefore">5.6 &nbsp; Testing regression parameters</h1>
<h2 class="pageName">5.6.1 &nbsp; Importance of zero slope</h2>

<p class="heading">Does the response depend on X?</p>
<p>In a normal linear model, the response has a distribution whose mean, µ<sub>y</sub>,
depends linearly on the explanatory variable,</p>
<p class=eqn><span class="black"><em>Y</em>&nbsp; ~ &nbsp;<font face="Arial, Helvetica, sans-serif">normal</font> (&mu;<sub>y</sub>&nbsp;, &sigma;)</span> </p>
<p>If the slope parameter, β<sub>1</sub>, is zero, then the response has a normal
distribution that <strong>does not depend on <i>X</i></strong>.</p>
<p class=eqn><span class="black"><em>Y</em> &nbsp; ~ &nbsp; <font face="Arial, Helvetica, sans-serif">normal</font> (&beta;<sub>0</sub> , &nbsp;&sigma;)</span> </p>
<p>This can be tested formally with a hypothesis test for whether β<sub>1</sub> is
zero.</p>




<h2 class="pageName">5.6.2 &nbsp; Testing whether slope is zero</h2>

<p class="heading notPrinted">Testing for zero slope</p>
<p>To assess whether the explanatory variable affects the response, we test the
hypotheses </p>
<p class=eqn><span class="blue"><strong><font size="+1">H</font><sub>0</sub>&nbsp;:&nbsp;&nbsp;&nbsp;</strong>&beta;<sub>1</sub> &nbsp;=&nbsp; 0<br><strong><font size="+1">H</font><sub>A</sub>&nbsp;:&nbsp;&nbsp;&nbsp;</strong>&beta;<sub>1</sub>  &nbsp;&ne;&nbsp;  0</span> </p>
<p>The test is based on how far the least squares slope, <em>b</em><sub>1</sub>,
is from zero. To assess this, we must take into account its standard deviation
(standard error),</p>
<p class=eqn><img class="gif" src="../../../en/regnTest/images/sdSlopeEqn.gif" width="129" height="42"> </p>
<p>If we knew the value of σ, we could  standardise <em>b</em><sub>1</sub> to
get a test statistic,</p>
<div class="centred">
	<table border="0" cellspacing="0" cellpadding="10" class="centred">
		<tr>
			<th style="margin:0px; padding:0px"><span class="black bold">standardised value,</span>&nbsp;&nbsp;&nbsp;</th>
			<td style="margin:0px; padding:0px"><span class="eqn"><img class="gif" src="../../../en/regnTest/images/standardisedSlope.gif" width="85" height="43">
			</span></td>
		</tr>
	</table>
</div>
<p class=eqn>&nbsp;</p>
<p>If β<sub>1</sub> was really zero (<strong>H<sub>0</sub></strong>), the probability
of getting a least squares slope as far from zero as that recorded would be the
p-value,</p>
<p class=eqn><img class="gif" src="../../../en/regnTest/images/zForTestingSlope.gif" width="294" height="141"></p>
<p>Unfortunately σ is usually unknown and the standard deviation of <em>b</em><sub>1</sub> must
be <a href="javascript:showNamedPage('regnEst4')">estimated from the sample
data</a>. We therefore use a test statistic of the form </p>
<div class="centred">
	<table border="0" cellspacing="0" cellpadding="10" class="centred">
		<tr>
			<th style="margin:0px; padding:0px"><span class="black bold">t ratio,</span>&nbsp;&nbsp;&nbsp;</th>
			<td style="margin:0px; padding:0px"><span class="eqn"><img class="gif" src="../../../en/regnTest/images/standardisedSlope2.gif" width="69" height="48">
			</span></td>
		</tr>
	</table>
</div>
<p>and refer to a t distribution with <i><span class="black">n</span></i><span class="black">&nbsp;-&nbsp;2</span> degrees
of freedom to find the p-value.</p>
<p class=eqn><img class="gif" src="../../../en/regnTest/images/slopeTestP.gif" width="426" height="268"> </p>
<p>The p-value is interpreted in the same way as for other hypothesis tests &mdash;
a p-value close to zero means that the sample slope is far enough from zero to
be inconsistent with <strong>H<sub>0</sub>: &beta;<sub>1</sub> = 0</strong>.</p>
<p class="heading">Examples</p>
<p align="center"><img src="../../../en/regnTest/images/possumDamage.gif" width="550" height="442" class="summaryPict"></p>
<p align="center"><img src="../../../en/regnTest/images/alcoholStrength.gif" width="550" height="442" class="summaryPict"></p>





<h1 class="sectionName breakBefore">5.7 &nbsp; Exercises</h1>
</body>
</html>
