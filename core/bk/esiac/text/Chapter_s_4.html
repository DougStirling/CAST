<!DOCTYPE HTML>
<html>
<head>
  <title>4. Numerical Summaries</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="../../../structure/summaryStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/maths/mathStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/printStyles.css" type="text/css">
  <script src="../../../structure/videoControls/jquery.js"></script>
  <script src="../../../structure/maths/theorems.js"></script>
  <script src="../../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js"></script>
  <script src="../../../structure/printFixes.js"></script>
</head>

<body id="body" onLoad="showPrintDialog(true)">
<div id='overlay'>
	<div id='dialogWindow'>
		<div class='printDialog'>
			<script type='text/javascript'>
				document.write("<div class='heading'>" + top.document.title + "</div>");
				if (top.url != null) {
					document.write("<p class='text'>A version of this chapter has already been generated in PDF format and we recommend that it is used for printing. The button below will download and display it.</p>");
					document.write("<p><button onClick='top.showPdf()'>Show PDF version of chapter</button></p>");
					document.write("<p class='text'>However downloading could be slow depending on your internet connection. If this is a problem, click the button below to print the chapter without downloading (but perhaps not formatted as well as the PDF version).</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>If you are <strong>not</strong> using the PDF version, the best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
				else {
					document.write("<p class='text'>Click the button below to print this chapter.</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>The best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
			</script>
			
			<p class='text'>If you don't want to print now,</p>
			<p><button onClick='top.showPrintDialog(false)'>Browse formatted chapter</button></p>
		</div>
	</div>
</div>
<h1 class="chapterName">Chapter 4 &nbsp; Numerical Summaries</h1>
<h1 class="sectionName">4.1 &nbsp; Describing centre</h1>
<h2 class="pageName">4.1.1 &nbsp; Centre and spread</h2>

<p class="heading notPrinted">Summarising centre and spread</p>
	<p>Two important 
		aspects of a distribution of values are particularly important.</p>
	<dl>
		<dt>Centre</dt>
		<dd>The centre  is a 'typical' value around which the data 
			are located.</dd>
		<dt>Spread</dt>
		<dd>The spread  describes the distance of the individual 
			values from the centre.</dd>
	</dl>
	<p class=eqn><img class="gif" src="../../../en/centerSpread/images/centerSpreadIdea.gif" width="325" height="109"> </p>
	<p>We will describe centre and spread with numerical 
		values called <strong>summary statistics</strong>. They provide particularly
concise and meaningful comparisons of different groups.</p>





<h2 class="pageName">4.1.2 &nbsp; Median, range and IQR</h2>

<p class="heading">Simple summaries of centre and spread</p>
	<dl>
		<dt>Centre</dt>
		<dd>The <strong>median</strong> is the simplest measure of centre. Half the
 data values are more than it, and half less.</dd>
		<dt>Spread</dt>
		<dd>The <strong>range</strong> (maximum - minimum) and <strong>interquartile 
			range</strong> (upper quartile - lower quartile) are two different summary 
			statistics that describe the spread of values in a data set.</dd>
	</dl>
	<p class=heading>Information from median and interquartile range</p>
	<p>Given the median and interquartile range, it is possible to sketch a bell-shaped 
		histogram that matches these values. Such a 'guess' is often close to the 
		actual distribution of values.</p>
	<p class=eqn><img class="gif" src="../../../en/centerSpread/images/iqrAndHisto.gif" width="424" height="223"></p>





<h2 class="pageName">4.1.3 &nbsp; Summaries of centre</h2>

<p class=heading>Median</p>
	<p>Half of the data values are below the median and half are above it:</p>
	<p class=eqn><img class="gif" src="../../../en/centerSpread/images/medianProperties.gif" width="500" height="140"></p>
	<p class=heading>Mean</p>
	<p>The mean  is: </p>
	<p class=eqn><img class="gif" src="../../../en/centerSpread/images/meanEqn.gif" width="70" height="35"> </p>
	<p>If each value in a dot plot was a solid object resting on a beam with negligible mass, the mean is the value at which the beam will balance.</p>
	<p class=eqn><img src="../../../en/centerSpread/images/s_balance.gif" width="451" height="139"> </p>
	<p>The  standard deviation  is denoted by the letter <span class="black em">s</span>  and
is defined by:</p>
<p class="eqn"><img class="gif" src="../../../en/centerSpread/images/sdDefn.gif" width="115" height="52"></p>
	<p>The numerator, <span class="eqn"><img class="gif" src="../../../en/centerSpread/images/ssqDevns.gif" width="70" height="26"></span>, depends on the distances of the values to the mean, so it will be small if the values are all close to the mean and big if they are far from the mean.</p>
	<p class="heading">Variance</p>
	<p>The square of the standard deviation, <em>s</em><sup>2</sup>, is called the
sample <strong>variance</strong>. Variances are sometimes reported and used but
standard deviations are easier to interpret since they have  the same units as
the original data (e.g. kilograms or dollars).</p>

 


<h2 class="pageName">4.2.2 &nbsp; Rules of thumb for st devn</h2>

<p class="heading">'Quarter-range' rule of thumb</p>
	<p>For many data sets, the standard deviation is just under 
		a quarter of the range.</p>

<div class="centred"><table border="0" cellpadding="12" cellspacing="0" class="centred">
	<tr>
		<td bgcolor="#DDDDDD"><img class="gif" src="../../../en/centerSpread/images/deviations2.gif" width="454" height="158"></td>
	</tr>
</table></div>

	<p>This is a simple rule, but is only very approximate. The standard deviation 
		can be more than a quarter the range in distributions with short tails or 
		much less if there are long tails or outliers.</p>
	<p class="heading">The 70-95-100 rule of thumb</p>
	<p>The <strong>70-95-100 rule</strong> is more accurate. In many distributions, </p>
	<ul>
		<li>Approximately 70% of the values are within 1 standard deviation of the mean.</li>
		<li>Approximately 95% of the values are within 2 standard deviations of the mean.</li>
		<li>Nearly all of the values are within 3 standard deviations of the mean.</li>
	</ul>
	<p>The 70-95-100 rule holds approximately for most reasonably symmetric data 
		sets, but for skew data or distributions with long tails, outliers or clusters, it is often less accurate.</p>




<h2 class="pageName">4.2.3 &nbsp; Understanding means and st devns</h2>

<p>Understanding the
		definition of the standard deviation is much less important than knowing
its properties and having a feel for what its numerical value tells you about
the data. </p>
	<p class="heading">Guessing <em>s</em> from histogram</p>
<p>About 95% of the values should 
		be within 2<em>s</em> of the mean, so after dropping the top 2.5% 
		and bottom 2.5% of the values (histogram area), the remainder should 
		span approximately 4<em>s</em>. Dividing this range by 4 should 
		approximate the standard deviation.</p>
	<p class=eqn><img class="gif" src="../../../en/centerSpread/images/guessSD.gif" width="288" height="154"> </p>
	<p class="heading">Sketching a histogram from the mean and <em>s</em></p>
<p>Similarly, you should 
		be able to draw a rough sketch of a symmetric histogram with any mean and
standard deviation that you are given. (It would be centred on the mean and 95%
of the area would be within 2<em>s</em> of this.)</p>




<h2 class="pageName">4.2.4 &nbsp; Warnings about mean &amp; st devn</h2>

<p class="heading notPrinted">The shape of a distribution</p>
	<div class="centred"><table width="75%" border="1" class="centred" cellpadding="10" cellspacing="0">
		<tr>
			<td bgcolor="#FFFFFF"><strong>The mean and standard deviation hold <span class="red">no information about the shape</span> of a distribution, other than its centre 
				and spread.</strong></td>
		</tr>
	</table></div>
	<p>Many different distributions have the same mean and standard deviation.</p>
	<p class=eqn><img src="../../../en/centerSpread/images/s_anscombe.gif" width="399" height="435"></p>
<p>More generally,</p>
	<p class="eqn"><img class="gif" src="../../../en/counts/images/meanCountEqn.gif" width="97" height="37"></p>
	<p>where the summation is over the distinct values in the data set, rather than 
		all individuals.</p>
	<p class=heading>Calculating the standard deviation</p>
	<p>A similar formula holds for the standard deviation, using the formula</p>
	<p class="eqn"><img class="gif" src="../../../en/counts/images/ssqEqn.gif" width="307" height="41"></p>




<h1 class="sectionName breakBefore">4.3 &nbsp; Variation and groups</h1>
<h2 class="pageName">4.3.1 &nbsp; Standard deviation of grouped data</h2>

<p class="heading">Within-group and overall standard deviation</p>
	<p>In some data sets, the 'individuals' can be split into groups.</p>
	<p class="eqn"><img src="../../../en/moreVariation/images/s_groups.gif" width="499" height="351"></td>
<td class="green">The <strong>total sum of squares</strong> reflects
the total variability of the response.</td>
</tr>
</table></div>
<p>The overall variance of all values (ignoring 
groups) is the total sum of squares divided by (<em>n</em>&nbsp;-&nbsp;1).</p>
<p class="eqn"><img src="../../../en/multiGroup/images/s_totalSsq.gif" width="413" height="277"></td>
<td class="red">The <strong> sum of squares between groups</strong> measures
the variability of the group means.</td>
</tr>
</table></div>
<p>Variation between groups is summarised by the differences between the group
means and the overall mean. Note that the summation  is <span class="black bold">over
all observations in the data set</span>.</p>
<p class="eqn"><img src="../../../en/multiGroup/images/s_betweenSsq.gif" width="413" height="277"></td>
<td class="blue">The <strong> sum of squares within groups</strong> quantifies
the spread of values within each group.</td>
</tr>
</table></div>
<p>This is also called the <strong>residual</strong> sum of squares since it
describes variability that is unexplained by differences between the groups.
Note that the pooled estimate of the common variance, σ<sup>2</sup>, is the sum
of squares within groups divided by (<em>n</em>&nbsp;-&nbsp;<em>g</em>).</p>
<p class="eqn"><img src="../../../en/multiGroup/images/s_withinSsq.gif" width="413" height="277"> </p>




<h2 class="pageName">4.3.5 &nbsp; Coefficient of determination</h2>

<p class="heading notPrinted">Sums of squares</p>
<div class="centred"><table border="0" class="centred" cellpadding="4" cellspacing="0">
<tr>
<th align="left">Sum of squares</th>
<th>Interpretation</th>
</tr>
<tr>
<td><img class="gif" src="../../../en/multiGroup/images/totalSsq2.gif" width="141" height="25">
<td>Overall variability of <em>Y</em>, taking no account of the groups.</td>
</tr>
<tr>
<td><img class="gif" src="../../../en/multiGroup/images/residSsq2.gif" width="154" height="25">
<td>Variability
that <strong>cannot be explained</strong> by the model.</td>
</tr>
<tr>
<td><img class="gif" src="../../../en/multiGroup/images/regnSsq2.gif" width="149" height="24">
<td>Variability that is <strong>explained</strong> by
the model.</td>
</tr>
</table></div>
<p class="heading">Coefficient of determination</p>
<p>The <strong>proportion</strong> of
the total sum of squares that is explained by the model is called
the <strong>coefficient of determination</strong>,</p>
<p class=eqn><img class="gif" src="../../../en/multiGroup/images/rSquaredDefn.gif" width="97" height="38"> </p>
<ul>
<li>0  ≤  R<sup>2</sup>  ≤  1</li>
<li>The proportion of <strong>unexplained</strong> variation is (1&nbsp;-&nbsp;R<sup>2</sup>)</li>
<li>When R<sup>2</sup> &asymp; 0, the group means are similar
to each other.</li>
<li>If R<sup>2</sup> &asymp; 1, the individual values must be  close
to their group means.</li>
</ul>
<p class="heading">Example</p>
<p align="center"><img src="../../../en/multiGroup/images/radiocarbonR2.gif" width="555" height="344"></td>
<td class="green">The <strong>mean total sum of squares</strong> is the
sample variance of the response (ignoring groups).</td>
</tr>
<tr>
<td><img class="gif" src="../../../en/multiGroup/images/residMss.gif" width="143" height="43"></td>
<td class="blue">The <strong>mean within-group sum of squares</strong> is
the pooled estimate of the variance within groups.</td>
</tr>
<tr>
<td><img class="gif" src="../../../en/multiGroup/images/regnMss.gif" width="162" height="43"></td>
<td class="red">The <strong>mean between-group sum of squares</strong> is
harder to directly interpret.</td>
</tr>
</table></div>
<p>The numerators in these ratios add up:</p>
<p class="eqn"><span class="green">SS<sub>Total</sub></span>  =  <span class="red">SS<sub>Between</sub></span>  +  <span class="blue">SS<sub>Within</sub></span></p>
<p>and the same relationship holds for their denominators (degrees of freedom):</p>
<p class="eqn"><span class="green">df<sub>Total</sub></span>  =  <span class="red">df<sub>Between</sub></span>  +  <span class="blue">df<sub>Within</sub></span></p>
<p class="heading">F ratio and p-value</p>
<p>The test statistic is  an <strong>F-ratio</strong>,</p>
<p class=eqn><img class="gif" src="../../../en/multiGroup/images/fRatio.gif" width="114" height="37"> </p>
<p>This test statistic compares between- and within-group variation. The further
apart the group means, the larger <span class="red">SS<sub>Between</sub></span> and the larger the F-ratio.<br>
</p>

<div class="centred"><div class="boxed">
<p>Large values of F suggest that H<sub>0</sub> does
not hold &mdash; that the group means are not the same.</p>
</div></div>

<p>The p-value for the test is the probability of such a high F ratio if <strong>H<sub>0</sub></strong> is
true (all group means are the same). It is based on a standard distribution called
an <strong>F distribution</strong> and is interpreted in the same way as other
p-values. </p>

<div class="centred"><div class="boxed">
<p>The closer the p-value to zero, the stronger the evidence
that H<sub>0</sub> does not hold.</p>
</div></div>

<p class="heading">Analysis of variance table</p>
<p>An <strong>analysis
of variance table</strong> (<strong>anova table</strong>) describes some of the calculations
above:</p>
<p class=eqn><img class="gif" src="../../../en/multiGroup/images/anovaTable2.gif" width="596" height="192"></p>




<h1 class="sectionName breakBefore">4.4 &nbsp; More about variation (optional)</h1>
<h2 class="pageName">4.4.1 &nbsp; Variance and degrees of freedom</h2>

<p class="heading">Variance</p>
	<p class=eqn style="color:#000000"><strong>variance &nbsp; = &nbsp; (standard deviation)<sup>2</sup> &nbsp; = &nbsp; </strong><img class="gif" src="../../../en/moreVariation/images/variance.gif" width="74" height="45"> </p>
	<p>The units of the variance are the <strong>square</strong> of 
		the units of the original values. For example, if the values are weights,
the standard deviation might be 6 kg, but the variance would be 36 <strong>square
kg</strong>. Since its units are easier to interpret, standard deviations are
more easily understood measures of spread, but variances are important in  advanced
statistics. (An important collection of methods for analysing relationships between
variables is called <strong>analysis of variance</strong>.)</p>
<p class="heading">Degrees of freedom (optional)</p>
	<p>The divisor (<em>n</em>&nbsp;&minus;&nbsp;1) in the formula for the sample standard 
		deviation is called its <strong>degrees of freedom</strong>. This is the number of 'independent pieces of information' that contribute to 
		it.</p>
	<dl>
		<dt>Sample of size <em>n</em>&nbsp;=&nbsp;1</dt>
		<dd>With only a single value, there is no information about the spread of 
			values, so there are 0 degrees of freedom.</dd>
		<dt>Sample of size <em>n</em>&nbsp;=&nbsp;2</dt>
		<dd>With two values, <em>x</em><sub>1</sub> and <em>x</em><sub>2</sub>, there
 is only a single piece of information about the spread &mdash; the difference 
			between the values, <em>x</em><sub>1</sub> &minus; <em>x</em><sub>2</sub> &mdash; 
			and there is one degree of freedom. </dd>
	<dt>Sample of size <em>n</em></dt>
		<dd>In general, there is one less 'piece of information about the spread' 
			in the sample than the number of data points because the sample mean, <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline">, 
			is one piece of information that does not give any information about the 
			spread of the data. There are therefore  (<em>n</em>&nbsp;&minus;&nbsp;1) 
			degrees of freedom.</dd>
	</dl>




<h2 class="pageName">4.4.2 &nbsp; Root mean squared error</h2>

<p class="heading">Distance of values from a target, <em>k</em></p>
<p>The distance of a single random value from a target is called its <strong>error</strong>.</p>
<p class=eqn style="color:#000000"><img src="../../../en/moreVariation/images/s_errorOne.gif" width="316" height="130"></p>
<p class="heading">Root mean squared error</p>
<p>One solution to the problem of negative errors is to square them before averaging,</p>
<p class=eqn style="color:#000000"><strong>mean squared error &nbsp; = &nbsp; </strong><img class="gif" src="../../../en/moreVariation/images/meanSqrError.gif" width="77" height="44"></p>
<p>To express this in the original units of the data (instead of units such as
squared kg), we can take its square root:</p>
<p class=eqn style="color:#000000"><span class="eqn" style="color:#000000"><strong>root
mean squared error &nbsp; = &nbsp; </strong><img class="gif" src="../../../en/moreVariation/images/rootMeanSqrError.gif" width="90" height="50"></span></p>

<div class="centred"><div class="boxed">
<p>The root mean squared error is a 
				'typical' error.</p>
</div></div>




<h2 class="pageName">4.4.3 &nbsp; Distances from the mean</h2>

<p class="heading">Distances from the <span class="darkred">centre</span> of the 
		distribution</p>
	<p>The <strong>population standard deviation</strong> is similar to the root mean square error but  summarises the distances of the values from the <strong>centre of their 
		distribution</strong>. It summarises the spread of values in the data.</p>
	<p class=eqn style="color:#000000"><strong>population standard deviation &nbsp; = &nbsp; </strong><img class="gif" src="../../../en/moreVariation/images/stDevn.gif" width="89" height="49"></p>
	<p>This can be illustrated graphically &mdash; the squared standard deviation is
the average of the squared distances of values to their mean:</p>
<p class="eqn"><img src="../../../en/moreVariation/images/s_squareAreas.gif" width="449" height="254"></p>
</div>
</div>
<p>Standard deviations 
		in  reports are likely to be  <strong>sample</strong> standard deviation.</p>

	


</body>
</html>
