<html>
<head>
<title>11. En comparant des groupes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 11 &nbsp; En comparant des groupes</h1>
<h2>11.1 &nbsp; Models for two groups</h2>
<h3>11.1.1 &nbsp; Interest in underlying population</h3>
<p>As with single-group data, the populations underlying two-group data sets are usually of more interest than the specific sample data.</p>
<h3>11.1.2 &nbsp; Model for two groups</h3>
<p>Two-group data sets are often modelled as separate random samples from two normal populations.</p>
<h3>11.1.3 &nbsp; Parameters of the normal model</h3>
<p>The normal model has four parameters — the means and standard deviations in the two groups.</p>
<h3>11.1.4 &nbsp; Parameter estimates</h3>
<p>The parameters of the normal model can be estimated by the sample means and standard deviations in the two groups.</p>
<h3>11.1.5 &nbsp; Difference between means</h3>
<p>The difference between the population means is of particular interest. The difference between the sample means provides an estimate. It varies from sample to sample and has a distribution.</p>
<h2>11.2 &nbsp; Distribution des sommes et des différences</h2>
<h3>11.2.1 &nbsp; Means and sums of random samples</h3>
<p>La moyenne d'un échantillon aléatoire est approximativement normale avec sd égale à σ divisé par √n. La somme d'un échantillon aléatoire est également à peu près normale, mais son sd est √nσ.</p>
<h3>11.2.2 &nbsp; Sum and differences</h3>
<p>La somme et la différence de deux variables normales indépendantes sont également distribuées normalement. Si elles ont le même écart-type, σ, la somme et de la différence les deux ont 1.414σ de déviation standard. (Leur écart est 2σ².)</p>
<h3>11.2.3 &nbsp; Sums and differences (cont)</h3>
<p>Cette page généralise les résultats à la somme et la différence des variables dont les déviations standard peut être différent.</p>
<h3>11.2.4 &nbsp; Probabilities for sums and differences</h3>
<p>Si deux variables sont indépendants et ont des distributions normales, les probabilités relatives à leur somme et la différence peuvent être trouvés en utilisant les formules pour la moyenne et l'écart type des sommes et des différences.</p>
<h2>11.3 &nbsp; Comparing means in two groups</h2>
<h3>11.3.1 &nbsp; Distn of difference between means</h3>
<p>The difference between the means of two samples from normal populations has a normal distribution whose mean and s.d. can be found from the population means and s.d.s. This is the approximate distribution even when the populations are non-normal.</p>
<h3>11.3.2 &nbsp; Distribution of estimation error</h3>
<p>When the difference between the sample means is used to estimate the difference between the underlying population means, there is likely to be an error. The error distribution is approximately normal with mean 0. A formula for its standard deviation is given.</p>
<h3>11.3.3 &nbsp; CI for difference between means</h3>
<p>A 95% confidence interval is given for the difference between two population means. Its properties are demonstrated.</p>
<h3>11.3.4 &nbsp; Testing a hypothesis</h3>
<p>A hypothesis test is developed for testing whether two group means are the same.</p>
<h3>11.3.5 &nbsp; One-tailed tests for differences</h3>
<p>If the alternative hypothesis is for one particular mean to be greater, then the p-value for the test is found from only one tail of the t distribution.</p>
<h2>11.4 &nbsp; Comparaison de deux proportions</h2>
<h3>11.4.1 &nbsp; Modelling two proportions</h3>
<p>Deux groupes de données catégoriques peuvent être modélisés comme des échantillons provenant de deux populations catégoriques avec des probabilités différentes de «succès».</p>
<h3>11.4.2 &nbsp; Distribution of difference in proportions</h3>
<p>La différence entre deux proportions de l'échantillon a une distribution qui est à peu près normale et dont les paramètres peuvent être estimés à partir des résultats antérieurs sur la moyenne et l'écart type des différences.</p>
<h3>11.4.3 &nbsp; CI for difference in proportions</h3>
<p>L'écart-type de la différence entre deux proportions de l'échantillon peut être estimé. De là, un intervalle de confiance de 95% a été développé pour la différence entre les deux probabilités.</p>
<h3>11.4.4 &nbsp; Testing for difference in probabilities</h3>
<p>Un test d'hypothèse est conçu pour déterminer si deux probabilités de population sont identiques.</p>
<h2>11.5 &nbsp; Paired t test</h2>
<h3>11.5.1 &nbsp; Paired data examples</h3>
<p>Paired data are a type of bivariate data in which two similar measurements are made from each individual. We are usually interested in testing whether the means of both measurements are the same.</p>
<h3>11.5.2 &nbsp; Analysis of differences</h3>
<p>For paired data, differences between the two measurements hold all information about whether the means of both variables are the same.</p>
<h3>11.5.3 &nbsp; Paired t-test</h3>
<p>Testing for a difference between the means of the measurements is done with an ordinary t-test for whether the mean difference is zero.</p>
<h3>11.5.4 &nbsp; Pairing and experimental design</h3>
<p>To estimate or test the difference between two means, it is sometimes possible to collect data from two independent samples or from paired units. If the paired units are similar, a pair data gives more accurate results.</p>
<h2>11.6 &nbsp; Comparing several means</h2>
<h3>11.6.1 &nbsp; Model with common standard deviation</h3>
<p>To compare the means of several groups, a model of normal distributions in all groups is used but all group standard deviations must be assumed to be the same.</p>
<h3>11.6.2 &nbsp; Estimate of common standard deviation</h3>
<p>The sample standard deviations in the separate groups can be combined to give a pooled estimate of the common standard deviation, σ.</p>
<h3>11.6.3 &nbsp; Inference about two groups ((optional))</h3>
<p>Earlier CIs and tests for equality of two group means can be improved when the group standard deviations are known to be the same. However this refinement is not recommended for general use.</p>
<h3>11.6.4 &nbsp; Assessing differences between groups</h3>
<p>Both variability between group means and variability within groups must be used to assess whether the groups differ.</p>
<h3>11.6.5 &nbsp; Sums of squares</h3>
<p>Variability within groups and between groups are described by sums of squares.</p>
<h3>11.6.6 &nbsp; Coefficient of determination</h3>
<p>The coefficient of determination (R-squared) is the ratio of the between-groups and total sums of squares. It is the proportion of variation that can be explained by differences between the groups.</p>
<h3>11.6.7 &nbsp; Test for differences between groups</h3>
<p>The F-ratio is a test statistic that is based on the between- and within-groups sums of squares. The associated p-value tests whether all groups have the same mean.</p>
<h3>11.6.8 &nbsp; Examples</h3>
<p>The F-test is applied to a few data sets.</p>
<h2>11.7 &nbsp; Blocs randomisés</h2>
<h3>11.7.1 &nbsp; Generalising the idea of paired data</h3>
<p>Dans certains ensembles de données, les valeurs se présentent dans des blocs de 3 ou plus apparentées mesures. Bloc randomisé et les données de mesure sont répétées de ce formulaire.</p>
<h3>11.7.2 &nbsp; Importance of using block information</h3>
<p>Ignorant le blocage de valeurs perd des informations importantes à propos de la différence entre les traitements. En comparant les traitements séparément contre un traitement de référence utilisant les différences appariées peut être possible.</p>
<h3>11.7.3 &nbsp; Data with no baseline treatment</h3>
<p>Si il n'y a pas de traitement de référence à laquelle comparer les autres mesures dans chaque bloc, il est possible de tester simultanément si tous les moyens de traitement sont égaux. Encore une fois, en ignorant les blocs perd des informations importantes.</p>
<h3>11.7.4 &nbsp; Randomised block designs</h3>
<p>Les données de cette forme se pose souvent d'une expérience en blocs aléatoires dans lequel les unités expérimentales se produisent dans les blocs et les traitements connexes sont répartis de façon aléatoire dans chaque bloc.</p>
<h3>11.7.5 &nbsp; Model for randomised blocks ((facultatif))</h3>
<p>Bien que les blocs et les traitements se posent de manière différente, ils sont modélisées de manière similaire. Dispositif d'affichage en 3 dimensions des données représente les deux blocs et les traitements de la même manière.</p>
<h3>11.7.6 &nbsp; Removing block effects</h3>
<p> La variation entre les blocs peut être éliminé par l'addition / soustraction d'une valeur pour chaque bloc à bloc des moyens de faire toute égal. Cela réduit la valeur résiduelle (inexpliquée) somme des carrés.</p>
<h3>11.7.7 &nbsp; Sums of squares</h3>
<p>La somme totale des carrés peut être divisée en sommes de carrés pour les blocs et les traitements, et une somme des carrés des résidus.</p>
<h3>11.7.8 &nbsp; Anova table and examples</h3>
<p>Une table d'analyse de variance montre ces sommes de carrés et de degrés de liberté associés. Le rapport F pour les traitements de la table est la base d'un test de moyens d'égalité de traitement. Plusieurs exemples sont donnés.</p>
</body>
</html>
