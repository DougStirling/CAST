<html>
<head>
<title>21. Investigate Bivariate Data (3.09)</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/printStyles.css" type="text/css">
<script src="../../../structure/printFixes.js"></script>
<link rel="stylesheet" href="../../../structure/summaryStyles.css" type="text/css">
<script type='text/javascript'>function outputExercise() {};</script>
</head>

<body id="body" onLoad="showPrintDialog(true)">
<div id='overlay'>
	<div id='dialogWindow'>
		<div class='printDialog'>
			<script type='text/javascript'>
				document.write("<div class='heading'>" + top.document.title + "</div>");
				if (top.url != null) {
					document.write("<p class='text'>A version of this chapter has already been generated in PDF format and we recommend that it is used for printing. The button below will download and display it.</p>");
					document.write("<p><button onClick='top.showPdf()'>Show PDF version of chapter</button></p>");
					document.write("<p class='text'>However downloading could be slow depending on your internet connection. If this is a problem, click the button below to print the chapter without downloading (but perhaps not formatted as well as the PDF version).</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>If you are <strong>not</strong> using the PDF version, the best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
				else {
					document.write("<p class='text'>Click the button below to print this chapter.</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>The best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
			</script>
			
			<p class='text'>If you don't want to print now,</p>
			<p><button onClick='top.showPrintDialog(false)'>Browse formatted chapter</button></p>
		</div>
	</div>
</div>
<h1 class="chapterName">Chapter 21 &nbsp; Investigate Bivariate Data (3.09)</h1>
<h1 class="sectionName">21.1 &nbsp; Correlation</h1>
<div class='leftTocCol'>
<ol class='toc'>
<li>Correlation coefficient and its properties</li>
<li>Nonlinear relationships</li>
<li>R does not tell the whole story</li>
</ol>
</div>
<div class='rightTocCol'>
<ol class='toc' start='4'>
<li>Exercise: Estimate r by eye</li>
<li>Exercise: r for non-standard data</li>
</ol>
</div>
<br clear='all'>
<h2 class="pageName">21.1.1 &nbsp; Correlation coefficient and its properties</h2><!DOCTYPE HTML>


<p class="heading">Definition</p>
<p>The <strong>correlation coefficient</strong> is usually defined by the formula </p>
	<p class=eqn><img class="gif" src="../../en/correlation/images/corrDefn2.gif" id="gif_image_1_1_1" width="213" height="67"><iframe class="svg" src="../../en/correlation/images/corrDefn2.svg" id="svg_image_1_1_1" width="213" height="67" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_1_1_1");</script></p>
	<p class="heading">How does <i>r</i> relate to the shape of a scatterplot?</p>
	<p>The following properties of <i>r</i> explain in general terms how its value 
		is related to the strength of a relationship in any particular scatterplot.</p>
	<table border="0" cellpadding="5" cellspacing="0" class="centred">
<tr>
			<td class="col1" bgcolor="#D2EDFF"><img class="gif" src="../../en/correlation/images/property1.gif" id="gif_image_1_1_2" width="224" height="92"><iframe class="svg" src="../../en/correlation/images/property1.svg" id="svg_image_1_1_2" width="224" height="92" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_1_1_2");</script></td>
			<td bgcolor="#D2EDFF"><img class="gif" src="../../en/correlation/images/property1.gif" id="gif_image_1_1_3" width="224" height="92"><iframe class="svg" src="../../en/correlation/images/property1.svg" id="svg_image_1_1_3" width="224" height="92" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_1_1_3");</script></td>
		</tr>
		<tr>
			<td colspan="2" align="center" bgcolor="#F9FFF8" class="col1"><img class="gif" src="../../en/correlation/images/property3.gif" id="gif_image_1_1_4" width="219" height="92"><iframe class="svg" src="../../en/correlation/images/property3.svg" id="svg_image_1_1_4" width="219" height="92" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_1_1_4");</script></td>
		</tr>
		<tr>
			<td class="col1" bgcolor="#D2EDFF"><img class="gif" src="../../en/correlation/images/property4.gif" id="gif_image_1_1_5" width="224" height="92"><iframe class="svg" src="../../en/correlation/images/property4.svg" id="svg_image_1_1_5" width="224" height="92" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_1_1_5");</script></td>
			<td bgcolor="#D2EDFF"><img class="gif" src="../../en/correlation/images/property5.gif" id="gif_image_1_1_6" width="224" height="92"><iframe class="svg" src="../../en/correlation/images/property5.svg" id="svg_image_1_1_6" width="224" height="92" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_1_1_6");</script></td>
		</tr>
		<tr>
			<td height="50" colspan="2" align="center" bgcolor="#F9FFF8" class="col1"><span class="black">&minus;1 &nbsp;&le;&nbsp; <em>r</em> &nbsp;&le;&nbsp; +1</span></td>
	</tr>
	</table>




<h2 class="pageName">21.1.2 &nbsp; Nonlinear relationships</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Correlation and nonlinear relationships</p>
	<p>The correlation coefficient, <i>r</i>, is a good description of the strength
of a relationship <strong>provided the crosses in a scatterplot of the data are not
scattered round a curve</strong>. If the data are scattered round a curve, the relationship
is called <strong>nonlinear</strong> and <i>r</i> may seriously underestimate its
strength.</p>
<p class="eqn"><img src="../../../en/correlation/images/s_curved.gif" width="556" height="246"></p>
	
<div class="centred"><div class="boxed">
<p>The correlation coefficient does <strong>not</strong> describe
the strength of nonlinear relationships adequately.</p>
</div></div>

	



<h2 class="pageName">21.1.3 &nbsp; R does not tell the whole story</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Always look at a scatterplot first</p>
	<p>Although the correlation coefficient is a good description of the strength 
		of many relationships, it does not adequately describe others.</p>
	
<div class="centred"><div class="boxed">
<p>A scatterplot should always be examined to help 
				assess whether there are features in the data that the correlation coefficient 
				cannot describe.</p>
</div></div>

	<p>The data sets below share the same value of <em>r</em> = 0.816 (and the same
means and st devns for <em>X</em> and <em>Y</em>) but their scatterplots show
that different conclusions should be drawn from them.</p>
	<p align="center"><img src="../../../en/correlation/images/s_anscombe.gif" width="550" height="440"></p>




<h2 class="pageName">21.1.4 &nbsp; Exercise: Estimate r by eye</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.1.5 &nbsp; Exercise: r for non-standard data</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h1 class="sectionName breakBefore">21.2 &nbsp; Least squares</h1>
<div class='leftTocCol'>
<ol class='toc'>
<li>Predicting Y from X</li>
<li>Linear models</li>
<li>Fitted values and residuals</li>
<li>Least squares</li>
<li>Curvature and outliers</li>
<li>Residual plots</li>
<li>Predicting Y and predicting X</li>
</ol>
</div>
<div class='rightTocCol'>
<ol class='toc' start='8'>
<li>Exercise: Pick the explanatory variable and response</li>
<li>Exercise: Draw a straight line</li>
<li>Exercise: Find the slope and intercept</li>
<li>Exercise: Interpret the slope and intercept</li>
<li>Exercise: Find a residual</li>
<li>Exercise: Match data and residual plot</li>
<li>Exercise: Predictions</li>
</ol>
</div>
<br clear='all'>
<h2 class="pageName">21.2.1 &nbsp; Predicting Y from X</h2><!DOCTYPE HTML>


<p class="heading">The notion of prediction</p>
	<dl>
		<dt>Causal relationships</dt>
		<dd>If one variable, <em>X</em>, is thought to directly affect the 
			other, <em>Y</em>, we might hope to predict 
			the value of <em>Y</em> if the value of <em>X</em> is changed.<br>
		</dd>
		<dt>Non-causal relationships</dt>
		<dd>Even if the relationship is not causal, we are often still interested 
			in predicting the value of one variable from a known value of the other 
			variable.<br>
		</dd>
	</dl>
	<p class="heading">Notation and convention</p>
	<p>If the variables can be classified as an <strong>explanatory 
		variable</strong> and a <strong>response</strong>, we  use the letter<i> X</i> to denote the explanatory 
		variable and <i>Y</i> to denote the response.</p>
	
<div class="centred"><div class="boxed">
<p>Always draw the response variable, <i>Y</i>, on the vertical 
				axis of a scatterplot and <i>X</i> on the horizontal axis.</p>
</div></div>

	<p class="heading">Predicting the response</p>
	<p>The correlation coefficient describes the <strong>strength</strong> of a
 relationship, but does not help you to predict <em>Y</em> from <em>X</em>.</p>
<p>A  curve or
straight line that is drawn close to the crosses on a scatterplot (by eye or
by any other method) is called a <strong>regression line</strong> and can be
used to 'read off' the y-value corresponding to any <em>x</em>.</p>
<p class="eqn"><img src="../../../en/leastSqrs/images/s_predict.gif" width="357" height="272"></p>
	



<h2 class="pageName">21.2.2 &nbsp; Linear models</h2><!DOCTYPE HTML>


<p class="heading">Equation to describe a regression line</p>
	<p>A regression line could be drawn 'by eye' through a scatterplot, 
		but we restrict attention to simple mathematical functions</p>
	<p class=eqn><span class="black"><em>y</em> &nbsp;=&nbsp; <em>&fnof;</em> (<em> x</em> )</span></p>
	<p>since they are  easier and more objective to use.</p>
<p class="heading">Linear model</p>
	<p>Some relationships must be described by curves, but a straight line 
		is an adequate description of many bivariate data sets.</p>
	<p class=eqn><span class="black"><em>y</em> &nbsp;=&nbsp; <em>b</em><sub>0</sub> + <em>b</em><sub>1 </sub><em>x</em></span> </p>
	<p>The constant <em>b</em><sub>0</sub> is  the <strong>intercept</strong> of
the line and describes the <em>y</em>-value when <em>x</em> is zero. The constant <em>b</em><sub>1</sub> is
the line's <strong>slope</strong>; it 
		describes the change in <i>y</i> when <i>x</i> increases by one. </p>
<p class="eqn"><img src="../../../en/leastSqrs/images/s_slopeIntercept.gif" width="238" height="197"></p>
	<p>The predicted response at any <em>x</em>-value is</p>
<p class=eqn><span class="black"><span style="position:relative; top:4px"><img src="../../../images/symbol.yHat.png" width="10" height="17" align="baseline"></span>&nbsp; =&nbsp; <em>b</em><sub>0</sub> + <em>b</em><sub>1 </sub><em>x</em></span> </p>




<h2 class="pageName">21.2.3 &nbsp; Fitted values and residuals</h2><!DOCTYPE HTML>


<p class="heading">Fitted values</p>
	<p>To assess how well a particular linear model fits any one of our data points, (<em>x<sub>i</sub></em>,&nbsp;<em>y<sub>i</sub></em>), 
	we might consider how well the model would predict the y-value of the point, </p>
	<p class=eqn><span class="black"><span style="position:relative; top:4px"><img src="../../../images/symbol.yiHat.png" width="11" height="18" align="baseline"></span>&nbsp;=&nbsp; <em>b</em><sub>0</sub> + <em>b</em><sub>1 </sub><em>x<sub>i</sub></em></span> </p>
	<p>These predictions  are called <strong>fitted 
		values</strong>. </p>
	<p class="heading">Residuals</p>
	<p>The difference between the <em>i</em>'th fitted values  and its actual 
		y-value is called its <strong>residual</strong>. </p>
	<p class=eqn><span class="black"><em>e<sub>i</sub></em>&nbsp;&nbsp;=&nbsp;&nbsp;<em>y<sub>i</sub></em> &minus; <span style="position:relative; top:4"><img src="../../../images/symbol.yiHat.png" width="11" height="18" align="baseline"></span></span> </p>
	<p>The residuals describe the 'errors' that would have resulted from using the
 model to predict <em>y</em> from the <em>x</em>-values of our data points.</p>
<p class="eqn"><img src="../../../en/leastSqrs/images/s_resid.gif" width="351" height="207"></p>
	
	<p>Note that the residuals are the <strong>vertical distances of the crosses to the line</strong>.</p>
	
	



<h2 class="pageName">21.2.4 &nbsp; Least squares</h2><!DOCTYPE HTML>


<p class="heading">Aim of small residuals</p>
	<p>The residuals from a linear model (vertical distances from the crosses 
		to the line) indicate how closely the model's predictions  match the actual responses in the data. </p>
	<p class="eqn"><img src="../../../en/leastSqrs/images/s_allResids.gif" width="354" height="310"></p>
	<p>Small residuals are good, so the parameters <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub>  should
be set to make them as small as possible.</p>
	<p class="heading">Least squares</p>
	<p>The size 
		of the residuals is summarised by the <strong>residual sum of squares</strong>, </p>
<p class=eqn><img class="gif" src="../../leastSqrs/images/residSsq.gif" id="gif_image_2_4_2" width="317" height="28"><iframe class="svg" src="../../leastSqrs/images/residSsq.svg" id="svg_image_2_4_2" width="317" height="28" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_2_4_2");</script> </p>
	<p>'Good' values for <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub> can be
objectively chosen to be the values that minimise the residual sum of squares.
This is the <strong>method
of least squares</strong> and the values of <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub> are
called  <strong>least squares 
		estimates</strong>.</p>
<p>The diagram below respresents the squared residuals as blue squares. The least squares estimates minimise the total blue area.</p>
	<p class="eqn"><img src="../../../en/leastSqrs/images/s_sqrResids.gif" width="359" height="316"></p>
	<p class="heading">Formulae</p>
	<p>The problem of minimising the residual sum of squares is not difficult mathematically, 
    but you will rarely require or use the resulting formulae for <em>b</em><sub>0</sub> and <em>b</em><sub>1</sub> since spreadsheets, statistical programs and even scientific calculators will 
  do the calculations for you. However, for completeness, the formulae are </p>
	<p class=eqn><img class="gif" src="../../leastSqrs/images/lsFormulae.gif" id="gif_image_2_4_1" width="350" height="57"><iframe class="svg" src="../../leastSqrs/images/lsFormulae.svg" id="svg_image_2_4_1" width="350" height="57" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_2_4_1");</script> </p>




<h2 class="pageName">21.2.5 &nbsp; Curvature and outliers</h2><!DOCTYPE HTML>


<p class="heading">Nonlinear relationships</p>
	<p>A simple linear model is only appropriate when the cloud of crosses 
	in a scatterplot of the data is regularly spread around a straight line. If the crosses are scattered round a <strong>curve</strong>, the relationship is called <strong>nonlinear</strong> and
other models must be used.</p>
<p class="heading">Outliers</p>
<p>Another problem arises if there are <strong>outliers</strong> &mdash; observations that do not conform to the 
		pattern and variability exhibited by the rest of the data. In a linear model, 
		the most important type of outlier is a data point that lies at a distance 
		from the line that would fit through the rest of the data. </p>
	<p>The individual corresponding to any outlier should be carefully examined. Recording
		or transcription errors may be the cause. Alternatively, it may be possible to determine some
		distinguishing characteristic of the individual that underlies the unusual response
		measurement. </p>
	<p>If an outlier is extreme enough, or if a special cause for its unusual behaviour can be
		found from outside information, the individual can be classified as aberrant
		and deleted from the data set.</p>
	<div class="centred"><div class="boxed">
		<p>It is important to <strong>look at any data set graphically</strong> before
fitting a linear model to check that no curvature or outliers is present.</p>
	</div></div>
	



<h2 class="pageName">21.2.6 &nbsp; Residual plots</h2><!DOCTYPE HTML>


<p class="heading">Detecting problems with the model</p>
	<p>If outliers or curvature are present in a data set, they are often visible 
		in a scatterplot of the response against the explanatory variable. However 
		these features are usually clearer if the <strong>residuals</strong> are plotted 
		against <i>X</i> rather than the original response.</p>
	<p class="eqn"><img src="../../../en/leastSqrs/images/s_residPlot.gif" width="557" height="264"></p>




<h2 class="pageName">21.2.7 &nbsp; Predicting Y and predicting X</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Different lines are used to predict Y and to predict X</p>
	<p>The 
		least squares line for predicting Y from X,</p>
	<p class=eqn><span class="black"><em>y</em> &nbsp;=&nbsp; <em>b</em><sub>0</sub> + <em>b</em><sub>1 </sub><em>x</em></span></p>
	<p> minimises the sum of squared <strong>vertical</strong> distances between 
		the points on a scatterplot and the line. On the other hand, if we are interested 
		in predicting X from Y using a line,</p>
	<p class=eqn><span class="black"><em>x</em> &nbsp;=&nbsp; <em>c</em><sub>0</sub> + <em>c</em><sub>1 </sub><em>y</em></span></p>
	<p>the residuals are the <strong>horizontal</strong> distances between the points 
		and the line, and least squares minimises their sum 
		of squares.</p>
	<p class=eqn><img class="gif" src="../../../en/leastSqrs/images/predictAndInverse.gif" id="gif_image_2_7_1" width="469" height="209"><iframe class="svg" src="../../../en/leastSqrs/images/predictAndInverse.svg" id="svg_image_2_7_1" width="469" height="209" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_2_7_1");</script></p>
	<p><strong>Different lines</strong> minimise the sum of squares of horizontal and vertical distances.</p>
	<p class="heading">About the two least squares lines</p>
	<p>The two least squares lines can be  written in terms of standardised 
		variables,</p>
<div class="centred"><table border="0" cellspacing="0" cellpadding="10" class="centred">
		<tr>
			<th>Equation of least squares line to predict Y from X</th>
			<td><img class="gif" src="../../leastSqrs/images/yxLsLine.gif" id="gif_image_2_7_3" width="135" height="44"><iframe class="svg" src="../../leastSqrs/images/yxLsLine.svg" id="svg_image_2_7_3" width="135" height="44" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_2_7_3");</script></td>
		</tr>
		<tr>
			<th>Equation of least squares line to predict X from Y</th>
			<td><img class="gif" src="../../leastSqrs/images/xyLsLine.gif" id="gif_image_2_7_2" width="136" height="44"><iframe class="svg" src="../../leastSqrs/images/xyLsLine.svg" id="svg_image_2_7_2" width="136" height="44" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_2_7_2");</script></td>
		</tr>
	</table></div>
	<p>where <i>r</i> is the correlation coefficient between <i>X</i> and <i>Y</i>. 
		Since <i>r</i> is always less than 1, the least squares line for predicting <i>Y</i> from <i>X</i> is the more horizontal (closer to being parallel to 
		the x-axis) of the two lines.</p>
<p class="eqn"><img src="../../../en/leastSqrs/images/s_dualLines.gif" width="410" height="313"></p>




<h2 class="pageName">21.2.8 &nbsp; Exercise: Pick the explanatory variable and response</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.2.9 &nbsp; Exercise: Draw a straight line</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.2.10 &nbsp; Exercise: Find the slope and intercept</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.2.11 &nbsp; Exercise: Interpret the slope and intercept</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.2.12 &nbsp; Exercise: Find a residual</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.2.13 &nbsp; Exercise: Match data and residual plot</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.2.14 &nbsp; Exercise: Predictions</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h1 class="sectionName breakBefore">21.3 &nbsp; Coefficient of determination</h1>
<div class='leftTocCol'>
<ol class='toc'>
<li>Sums of squares</li>
</ol>
</div>
<div class='rightTocCol'>
<ol class='toc' start='2'>
<li>Coefficient of determination</li>
</ol>
</div>
<br clear='all'>
<h2 class="pageName">21.3.1 &nbsp; Sums of squares</h2><!DOCTYPE HTML>


<p class="heading">Sums of squares</p>
<p>An alternative description of the strength of a relationship is often used when the variables can be treated as a response measurement that may be affected by an explanatory variable. This description depends on three values called <strong>sums of squares</strong>.</p>
<p class="heading">Residual sums of squares</p>
<p>The residual sum of squares is the sum of squared vertical distances between scatterplot crosses and the least squares line,</p>
<p class="eqn"><img src="../../../bk/ncea/images/ssResid.gif" width="286" height="230"></p>
<p>This sum of squares describes response variation that is <strong> unexplained</strong> by the explanatory variable X and the method of least squares positions the line to make it as small as possible.</p>
<p class="eqn">SS<sub>Resid</sub> &nbsp; = &nbsp; <span style="font-size:large; vertical-align:sub">Σ</span>&nbsp;residual<sup>2</sup></p>
<p class="heading">Total sums of squares</p>
<p>The overall variation of the response, ignoring the existance of the explanatory variable, can be summarised by the sum of squared differences between the values and the overall mean response. These differences can be displayed on the scatterplot as vertical distances between the crosses and the mean response.</p>
<p class="eqn"><img src="../../../bk/ncea/images/ssTotal.gif" width="286" height="230"></p>
<p>The total sum of squares is the sum of the squared green lines above.</p>
<p class="eqn">SS<sub>Total</sub> &nbsp; = &nbsp; <span style="font-size:large; vertical-align:sub">Σ</span>&nbsp;(y - overall mean)<sup>2</sup></p>
<p class="heading">Explained  sums of squares</p>
<p>The difference between these two sums of squares is called the <strong>explained sum of squares</strong> and describes the response variation that is explained by the explanatory variable,</p>
<p class="eqn">SS<sub>Explained</sub> &nbsp; = &nbsp; SS<sub>Total</sub> &nbsp; - &nbsp; SS<sub>Resid</sub></p>
<p>This sum of squares can be described graphically as the sum of squared distances between the least squares line and the overall mean, evaluated at each data point.</p>
<p class="eqn"><img src="../../../bk/ncea/images/ssExplained.gif" width="286" height="230"></p>
<p>The explained sum of squares is the sum of the squared purple lines above.</p>
<p class="eqn">SS<sub>Explained</sub> &nbsp; = &nbsp; <span style="font-size:large; vertical-align:sub">Σ</span>&nbsp;(LS prediction &nbsp; - &nbsp; overall mean)<sup>2</sup></p>
<div class="boxed">
	<p>The relative sizes of the explained and residual sums of squares describe how much of the variability is explained by the model.<br>
	
	<p></p>
</div>
<div class="diagram">

<p class="heading">Simulation: Impurities in plastic</p>
<p>The next diagram shows simulated data that might describe the impurities recorded 
from batches of plastic produced at different temperatures (degrees Fahrenheit).</p>

<div class="centred">
<applet codebase="../../../java" code="ssqProg.ComponentsSsqApplet.class" archive="coreCAST.jar" width="550" height="360">
<script type="text/javascript">writeAppletParams();</script>
<param name="yVarName" value="Impurities, y">
<param name="xVarName" value="Temperature, x">
<param name="xRandom" value="30 70 8 445945782 2.0">
<param name="regnModel" value="-25.0 0.5 2.0">
<param name="randomSeed" value="623945782">
<param name="xAxis" value="50 90 50 10">
<param name="yAxis" value="0 20 0 5">
<param name="decimals" value="3">
<param name="residAxis" value="-20 20 -20 10">
<param name="initialR2" value="0.75">
<param name="maxSsq" value="999.99">
<param name="componentName" value="Total#Explained#Residual">
<param name="customText" value="Variability=Variability#All unexplained=All unexplained#All explained=All explained">
</applet>
</div>

<p>Click on the jittered dot plots on the right to display the different components 
as coloured vertical lines on the scatterplot.</p>
<p><strong>Drag the slider</strong> to change the strength of the relationship 
between the impurities and temperature. Observe that:</p>

<div class="boxed">
<dl style="margin-left:0">
<dt>When the relationship is strong,</dt>
<dd style="font-weight:normal">...the residuals are much smaller than the explained components and their 
sum of squares is also a small part of the total sum of squares.</dd>

<dt>When the relationship is weak,</dt>
<dd style="font-weight:normal">...the residuals are larger than the explained components and their sum of 
squares is a large part of the total sum of squares.</dd>
</dl>
</div>

<p>The relative sizes of the sums of squares therefore hold information about the
strength and significance of the relationship.</p>

</div>




<h2 class="pageName">21.3.2 &nbsp; Coefficient of determination</h2><!DOCTYPE HTML>


<p class="heading">Coefficient of determination</p>
<p>We have seen that the total sum of squares can be split into two parts, the 
explained and residual sums of squares.</p>
<div class="boxed">
<dl style="margin-left:0">
<dt>When the relationship is strong,</dt>
<dd style="font-weight:normal">...the explained sum of squares is close to the
total sum of squares (and the residual sum of squares is small).</dd>
<dt>When the relationship is weak,</dt>
<dd style="font-weight:normal">...the explained sum of squares is small relative
to the total sum of squares.</dd>
</dl>
</div>
<p>A useful summary statistic is the <strong>proportion</strong> 
of the total variation that is explained, <strong>the coefficient of determination</strong>, 
<em>R</em><sup>2</sup>, </p>
<p class=eqn><img src="../../en/regnAnova/images/r2Defn3.gif" width="110" height="38" alt="R-squared = SSexplained / SStotal"></p>
<p>The coefficient of determination is always between 0 and 1. <em>R</em><sup>2</sup> 
is close to 1 when most of the response variation is explained by the explanatory 
variable; it is close to 0 when most variation is unexplained.</p>
<p>Because the explained and residual sums of squares add to the total sum of squares, the residual sum 
of squares is a proportion (1&nbsp;-&nbsp;<em>R</em><sup>2</sup>) of the total 
variation, so this is the proportion of total variation that is <strong>unexplained</strong> 
by the normal linear model.</p>
<p class="heading">Correlation coefficient</p>
<p>Although it is derived with quite a different aim, the value of <em>R</em><sup>2</sup> 
is the square of the correlation coefficient between the explanatory and response 
variables for regression data. This may help to interpret its value. </p>
<p class=eqn><img src="../../en/regnAnova/images/rSquaredEqn.gif" width="230" height="24" alt="R-squared = corr-squared"></p>

<div class="diagram"> 

<p class="heading">Illustration</p>
<p>We again consider simulated data that might describe the impurities recorded 
from batches of plastic produced at different temperatures.</p>
<div class="centred">
<applet codebase="../../../java" code="ssqProg.ComponentsR2Applet.class" archive="coreCAST.jar" width="550" height="400">
<script type="text/javascript">writeAppletParams();</script>
<param name="yVarName" value="Impurities, y">
<param name="xVarName" value="Temperature, x">
<param name="xRandom" value="30 70 8 445945782 2.0">
<param name="regnModel" value="-10.0 0.3 2.0">
<param name="randomSeed" value="655945782">
<param name="xAxis" value="50 90 50 10">
<param name="yAxis" value="0 20 0 5">
<param name="decimals" value="3">
<param name="residAxis" value="-20 20 -20 10">
<param name="initialR2" value="0.75">
<param name="maxSsq" value="999.9">
<param name="componentName" value="Total#Explained#Residual">
<param name="customText" value="Another data set=Another data set#Variability=Variability#All unexplained=All unexplained#All explained=All explained">
</applet>
</div>

<p>Use the slider to adjust the strength of the relationship, and observe how 
the value of <em>R</em><sup>2</sup> is affected.</p>
<p class="heading">Real data sets</p>
<p>Use the popup menu below to display the coefficient of determination for different 
data sets and see how it is interpreted.</p>

<form>
<select name="dataset" onChange="changeSvgImage(this)">
<option value="0" selected>Cancer deaths and radiation</option>
<option value="1">Butterfat content of milk</option>
<option value="2">Jaw length and weight of deer</option>
<option value="3">Non-response in phone surveys</option>
<option value="4">Alcoholism and strength</option>
</select>
</form>

<p align="center"><img src="../../en/regnAnova/images/cancerRadiation.gif" name="dataImage" width="587" height="367"></p>

</div>




<h1 class="sectionName breakBefore">21.4 &nbsp; Nonlinear relationships (advanced)</h1>
<div class='leftTocCol'>
<ol class='toc'>
<li>Transformations and correlation</li>
<li>Transformations and models</li>
<li>Quadratic models</li>
<li>Dangers of extrapolation</li>
</ol>
</div>
<div class='rightTocCol'>
<ol class='toc' start='5'>
<li>Exercise: Regression problems</li>
<li>Exercise: Transformations of X and Y</li>
<li>Exercise: Predictions and nonlinearity</li>
</ol>
</div>
<br clear='all'>
<h2 class="pageName">21.4.1 &nbsp; Transformations and correlation</h2><!DOCTYPE HTML>


<p class="heading">Correlation coefficient and nonlinear relationships</p>
	<p>The correlation coefficient, <i>r</i>, is a good description of the strength 
		of linear relationship but <a href="javascript:showNamedPage('correlation4')">not 
			nonlinear ones</a>. If a scatterplot shows marked curvature, the correlation 
		coefficient can considerably understate the strength of the relationship.</p>
	<p class="heading">Transform the variables to linearise the relationship</p>
	<p>Nonlinear transformations of X and Y alters the shape of the relationship. It is often possible 
		to linearise a relationship by transforming one or both variables.</p>
<p>The strength of a nonlinear relationship can therefore be described with the
correlation coefficient after  a transformation to one or both variables has
been applied to <strong>remove
the nonlinearity</strong>.</p>
<p class="eqn"><img src="../../../en/curvature/images/s_rawCorr.gif" width="354" height="276"><img src="../../../en/curvature/images/s_logCorr.gif" width="354" height="276"></p>




<h2 class="pageName">21.4.2 &nbsp; Transformations and models</h2><!DOCTYPE HTML>


<p class="heading">Linear model with transformed variables</p>
	<p>If the relationship between <i>Y</i> and <i>X</i> is nonlinear, a linear 
		model will give poor predictions and must be avoided.</p>
	<p class="eqn"><img src="../../../en/curvature/images/s_rawModel.gif" width="303" height="230"></p>
	<p>However, by transforming 
		one or both of the variables, it is often possible to linearise the relationship 
		and therefore use least squares to fit a linear model to the transformed variables.</p>
	<p class="eqn"><img src="../../../en/curvature/images/s_logModel.gif" width="550" height="232"></p>
	<p>A logarithmic transformation of either Y or X often works, but a more general 
		power transformation is sometimes needed to linearise the relationship.</p>




<h2 class="pageName">21.4.3 &nbsp; Quadratic models</h2><!DOCTYPE HTML>


<p class="heading notPrinted">Adding a quadratic term</p>
	<p>An alternative solution to the problem of curvature is to extend the simple 
		linear model with the addition of a quadratic term, </p>
	<p class=eqn><span class="black"><em>y</em>&nbsp;&nbsp;=&nbsp;&nbsp;<em>b</em><sub>0</sub>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>1 </sub><em>x</em>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>2 </sub><em>x</em><sup>2</sup></span> </p>
	<p>Fitted values and residuals are defined (and interpreted) in a similar way 
		to those for a linear model,</p>
	<p class=eqn><span class="black"><span style="position:relative; top:4"><img src="../../../images/symbol.yiHat.png" width="11" height="18" align="baseline"></span>&nbsp;&nbsp;=&nbsp;&nbsp;<em>b</em><sub>0</sub>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>1 </sub><em>x<sub>i</sub></em>&nbsp;&nbsp;+&nbsp;&nbsp;<em>b</em><sub>1 </sub><em>x<sub>i</sub></em><sup>2</sup></span> <br>
			<span class="black"><em>e<sub>i</sub></em>&nbsp;&nbsp;=&nbsp;&nbsp;<em>y<sub>i</sub></em> &minus; <span style="position:relative; top:4"><img src="../../../images/symbol.yiHat.png" width="11" height="18" align="baseline"></span></span> </p>
	<p>As in a linear model, the quadratic model's residuals are the vertical distances 
		between the crosses in a scatterplot and the curve. We again use <strong>least 
			squares</strong> to estimate the unknown parameters &mdash; choose values of the 
		three parameters to minimise the residual sum of squares, </p>
	<p class=eqn><img class="gif" src="../../curvature/images/residSsqEqn.gif" id="gif_image_4_3_1" width="369" height="28"><iframe class="svg" src="../../curvature/images/residSsqEqn.svg" id="svg_image_4_3_1" width="369" height="28" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_4_3_1");</script> </p>
	<p class="eqn"><img src="../../../en/curvature/images/s_quadraticModel.gif" width="374" height="327"></p>




<h2 class="pageName">21.4.4 &nbsp; Dangers of extrapolation</h2><!DOCTYPE HTML>


<p class="heading notPrinted">The shape of a relationship is only known around the data</p>
	<p>The models that we have used to describe the relationship between a response, <i>Y</i>, and explanatory variable, <i>X</i>, are usually only approximations to
		the 'real' relationship. For example, a scatterplot may <strong>look</strong> linear,
		but we really have no information about the shape of the relationship beyond our data. </p>
	<p class=eqn><img class="gif" src="../../curvature/images/extrapolate.gif" id="gif_image_4_4_1" width="256" height="166"><iframe class="svg" src="../../curvature/images/extrapolate.svg" id="svg_image_4_4_1" width="256" height="166" frameborder="0"></iframe><script type="text/javascript">showCorrectImage("image_4_4_1");</script>
	<p>A model may be useful for predicting <i>Y</i> from values of <i>X</i> that are within the range of x-values in our data, but we
		should be very cautious about using it to predict <em>Y</em> outside this range.
		This is called <strong>extrapolation</strong> and it can be badly in error. </p>
	
<div class="centred"><div class="boxed">
<p>Avoid using a model to predict <em>Y</em> far beyond the available 
				data.</p>
</div></div>





<h2 class="pageName">21.4.5 &nbsp; Exercise: Regression problems</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.4.6 &nbsp; Exercise: Transformations of X and Y</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
<h2 class="pageName" style='margin-top:2em;'>21.4.7 &nbsp; Exercise: Predictions and nonlinearity</h2><div class='summary_text'><p>Exercises are only available online.</p></div>
</html>
