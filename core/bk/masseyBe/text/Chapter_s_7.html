<!DOCTYPE HTML>
<html>
<head>
  <title>7. Sample Means and Propns</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="../../../structure/summaryStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/maths/mathStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/printStyles.css" type="text/css">
  <script src="../../../structure/videoControls/jquery.js"></script>
  <script src="../../../structure/maths/theorems.js"></script>
  <script src="../../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js"></script>
  <script src="../../../structure/printFixes.js"></script>
</head>

<body id="body" onLoad="showPrintDialog(true)">
<div id='overlay'>
	<div id='dialogWindow'>
		<div class='printDialog'>
			<script type='text/javascript'>
				document.write("<div class='heading'>" + top.document.title + "</div>");
				if (top.url != null) {
					document.write("<p class='text'>A version of this chapter has already been generated in PDF format and we recommend that it is used for printing. The button below will download and display it.</p>");
					document.write("<p><button onClick='top.showPdf()'>Show PDF version of chapter</button></p>");
					document.write("<p class='text'>However downloading could be slow depending on your internet connection. If this is a problem, click the button below to print the chapter without downloading (but perhaps not formatted as well as the PDF version).</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>If you are <strong>not</strong> using the PDF version, the best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
				else {
					document.write("<p class='text'>Click the button below to print this chapter.</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>The best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
			</script>
			
			<p class='text'>If you don't want to print now,</p>
			<p><button onClick='top.showPrintDialog(false)'>Browse formatted chapter</button></p>
		</div>
	</div>
</div>
<h1 class="chapterName">Chapter 7 &nbsp; Sample Means and Propns</h1>
<h1 class="sectionName">7.1 &nbsp; Distribution of sample mean</h1>
<h2 class="pageName">7.1.1 &nbsp; Parameters and statistics</h2>

<p class="heading">Sampling mechanism</p>
	<p>The mechanism of sampling from a population explains randomness in data.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/s_samplingHistos.gif" width="223" height="184"></p>
	<p>In practice, we must use  a <strong>single</strong> sample to find information about the population.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/s_oneHisto.gif" width="221" height="70"></p>
	<p class="heading">Parameters and statistics</p>
	<p>We usually focus attention on a small number of numerical characteristics.</p>
	<ul>
		<li>Populations are summarised by values called <strong> parameters</strong>.</li>
		<li>The corresponding sample values are <strong>sample statistics</strong> and provide <strong>estimates</strong> of the parameters.</li>
	</ul>
	<p class="eqn"><img src="../../../en/randomMean/images/s_oneMean.gif" width="221" height="70"></p>
	<p class="heading">Variability of sample statistics</p>
	<p>The variability in random samples also implies sample-to-sample variability in sample statistics.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/s_samplingMeans.gif" width="223" height="183"></p>




<h2 class="pageName">7.1.2 &nbsp; Variability of sample mean</h2>

<p class="heading notPrinted">Distribution of the sample mean</p>
	<p>The mean of a random sample of <em>n</em> values is a random quantity. Its
distribution  is centred on the population mean but its spread is lower then
that of the population distribution.</p>


<h2 class="pageName">7.1.3 &nbsp; Standard devn of sample mean</h2>

<p class="heading notPrinted">Centre and spread of the sample mean's distribution</p>
	<ul>
		<li>The sample mean has a distribution that is centred on the 
			population mean.</li>
		<li>Its variability decreases as the sample size increases. </li>
	</ul>
<p>We can be more precise. If the population has mean µ and standard deviation σ, then  the   mean of a sample of <em>n</em> values, <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline">, 
		has a distribution with mean and standard deviation:</p>
<div class="centred">
	<table border="0" cellpadding="0" cellspacing="0" class="centred">
		<tr>
			<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
			<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</td>
		</tr>
	</table>
</div>
<div class="centred">
	<table border="0" cellpadding="0" cellspacing="0" class="centred">
		<tr>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
			<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
		</tr>
	</table>
</div>


<h2 class="pageName">7.1.4 &nbsp; Means from normal populations</h2>

<p class="heading">Shape of the mean's distribution</p>
	<p><strong>Whatever</strong> the shape of the population distribution,</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</span> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
		</table>
	</div>
	<p>However skewness in the population distribution 
		leads to some <strong>skewness in the distribution of the mean</strong>.</p>
	<p class="heading">Samples from normal populations</p>
	<p>When the population distribution is normal, the sample mean 
	also has a normal distribution.</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></td>
				<td valign="middle">&nbsp; ~ &nbsp;<font face="Arial, Helvetica, sans-serif">normal</font> (μ , &nbsp;</td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
				<td valign="middle">)</td>
			</tr>
		</table>
	</div>
	<br>
	<p class=eqn><img src="../../../en/randomMean/images/s_normalMean.gif" width="428" height="344"></p>




<h2 class="pageName">7.1.5 &nbsp; Large-sample normality of means</h2>

<p class="heading">Means from non-normal populations</p>
	<p>Irrespective of the shape of the population distribution,</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</span> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
		</table>
	</div>
	<p>If the population is not a normal distribution, the sample mean does not 
		have a normal distribution. However  the <strong>Central Limit 
		Theorem</strong> states that...</p>
<div class="centred"><div class="boxed"><p>For most non-normal population distributions, the distribution of 
				the sample mean becomes close to normal when the sample size increases.</p></div></div>
<p class="eqn"><img src="../../../en/randomMean/images/s_gammaMean.gif" width="428" height="344"></p>




<h2 class="pageName">7.1.6 &nbsp; Distribution of mean from a sample</h2>

<p class="heading">Need for multiple values to assess variability</p>
	<p>We usually need to make two or more measurements of a variable 
		to get any information about its variability. A single value contains no information about the quantity's variability.</p>
<p class="heading">Achieving the impossible?</p>
<p>Fortunately, <strong>we do not need multiple sample</strong> means to assess the variability of a sample mean. Its distribution can be estimated from a <strong>single sample</strong> using </p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.muXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=&nbsp; &mu;</td>
			</tr>
		</table>
	</div>
<div class="centred">
	<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
	</table>
	</div>
	<p>The distribution of the mean can be approximated with a normal distribution with this mean and standard deviation, if we replace µ 
	and σ with <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"> and <em>s</em>.</p>
	<p class="eqn"><img src="../../../en/randomMean/images/contamination.gif" width="540" height="469" class="summaryPict"></p>




<h2 class="pageName">7.1.7 &nbsp; Requirement of independence</h2>

<p class="heading">Independent random samples</p>
	<p>The formula for the standard deviation of a sample mean,</p>
	<div class="centred">
		<table border="0" cellpadding="0" cellspacing="0" class="centred">
			<tr>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
				<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </td>
				<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
			</tr>
		</table>
	</div>
<p>is only accurate if the sample values are <strong>independent</strong>.</p>
<p class="heading">Dependent random samples</p>
	<p>When  sample values are correlated with each other, they are said to be <strong>dependent</strong> and the formula</p>
	<p class="eqn"><img class="gif" src="../../../en/randomMean/images/estSDMean.gif" width="64" height="32"></p>
	<p> can badly underestimate the variability (and hence accuracy) of the sample 
		mean of dependent random samples.</p>
	<p>Always check that a random sample is independently selected from the whole 
		population before using the formula for the standard deviation of the sample mean.</p>




<h2 class="pageName">7.1.8 &nbsp; Sampling from finite popns (opt) (Optional (not examined))</h2>

<p class="heading">Sampling with replacement from finite populations</p>
	<p>When  a random sample is selected <strong>with replacement</strong> from a finite 
		population, the sample values are independent and the standard 
		deviation of the sample mean is again</p>

<div class="centred"><table border="0" cellpadding="0" cellspacing="0" class="centred">
		<tr>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaXbar.png" width="19" height="16" align="baseline"></td>
			<td valign="middle">&nbsp;<span class="black">=</span>&nbsp; </span></td>
			<td valign="middle"><img src="../../../en/../images/symbol.sigmaOverRootN.png" width="26" height="31" align="baseline"></td>
		</tr>
	</table></div>

	<p>Note however that the population  standard deviation, σ, 
		uses divisor <em>N</em>, the number of values in the population, rather than (<em>N</em>&nbsp;-&nbsp;1).	</p>
	<p class=eqn><img class="gif" src="../../../en/randomMean/images/popnSdFinite.gif" width="114" height="49"></p>
<p class="heading">Sampling without replacement from finite populations</p>
	<p>When a sample is selected <strong>without replacement</strong>, successive values are no longer independent &mdash; if a large value is selected, it cannot be selected again, so the next value will tend 
	to be lower.</p>
	<p>For sampling without replacement, a different formula should be used for the standard deviation of the sample mean:</p>
	<p class=eqn><img class="gif" src="../../../en/randomMean/images/sdMeanSWOR.gif" width="138" height="45"></p>
	<p>The quantity (<em>N </em>- <em>n</em>) / (<em>N</em> - 1) is called the <strong>finite 
		population correction factor</strong>. It can usually be ignored if only a small fraction of the population is sampled (say under 5%).</p>




<h1 class="sectionName breakBefore">7.2 &nbsp; Normal distributions</h1>
<h2 class="pageName">7.2.1 &nbsp; Importance of normal distributions</h2>

<p class="heading">Normal distribution parameters</p>
	<p>The <a href="javascript:showNamedPage('probDensity5')">family of 
		normal distributions</a> consists of symmetric bell-shaped distributions that 
		are defined by two parameters, µ 
		and σ, the distribution's mean and standard deviation.</p>
	<p class="heading">Normal distributions as models for data</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_bestFit.gif" width="404" height="202"></p>
	<p>The sample data rarely gives enough information for us to be <strong>sure</strong> that the underlying population is  normal, but a normal model is often used unless there is <strong>obvious</strong> non-normality in the data.</p>
<p>Even if the sample data are obviously skew, a normal distribution may be a reasonable
model for a nonlinear transformation of the values (e.g. a log transformation).</p>
<p class="heading">Distribution of summary statistics</p>
	<p>A more important reason for the importance of the normal distribution in statistics 
		is that...</p>
	
<div class="centred"><div class="boxed">
<p>Many summary statistics have normal distributions (at least approximately).</p>
</div></div>

	<p>The Central Limit Theorem shows that the mean of a random sample has a distribution that is close to normal when the sample size is moderate or large, <strong>irrespective 
	of the shape of the distribution of the individual values</strong>. The following are also 
	approximately normal when the sample size is moderate or large...</p>
	<ul>
		<li>A sample proportion</li>
		<li>The slope and intercept of a least squares line</li>
		<li>The difference between the means of two samples</li>
	<li>The difference between two proportions</li></ul>




<h2 class="pageName">7.2.2 &nbsp; Shape of normal distributions</h2>

<p class="heading notPrinted">Effect of normal parameters on distribution</p>
	<p>Distributions from the normal family have different locations and spreads, 
		but other aspects of their shape are the same. Indeed, if the scales on the horizontal 
		and vertical axes are suitably chosen, ...</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_normalAxes.gif" width="514" height="295"></p>





<h2 class="pageName">7.2.3 &nbsp; Sketching a normal distribution</h2>

<p class="heading">A common diagram for <span class="red">all</span> normal 
		distributions</p>
	<p>All normal distributions have basically the same shape.</p>
	<ul>
		<li>The distribution almost disappears at 3σ 
			from µ</li>
		<li>The probability (area) further than 2σ 
			from µ 
			is small &mdash; only about <sup>1</sup>/<sub>20</sub> of the total area.</li>
	</ul>
	<p>This should allow you to sketch a normal distribution, given any values of µ and σ.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_sketch.gif" width="505" height="237"></p>




<h2 class="pageName">7.2.4 &nbsp; Some normal probabilities</h2>

<p class="heading notPrinted">Some probabilities for normal distributions</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_empiricalRule.gif" width="499" height="553"></p>
	<p>A more precise version of the middle probability is</p>
	<ul>
		<li>P&nbsp;(within 1.96σ 
			of µ) 
			&nbsp;=&nbsp; 0.95</li>
	</ul>
	<p class="heading">70-95-100 rule of thumb and the normal distribution</p>
	<p>These probabilities are the basis of the <a href="javascript:showNamedPage('centerSpread7')">70-95-100 
		rule of thumb</a> for 
		'bell-shaped' data sets.</p>
	<ul>
		<li>About 70% of values are within <em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
		<li>About 95% of values are within 2<em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
		<li>Almost all values are within 3<em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
	</ul>




<h2 class="pageName">7.2.5 &nbsp; Z-scores for data sets</h2>

<p class="heading">Z-scores</p>
	<p>The <strong>standardised</strong> form of a variable X is found by subtracting its mean then dividing by its standard deviation,</p>
	<div class="centred">
		<table border="0" cellspacing="0" cellpadding="10" class="centred">
			<tr>
				<th style="margin:0px; padding:0px" valign="middle"><span class="bold">standardised value,</span>&nbsp;&nbsp;&nbsp;</th>
				<td style="margin:0px; padding:0px" valign="middle"><img class="gif" src="../../../en/correlation/images/standardiseX.gif" width="105" height="39"></td>
			</tr>
		</table>
	</div>
	<p>The resulting values are  called <strong>z-scores</strong> and are the same,
whatever the units in which X was originally recorded.</p>
<p class="heading">Properties of z-scores</p>
	<p>A standardised variable always has zero mean and standard deviation one. </p>
	<p class=eqn> <img class="gif" src="../../../en/correlation/images/standardMeanSD.gif" width="110" height="18"> </p>
	<p>From the  <a href="javascript:showNamedPage('centerSpread6')">70-95-100 
	rule-of-thumb</a>, </p>
	<div class="centred"><div class="boxed">
		<ul>
			<li>About 70% of z-scores will be between -1 and +1</li>
			<li>About 95% of z-scores will be between -2 and +2</li>
			<li>Almost all z-scores will be between -3 and +3</li>
		</ul>
	</div></div>
	<p>An individual's z-score tells you how many standard deviations it is above the mean. From its value, you can tell whether the value is very high (say over +2) or low (say under -2) in relation to the other values  of the variable.</p>




<h2 class="pageName">7.2.6 &nbsp; Z-scores</h2>

<p class="heading">Standard deviations from the mean</p>
	<p>Any x-value can be expressed as a number of standard deviations from the mean &mdash; its <strong>z-score</strong>.</p>
	<p class=eqn><img src="../../../en/normalDistn/images/s_zScore.gif" width="498" height="145"></p>
	<p>or equivalently, </p>
	<p class=eqn><span class="black"><em>x</em> &nbsp;=&nbsp; &mu; &nbsp;+&nbsp; <em>z</em> &times; &sigma;</span> </p>
	<p class="heading">Probabilities and z-scores</p>
	<p>Any  probability (area) relating to a normally distributed random variable, <em>X</em>, can be expressed in terms of z-scores:</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_zProb.gif" width="502" height="298"></p>
	<p>Note in particular that:</p>
	<ul>
		<li>P(-1 &lt; z &lt; +1) &nbsp;is approx&nbsp;0.68</li>
		<li>P(-2 &lt; <em> z </em> &lt; +2) &nbsp;is approx&nbsp;0.95</li>
		<li>P(-3 &lt; <em>z</em> &lt; +3) &nbsp;is approx&nbsp;0.997</li>
	</ul>




<h2 class="pageName">7.2.7 &nbsp; Finding normal probabilities</h2>

<p class="heading">Distribution of z-scores</p>
	<p>Calculating a z-score from a value, <em>x</em>, is  called <strong>standardising</strong> it.</p>
	<div class="centred">
		<table border="0" cellspacing="0" cellpadding="10" class="centred">
			<tr>
				<th style="margin:0px; padding:0px" valign="middle"><span class="black">standardised value,</span>&nbsp;&nbsp;&nbsp;</th>
				<td style="margin:0px; padding:0px" valign="middle"><img class="gif" src="../../../en/normalDistn/images/standardiseEqn2.gif" width="103" height="31"></td>
			</tr>
		</table>
	</div>
<p>If <em>X</em> has a normal distribution, then <i>Z</i> has a <strong>standard 
		normal distribution</strong> with mean µ&nbsp;=&nbsp;0 
	and standard deviation σ&nbsp;=&nbsp;1. </p>
	<p class="heading">Probabilities for the standard normal distribution</p>
	<p>After translating a probability about <em>X</em> into one about a z-score, it is easier to evaluate it.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_xProb.gif" width="509" height="436"></p>
	<p>Areas under the standard normal curve can be evaluated in Excel and most statistical programs. Statistical tables can also be used (see later).</p>




<h2 class="pageName">7.2.8 &nbsp; Other probabilities</h2>

<p class="heading">Evaluating other probabilities</p>
	<p>Other probabilities about normal distributions can be found using the following properties:</p>
	<ul>
		<li>The total area under a normal p.d.f. is 1</li>
		<li>The probability of a value in any interval is the area under the normal p.d.f. above this interval.</li>
	</ul>
	<p class="heading">Probability of higher value</p>
	<p class=eqn><img src="../../../en/normalDistn/images/normalAreas.gif" width="550" height="115"></p>
	<p class="heading">Probability of value between two others</p>
	<p class=eqn><img src="../../../en/normalDistn/images/normalAreas2.gif" width="506" height="241"></p>
	<p>In both cases, the conversion can be done either before or after translating the 
		required probability from x-values to z-scores.</p>




<h2 class="pageName">7.2.9 &nbsp; Normal tables</h2>

<p class="heading notPrinted">Standard normal probabilities without a computer</p>
	<p>Probabilities about z-scores can be found <strong>without a computer</strong>. Most 
		introductory statistics textbooks contain printed tables with left-tail probabilities 
	for the standard normal distribution. </p>
	<p class=eqn><img src="../../../en/normalDistn/images/table.gif" width="482" height="176" alt="pdf = table"> </p>
	<p>These tables can be used after the required probability has been translated 
		into a problem relating to the standard normal distribution.</p>




<h2 class="pageName">7.2.10 &nbsp; Finding normal quantiles</h2>

<p class="heading">Finding an x-value from a probability</p>
	<dl>
		<dt>Quartiles</dt>
		<dd>The <strong>quartiles</strong> of a  distribution are the three values such that there is probability <sup>1</sup>/<sub>4</sub>, <sup>2</sup>/<sub>4</sub> and <sup>3</sup>/<sub>4</sub> of being lower.</dd>
		<dt>Percentiles</dt>
		<dd>The <em>r</em>'th percentile of the distribution is the value with probability <sup><em>r</em></sup>/<sub>100</sub> of being lower.</dd>
		<dt>Quantiles</dt>
		<dd>These are generalised by the term <strong>quantile</strong>. The value with probability <em>p</em> of being lower is called the quantile of the distribution corresponding to probability <em>p</em>.</dd>
	</dl>
	<p class="heading">Finding quantiles</p>
	<p>To find the x-value for which there is probability <em>p</em> of a normal distribution being lower,</p>
	<ul>
		<li>Find the z-score for which there is probability <em>p</em> of being less.</li>
		<li>Translate the z-score to an x-value</li>
	</ul>
	<p>The first step of this process can be done with Excel (or other statistical software) or statistical tables can be used. For example, the 
		diagram below shows how to find the z-score such that there is probability 
		0.9 of being less.</p>
	<p class=eqn><img src="../../../en/normalDistn/images/invTable.gif" width="482" height="176" class="summaryPict"> </p>
	<p>Translating from a z-score to the corresponding x-value is done with the 
		formula,</p>
	<p class=eqn><span class="black"><em>x</em> &nbsp;=&nbsp; &mu; &nbsp;+&nbsp; <em>z</em> &sigma;</span> </p>




<h2 class="pageName">7.2.11 &nbsp; Normal probability plots (opt) (Optional (not examined))</h2>

<p class="heading">Do the data come from a normal distribution?</p>
	<p>A histogram  may indicate that a sample is unlikely to come from a normal distribution, but a <strong>normal probability plot</strong> can indicate more subtle departures from a normal distribution.</p>
	<ol>
		<li>Sort the data values into order, <em>x</em><sub>(1)</sub>&nbsp;&lt;&nbsp;<em>x</em><sub>(2)</sub>&nbsp;&lt;&nbsp;...&nbsp;&lt;&nbsp;<em>x</em><sub>(<em>n</em>)</sub></li>
		<li>Find ordered values that are spaced out as you would <strong>expect</strong> from a normal distribution, <em>q</em><sub>1</sub>&nbsp;&lt;&nbsp;<em>q</em><sub>2</sub>&nbsp;&lt;&nbsp;...&nbsp;&lt;&nbsp;<em>q</em><sub><em>n</em></sub>. 
			The quantiles of the normal distribution corresponding to probabilities <sup>1</sup>/<sub>(<em>n</em>+1)</sub>, <sup>2</sup>/<sub>(<em>n</em>+1)</sub>, ..., <sup><em>n</em></sup>/<sub>(<em>n</em>+1)</sub> are commonly used.</li>
		<li>Plot <em>x</em><sub>(<em>i</em>)</sub> against <em>q</em><sub><em>i</em></sub></li>
	</ol>
	<p>If the data set is from a normal distribution, the data should be spaced out in a similar way to the normal quantiles, so the crosses in the normal probability 
		plot should lie close to a straight line.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_probPlot.gif" width="359" height="357"></p>
	<p class="heading">How much curvature is needed to suggest non-normality?</p>
	<p>This is a difficult question to answer and we will not address it here.</p>





<h1 class="sectionName breakBefore">7.3 &nbsp; Distribution of sample proportion</h1>
<h2 class="pageName">7.3.1 &nbsp; Proportion and probability</h2>

<p class="heading">A sample proportion has a distribution</p>
	<p>If a categorical data set is modelled as a random sample from a categorical 
		population, the sample proportions   must be treated as 
		random quantities &mdash; they vary from sample to sample.</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_samplingPropns.gif" width="446" height="365"></p>
	<p>The population proportion in a category  is called 
		its <strong>probability</strong>, and is often denoted by π. 
		The corresponding sample proportion is usually denoted by <em>p</em>. </p>
	<div class="centred">
		<div class="centred">
			<table class="centred" border="0" cellspacing="0" cellpadding="4">
				<tr>
					<th>&nbsp; </th>
					<th align="CENTER">Sample Statistic</th>
					<th align="CENTER">Population Parameter</th>
				</tr>
				<tr>
					<th align="left">Mean</th>
					<td align="CENTER" style="border-top:1px solid #999999;"><img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></td>
					<td align="CENTER" style="border-top:1px solid #999999;">µ</td>
				</tr>
				<tr>
					<th align="left">Standard deviation</th>
					<td align="CENTER" style="border-top:1px solid #999999;"><em>s</em></td>
					<td align="CENTER" style="border-top:1px solid #999999;">σ</td>
				</tr>
				<tr>
					<th align="left">Proportion/probability</th>
					<td align="CENTER" style="border-top:1px solid #999999; border-bottom:1px solid #999999;"><em>p</em></td>
					<td align="CENTER" style="border-top:1px solid #999999; border-bottom:1px solid #999999;">π</td>
				</tr>
			</table>
		</div>
	</div>
<p>In practice, we only have a single sample and must use it to get information about the underlying population.</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_onePropn.gif" width="442" height="140"></p>




<h2 class="pageName">7.3.2 &nbsp; Properties of counts and proportions</h2>

<p class="heading">Properties of a sample proportion</p>
	<p>A sample proportion  from a random sample
	of size <i>n</i> has a distribution that ... </p>
	<ul>
		<li>is centred on the underlying population probability,
			π, and</li>
		<li>has a spread that decreases as the sample size <i>n</i> increases.</li>
	</ul>
	<p class="heading">Count and proportion of successes</p>
	<p>Although the sample proportion in a category, <span class="em black">p</span> , 
		is a good summary statistic, the raw count of sample values in the category, <span class="em black">x</span> <span class="black">&nbsp;=&nbsp;<em>np</em></span>, 
		contains equivalent information and is often easier to use. They have distributions with the same shape (other than the scaling constant <i><span class="black">n</span></i>).</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_propnDist.gif" width="550" height="286"></p>




<h2 class="pageName">7.3.3 &nbsp; Binomial distribution</h2>

<p class="heading">General notation</p>
	<p>In a categorical population, we choose one category of interest and call it <em><strong>success</strong></em>; all other categories are collectively called <em><strong>failures</strong></em>. The population proportion of successes is denoted by <span class="black">π</span>.</p>
	<p>When a random sample of <i><span class="black">n</span></i> values is selected, 
		we denote the number of successes by <span class="em black">x</span>  and the proportion of successes by <span class="em black">p</span> <span class="black">&nbsp;=&nbsp;<em><span style="vertical-align:20%">x</span></em>/<em><span style="vertical-align:-20%">n</span></em></span>. </p>
	<p class="heading">Distribution of a sample proportion</p>
	<p>The number of successes, <span class="em black">x</span> , 
		has a 'standard' discrete distribution called a <strong>binomial distribution</strong> which has two parameters, <span class="em black">n</span>  and <span class="black">π</span>.</p>
	<p>In practical applications, <span class="em black">n</span>  is a known constant, but <span class="black">π</span> may be unknown. The sample proportion, <span class="em black">p</span> , 
		has a distribution with the same shape, but is scaled by <span class="em black">n</span> .</p>
	<ul>
		<li>The distribution of <em>p</em> is centred on π.</li>
		<li>The spread of the distribution of <em>p</em> decreases as <em>n</em> increases.</li>
		<li>The distribution is symmetric when π 
			= 0.5, but becomes more skew as π 
			approaches 0 or 1.</li>
	</ul>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_binomials.gif" width="466" height="515"></p>




<h2 class="pageName">7.3.4 &nbsp; Binomial probability examples</h2>

<p class="heading">Assumptions underlying the binomial distribution</p>
	<ul>
		<li>Each observation has the same probability, <span class="black">π</span>, 
			of being a 'success'.</li>
		<li>Each of the <span class="em black">n</span>  observations is independently obtained.</li>
		<li>We record the number (or proportion) of successes in the <span class="em black">n</span>  observations.</li>
	</ul>
	<p class="heading">Evaluating binomial probabilities</p>
	<p>They may be obtained using ... </p>
	<ul>
		<li>a computer (preferred),</li>
		<li>a mathematical formula, or</li>
		<li>tables of binomial probabilites.</li>
	</ul>
	<p class="heading">A range of counts</p>
	<p>Finding the probability that the number of successes is within an interval involves adding the binomial probabilities for all integer values in the interval.</p>
	<p>Think carefully about the wording of the interval &mdash; does it include the values at the end? Adding or subtracting <sup>1</sup>/<sub>2</sub> to the endpoints of the interval makes it clearer. (This is also particularly useful when using the normal approximations that are described in the following pages.)</p>
	<div class="centred"><table border="0" class="centred" cellpadding="3" cellspacing="0">
<tr>
<th align="center" scope="col">In words...</th>
<th align="center" scope="col">&nbsp;&nbsp;&nbsp;&nbsp;In terms of X&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th align="center" scope="col">&nbsp;&nbsp;&nbsp;&nbsp;Using <sup>1</sup>/<sub>2</sub>&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">More than 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">X &gt; 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">X&nbsp;&gt;&nbsp;5.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">Greater than or equal to 5</td>
<td align="center" bgcolor="#FFFFFF">X ≥ 5</td>
<td align="center" bgcolor="#FFFFFF">X &gt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">No more than 5</td>
<td align="center" bgcolor="#FFFFFF">X ≤ 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 5.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">At least 5</td>
<td align="center" bgcolor="#FFFFFF">X ≥ 5</td>
<td align="center" bgcolor="#FFFFFF">X &gt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">Fewer than 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">5 or fewer</td>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">X ≤ 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">X &lt; 5.5</td>
</tr>
</table></div>
<p>The following example illustrates the use of <sup>1</sup>/<sub>2</sub> in this way.</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_binomExample.gif" width="550" height="272"></p>





<h2 class="pageName">7.3.5 &nbsp; Normal approximation to binomial</h2>

<p class="heading">Mean and standard deviation of <em>x</em> and <em>p</em></p>
	<p>The mean and standard deviation are given below for the proportion of successes <span class="em black">p</span> , and number of successes,<span class="em black"> x</span> <span class="black">&nbsp;=&nbsp;<em>np</em></span></p>
	<p class=eqn><img class="gif" src="../../../en/randomPropn/images/normalApprox.gif" width="389" height="126"> </p>
	<p>The fact that both <span class="em black">x</span>  and <span class="em black">p</span>  are approximately normally distributed in large samples is justified below.</p>
	<p class="heading">Proportions and means</p>
	<p>If we assign a code of '1' to the successes and '0' to the failures in the 
		random sample, then the resulting values are called an <strong>indicator variable</strong>. Its mean is identical to the proportion of successes. </p>
	<p class=eqn><img class="gif" src="../../../en/randomPropn/images/propnAsMeanEqn.gif" width="397" height="100"> </p>
	<p>Since the proportion of successes in a sample is a kind of mean, its distribution is close to a normal distribution if the sample size is large enough.<br>
	</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_normalApprox.gif" width="502" height="375"></p>




<h2 class="pageName">7.3.6 &nbsp; Normal approximation examples</h2>

<p class="heading notPrinted">Use of the normal approximation to the binomial distribution</p>
	<p>To avoid adding large numbers of binomial probabilities, the normal approximation can be used to find the probability that a binomial variable is within a certain range when the sample size, <span class="em black">n</span> , is large.</p>
	<p>A common rule-of-thumb for when this kind of normal approximation can be used is:</p>
	
	<div class="centred"><div class="boxed percent50">
		<p><em>n</em>π &gt; 5 &nbsp; &nbsp;and &nbsp; &nbsp; <em>n</em>(1-π) &gt; 5 </p>
	</div></div>
	
	<p>An example is given below:</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_normalApproxEx.gif" width="550" height="460"></p>
	<p>Note the translation of the range of values into one involving <sup>1</sup>/<sub>2</sub>. It is called a <strong>continuity correction</strong> in this context.</p>





</body>
</html>
