<!DOCTYPE HTML>
<html>
<head>
	<title>Common patterns in tests</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>
	<script language="javascript">
		var currentBlockName = "ex1";
		function changeDataset() {
			var menu = document.getElementById("dataset");
			var option = menu.options[menu.selectedIndex];
			var newBlockName = option.value;
			
			
			var oldBlock = document.getElementById(currentBlockName);
			oldBlock.style.display = "none";
			var newBlock = document.getElementById(newBlockName);
			newBlock.style.display = "block";
			currentBlockName = newBlockName;
		}
	</script>

	<meta name="index" content="hypothesis test, null hypothesis, alternative hypothesis, p-value">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">A general framework</p>
<p>The examples in earlier pages of this section involved different types of data 
and different analyses. Indeed, you may find it difficult to spot their common 
theme!</p>
<p>All analyses were examples of <strong>hypothesis testing</strong>. We now describe 
the general framework of hypothesis testing within which all of these examples 
fit. This general framework is the basis for important applications in later sections 
of CAST.</p>

<div class="centred"><div class="boxed">
<p>The concepts in this page are extremely important &mdash; make sure that 
you understand them well before moving on.</p>
</div></div>


<p class="heading">Data, model and question</p>
<dl>
	<dt>Data (and model)</dt>
	<dd>Each example dealt with a data set that was assumed to arise from some random
	mechanism. We may be able to specify some aspects of this random mechanism (model),
	but it also has unknown characteristics</dd>
	<dt>Null hypothesis</dt>
	<dd>All models had unknown characteristics, and we want to know whether the model 
	has particular properties &mdash; the <strong>null hypothesis</strong>.</dd>
	<dt>Alternative hypothesis</dt>
	<dd>If the null hypothesis is not true, we say that the <strong>alternative hypothesis</strong> holds. (You can understand most of hypothesis testing without paying much attention 
	to the alternative hypothesis however!)</dd>
</dl>

<div class="centred"><div class="boxed">
<p>Either the null hypothesis or the alternative hypothesis must be true.</p>
</div></div>

<p class="heading">Approach</p>
<p>We assess whether the null hypothesis is true by asking&nbsp;...</p>

<div class="boxed" style="background-color:#FFFF33; border-color:#990000">
<p><span class="darkred">Are the data consistent with the null hypothesis?</span></p>
</div>

<p>It is <strong>extremely</strong> important that you understand that hypothesis 
	testing addresses this question &mdash; make sure that you remember it well!!</p>
<p class="heading">Answering the question</p>
<dl>
	<dt>Test statistic</dt>
	<dd>This is some function of the data  that throws light on whether the null or 
	alternative hypothesis holds.</dd>
	<dt>P-value</dt>
	<dd>Testing whether the data are consistent with the null hypothesis is based on  the probability of obtaining a test statistic value as  'extreme'
		as the one recorded <strong>if the null hypothesis holds</strong>. This is called the p-value for the test.</dd>
	<dt>Interpreting the p-value</dt>
	<dd>Although it may be regarded as an over-simplification, the table below can 
	be used as a guide to interpreting p-values.</dd>
</dl>

<div class="centred"><table cellpadding="5" cellspacing="0" class="centred">
	<tr>
		<th align="left">p-value</th>
		<th align="left">Interpretation</th>
		</tr>
	<tr bgcolor="white">
		<td style="border-top:1px solid #999999;"><strong>over 0.1</strong></td>
	<td style="border-top:1px solid #999999;">no evidence that the null hypothesis does not hold</td>
		</tr>
	<tr bgcolor="white">
		<td style="border-top:1px solid #999999;"><strong>between 0.05 and 0.1</strong></td>
	<td style="border-top:1px solid #999999;">very weak evidence that the null hypothesis does not hold</td>
		</tr>
	<tr bgcolor="white">
		<td style="border-top:1px solid #999999;"><strong>between 0.01 and 0.05</strong></td>
	<td style="border-top:1px solid #999999;">moderately strong evidence that the null hypothesis does not hold</td>
		</tr>
	<tr bgcolor="white">
		<td style="border-top:1px solid #999999; border-bottom:1px solid #999999;"><strong>under 0.01</strong></td>
	<td style="border-top:1px solid #999999; border-bottom:1px solid #999999;">strong evidence that the null hypothesis does not hold</td>
		</tr>
	</table></div>
	

<div class="diagram">

<p>Use the pop-up menu below to check how the earlier examples in this section fit
into the hypothesis testing framework.</p>

<div class="divChoice">
<form><select id="dataset" onChange="changeDataset()" style="font-weight:bold; font-size:13px; padding:2px">
<option value="ex1" selected>Soccer league in one season</option>
<option value="ex2">Weapon detection at LAX</option>
<option value="ex3">Net weight of corn flake packets</option>
</select></form>

<div id="ex1" style="display:block">
<dl>
<dt>Data (and model)</dt>
<dd>Some random mechanism underlies the actual results in the matches during a 
season. The probabilities of winning may vary from team to team and there may 
be a home-team advantage, so there are a lot of unknowns about this model! Our 
data are a single set of results &mdash; the league table at the end of the season.</dd>
<dt>Null hypothesis</dt>
<dd>The null hypothesis is that all teams are equally matched &mdash; i.e. that they 
all have the same probability of winning each match.</dd>
<dt>Alternative hypothesis</dt>
<dd>The alternative hypothesis is that all teams do <strong>not</strong> have the
same probabilities of winning.</dd>
<dt>Test statistic</dt>
<dd>The standard deviation of final points is used. It will be low if the teams
have the same abilities (null hypothesis) and higher otherwise (alternative hypothesis).</dd>
<dt>P-value</dt>
<dd>We simulated the soccer league, assuming that all teams had the same probability 
of winning. The p-value was the probability of getting a standard deviation of 
final points as high as 16.7 (the actual data).</dd>
<dt>Interpreting the p-value</dt>
<dd>The p-value was 0.000 (or close). Since there is virtually no chance of getting a standard
deviation of points as high as that in the actual league from equally matched teams, we conclude
that the teams are <strong>not</strong> equally matched &mdash; the null hypothesis is false.</dd>
</dl>
</div>


<div id="ex2" style="display:none">
<dl>
<dt>Data (and model)</dt>
<dd>Each weapon has some probability of being detected &mdash; our model. We also assume
that detection of different weapons is independent, a reasonable assumption if different
FAA agents are used over a reasonable period of time, but not if the same agent repeatedly
tries to carry a weapon on board. A sample of 100 weapons was used and our data is
the number that were detected.</dd>
<dt>Null hypothesis</dt>
<dd>The null hypothesis is that each weapon has probability 0.80 of being detected
&mdash; the national rate.</dd>
<dt>Alternative hypothesis</dt>
<dd>The alternative hypothesis is that the LAX detection rate is lower than 0.80.</dd>
<dt>Test statistic</dt>
<dd>The number of weapons detected is the test statistic. It will be near 80 if the
underlying probability of success is 0.80 (null hypothesis) and lower than 80 if
it is less (alternative hypothesis).</dd>
<dt>P-value</dt>
<dd>We simulated carrying 100 weapons onto planes, assuming that each had probability
0.80 of being detected. The p-value was the probability of <sup>72</sup>/<sub>100</sub> or
fewer being detected (the actual data).</dd>
<dt>Interpreting the p-value</dt>
<dd>The p-value was around 0.04. This means that getting as few as 72 weapons detected
would be unlikely if the LAX detection rate was 0.80, giving moderately strong evidence
that the LAX detection rate was lower than 0.80 &mdash; i.e. moderately strong evidence
that the null hypothesis is not true.</dd>
</dl>
</div>


<div id="ex3" style="display:none">
<dl>
<dt>Data (and model)</dt>
<dd>We are told that the net weight of corn flake packets is normally distributed
with a standard deviation of σ&nbsp;=&nbsp;10&nbsp;gm and unknown mean, µ. The data
are a random sample from this distribution.</dd>
<dt>Null hypothesis</dt>
<dd>The null hypothesis is that the weights of packets have a distribution with mean
µ&nbsp;=&nbsp;520&nbsp;gm.</dd>
<dt>Alternative hypothesis</dt>
<dd>The alternative hypothesis is that µ&nbsp;≠&nbsp;520&nbsp;gm.</dd>
<dt>Test statistic</dt>
<dd>The mean weight of our sample of 10 packets is the test statistic. It will be
close to 520&nbsp;gm if the filling machine is working correctly (the null hypothesis)
and will be far from this if the mean filling weight has drifted from 520&nbsp;gm
(the alternative hypothesis).</dd>
<dt>P-value</dt>
<dd>We simulated samples of <em>n</em> = 10 values from a normal (µ = 520, σ&nbsp;=&nbsp;10)
distribution. The p-value was the probability of getting a sample mean as far from
520 as the value in our actual data (529).</dd>
<dt>Interpreting the p-value</dt>
<dd>A p-value of around 0.01 means that a sample mean weight as far from 520 gm as
the one we recorded would be very unlikely if the null hypothesis was true. There
is strong evidence that the mean weight is <strong>no longer</strong> 520 gm.</dd>
</dl>
</div>
</div>
</div>



<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
