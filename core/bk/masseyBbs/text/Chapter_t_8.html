<html>
<head>
<title>8. Comparisons</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 8 &nbsp; Comparisons</h1>
<h2>8.1 &nbsp; Models for two groups</h2>
<h3>8.1.1 &nbsp; Interest in underlying population</h3>
<p>As with single-group data, the populations underlying two-group data sets are usually of more interest than the specific sample data.</p>
<h3>8.1.2 &nbsp; Model for two groups</h3>
<p>Two-group data sets are often modelled as separate random samples from two normal populations.</p>
<h3>8.1.3 &nbsp; Parameters of the normal model</h3>
<p>The normal model has four parameters â€” the means and standard deviations in the two groups.</p>
<h3>8.1.4 &nbsp; Parameter estimates</h3>
<p>The parameters of the normal model can be estimated by the sample means and standard deviations in the two groups.</p>
<h3>8.1.5 &nbsp; Difference between means</h3>
<p>The difference between the population means is of particular interest. The difference between the sample means provides an estimate. It varies from sample to sample and has a distribution.</p>
<h3>8.1.6 &nbsp; Distribution of a difference</h3>
<p>The difference between two independent normal variables is also normally distributed. Its variance is the sum of the variances of the original variables and its standard deviation is the squares root of this.</p>
<h2>8.2 &nbsp; Are the means equal?</h2>
<h3>8.2.1 &nbsp; Distn of difference between means</h3>
<p>The difference between the means of two samples from normal populations has a normal distribution whose mean and s.d. can be found from the population means and s.d.s. This is the approximate distribution even when the populations are non-normal.</p>
<h3>8.2.2 &nbsp; SE of difference between means</h3>
<p>When the difference between the sample means is used to estimate the difference between the underlying population means, there is likely to be an error. The error distribution is approximately normal with mean 0. A formula for its standard deviation is given.</p>
<h3>8.2.3 &nbsp; Are the means equal?</h3>
<p>A hypothesis test is developed for testing whether two group means are the same.</p>
<h3>8.2.4 &nbsp; One-tailed tests for differences</h3>
<p>If the alternative hypothesis is for one particular mean to be greater, then the p-value for the test is found from only one tail of the t distribution.</p>
<h3>8.2.5 &nbsp; Exercise:  Test for two means being equal</h3>
<p>This page provides an exercise that gives practice in evaluating p-values for hypothesis tests comparing two means and interpreting them.</p>
<h2>8.3 &nbsp; Paired data</h2>
<h3>8.3.1 &nbsp; Paired data</h3>
<p>Paired data are a type of bivariate data in which two similar measurements are made from each individual. We are usually interested in testing whether the means of both measurements are the same.</p>
<h3>8.3.2 &nbsp; Analysis of differences</h3>
<p>For paired data, differences between the two measurements hold all information about whether the means of both variables are the same.</p>
<h3>8.3.3 &nbsp; Paired t-test</h3>
<p>Testing for a difference between the means of the measurements is done with an ordinary t-test for whether the mean difference is zero.</p>
<h3>8.3.4 &nbsp; Pairing and experimental design</h3>
<p>To estimate or test the difference between two means, it is sometimes possible to collect data from two independent samples or from paired units. If the paired units are similar, a pair data gives more accurate results.</p>
<h3>8.3.5 &nbsp; Exercise:  Paired or two-sample test?</h3>
<p>This exercise presents 3 different scenarios and asks whether the two means in each scenario should be compared with a 2-sample or a paired t-test.</p>
<h3>8.3.6 &nbsp; Exercise:  Conduct a paired t-test</h3>
<p>In this exercise, you are presented with a set of paired data and asked to perform a test about whether the two means are equal.</p>
<h2>8.4 &nbsp; Comparing two proportions</h2>
<h3>8.4.1 &nbsp; Modelling two proportions</h3>
<p>Two-group categorical data can be modelled as samples from two categorical populations with different probabilities of 'success'.</p>
<h3>8.4.2 &nbsp; Distribution of difference in proportions</h3>
<p>If the two population proportions are equal, the difference between the sample proportions has a distribution with mean zero. It is approximately normal and its standard deviation can be estimated.</p>
<h3>8.4.3 &nbsp; Testing for difference in probabilities</h3>
<p>A hypothesis test is developed to assess whether two population probabilities are the same.</p>
<h3>8.4.4 &nbsp; Exercise:  Are probabilities in two groups equal?</h3>
<p>This exercise asks for the hypotheses, p-value and conclusion when testing whether two group proportions are equal, both with one- and two-tailed alternatives.</p>
<h2>8.5 &nbsp; Contingency table tests</h2>
<h3>8.5.1 &nbsp; Independence from samples</h3>
<p>Independence is a population property. To assess independence from a sample contingency table, the observed cell counts are compared to those estimated from a model with independence.</p>
<h3>8.5.2 &nbsp; Testing for independence</h3>
<p>The 'chi-squared' test statistic is used for testing whether the rows and columns are independent. It is defined as the sum over all contingency table cells of the squared difference between the observed and estimated cell count divided by the estimated count.</p>
<h3>8.5.3 &nbsp; Chi-squared distribution</h3>
<p>The 'chi-squared' statistic has a standard distribution (a chi-squared distribution) when there is independence. Its shape depends only on the number of rows and columns of the contingency table.</p>
<h3>8.5.4 &nbsp; P-value for chi-squared test</h3>
<p>The chi-squared statistic can be used to find a p-value for testing independence. The p-value has similar interpretation and properties to p-values for all other hypothesis tests.</p>
<h3>8.5.5 &nbsp; Examples</h3>
<p>The chi-squared test is applied to a few real data sets. When the variables are found to be associated, the nature of the relationship is described from a comparison of observed and estimated cell counts.</p>
<h3>8.5.6 &nbsp; Comparing groups</h3>
<p>The chi-squared test assesses independence of two categorical variables. It is also used to test whether a single categorical variable has the same distribution in several groups.</p>
<h3>8.5.7 &nbsp; Exercise:  Expected cell counts</h3>
<p>This exercise shows a contingency table and asks for the expected cell count in one of the table cells, assuming the row and column variables are independent.</p>
<h3>8.5.8 &nbsp; Exercise:  Chi-squared test</h3>
<p>In this exercise, the test statistic and p-value are provided for a chi-squared test applied to a contingency table. You are asked to interprete the result of the test.</p>
</body>
</html>
