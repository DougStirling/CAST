<!DOCTYPE HTML>
<html>
<head>
  <title>5. Probability Distributions</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="../../../structure/summaryStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/maths/mathStyles.css" type="text/css">
  <link rel="stylesheet" href="../../../structure/printStyles.css" type="text/css">
  <script src="../../../structure/videoControls/jquery.js"></script>
  <script src="../../../structure/maths/theorems.js"></script>
  <script src="../../../structure/maths/mathJax/MathJax.js?config=TeX-AMS-MML_SVG,statMacros.js"></script>
  <script src="../../../structure/printFixes.js"></script>
</head>

<body id="body" onLoad="showPrintDialog(true)">
<div id='overlay'>
	<div id='dialogWindow'>
		<div class='printDialog'>
			<script type='text/javascript'>
				document.write("<div class='heading'>" + top.document.title + "</div>");
				if (top.url != null) {
					document.write("<p class='text'>A version of this chapter has already been generated in PDF format and we recommend that it is used for printing. The button below will download and display it.</p>");
					document.write("<p><button onClick='top.showPdf()'>Show PDF version of chapter</button></p>");
					document.write("<p class='text'>However downloading could be slow depending on your internet connection. If this is a problem, click the button below to print the chapter without downloading (but perhaps not formatted as well as the PDF version).</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>If you are <strong>not</strong> using the PDF version, the best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
				else {
					document.write("<p class='text'>Click the button below to print this chapter.</p>");
					document.write("<p><button onClick='top.doPrint()'>Show print dialog</button></p>");
					document.write("<p class='text'>The best print results are obtained if the text is reduced in size and printed on  sheets of paper that are smaller than A4. This can be done using your browser's Page Setup command to scale by 71% and then printing on A5 paper.</p>");
				}
			</script>
			
			<p class='text'>If you don't want to print now,</p>
			<p><button onClick='top.showPrintDialog(false)'>Browse formatted chapter</button></p>
		</div>
	</div>
</div>
<h1 class="chapterName">Chapter 5 &nbsp; Probability Distributions</h1>
<h1 class="sectionName">5.1 &nbsp; Discrete distributions</h1>
<h2 class="pageName">5.1.1 &nbsp; Introduction and examples</h2>

<p class="heading">Discrete distributions</p>
<p>A discrete distribution describes the randomness of a situation in which a discrete
numerical measurement is made. This discrete measurement is usually a whole number
(count) and is called a <strong>discrete random variable</strong>.</p>
<p>Each possible value is associated with a probability and, since it is impossible
to simultaneously record two different values (i.e. the values are mutually exclusive),
the probabilities must sum to 1.</p>
<p class="heading">Car sales in 500 days</p>
<div class="centred"><table border="0" class="centred" cellpadding="3" cellspacing="0">
<tr>
<td><strong>Number of cars sold, X&nbsp;&nbsp;</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999; border-left:1px solid #999999;"><strong>0</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>1</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>2</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>3</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>4</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>5</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999; border-right:1px solid #999999;"><strong>6</strong></td>
</tr>
<tr>
<td><strong>Number of days</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999; border-left:1px solid #999999;">25</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">125</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">150</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">100</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">50</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">25</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999; border-right:1px solid #999999;">25</td>
</tr>
</table></div>
<p>Based on these records, we can obtain empirical probabilities &mdash; the relative
frequencies for the possible counts:</p>
<div class="centred"><table border="0" class="centred" cellpadding="3" cellspacing="0">
<tr>
<td><strong>x</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999; border-left:1px solid #999999;"><strong>0</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>1</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>2</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>3</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>4</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>5</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999; border-right:1px solid #999999;"><strong>6</strong></td>
</tr>
<tr>
<td><strong>P(X&nbsp;=&nbsp;x)</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999; border-left:1px solid #999999;">0.05</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.25</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.30</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.20</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.10</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.05</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999; border-right:1px solid #999999;">0.05</td>
</tr>
</table></div>
<p>What is the probability that fewer than 3 cars are sold in a day?</p>
<p class="eqn">P(X&nbsp;&lt;&nbsp;3) &nbsp; = &nbsp; P(X&nbsp;=&nbsp;0) &nbsp;+&nbsp; P(X&nbsp;=&nbsp;1) &nbsp;+&nbsp; P(X&nbsp;=&nbsp;2) &nbsp; = &nbsp; 0.05
+ 0.25 + 0.30 &nbsp; = &nbsp; 0.60</p>


<h2 class="pageName">5.1.2 &nbsp; Bar charts and probabilities</h2>

<p class="heading">Describing   categorical and discrete populations</p>
	<p>Categorical and discrete samples can be described graphically with bar charts of the proportions for the distinct values. Since probabilities are defined to be population proportions, the underlying population can also be described by a bar chart.</p>
	<p class="eqn"><img class="gif" src="../../../en/probDensity/images/barChart.gif" width="206" height="194"></p>
	<p class="heading">Bar charts and the law of large numbers</p>
	<p>The law of large numbers states that sample proportions approach  the underlying probabilities as the sample size increases. This means that a sample bar chart will be close in shape to the unknown population bar chart if the sample size is big enough.</p>




<h2 class="pageName">5.1.3 &nbsp; Expected value</h2>

<p class="heading">Expected value and mean</p>
<p>The mean of a numerical data set describes a 'typical' value. The <strong>expected
value</strong> of a distribution has a similar interpretation and is also called
the distribution's <strong>mean</strong>.</p>
<p>The expected value of a variable X is defined as a type of 'weighted average'
of its possible values, with each value 'weighted' by the probability of it being
obtained. The following formula gives a formal definition.</p>
<p class="eqn"><img src="../images/discreteMeanEqn.gif" width="300" height="57"></p>
<p>If the distribution is based on empirical probabilities from a discrete data set,
the expected value of X is the same as the mean of this data set.</p>
<p class="heading">Car sales in 500 days</p>
<div class="centred"><table border="0" class="centred" cellpadding="3" cellspacing="0">
<tr>
<td><strong>Number of cars sold, X</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999; border-left:1px solid #999999;"><strong>0</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>1</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>2</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>3</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>4</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;"><strong>5</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999; border-right:1px solid #999999;"><strong>6</strong></td>
</tr>
<tr>
<td><strong>P(X&nbsp;=&nbsp;x)</strong></td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999; border-left:1px solid #999999;">0.05</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.25</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.30</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.20</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.10</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">0.05</td>
<td width="40" align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999; border-right:1px solid #999999;">0.05</td>
</tr>
</table></div>
<p>The expected number of cars sold in a day is:</p>
<p>E[X] &nbsp; = &nbsp; 0 × P(0) &nbsp; + &nbsp; 1 × P(1) &nbsp; + &nbsp;2 × P(2) &nbsp; + &nbsp; ... &nbsp; + &nbsp; 6
× P(6)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp; = &nbsp; 0 × 0.05 + 1 × 0.25 + 2 × 0.3 + 3 × 0.2 + 4 × 0.1 + 5 × 0.05 + 6
× 0.05<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp; = &nbsp; 2.4 cars</p>
<p>Since these are empirical probabilities, this is the mean number of cars sold
in the 500 days.</p>


<h2 class="pageName">5.1.4 &nbsp; Standard deviation</h2>

<p class="heading">Variance and standard deviation</p>
<p>The centre of a discrete distribution <strong>and
its spread</strong> are important. The variance of a discrete random variable is
defined as:</p>
<p class="eqn"><img src="../images/discreteVarEqn.gif" width="150" height="52"></p>
<p>This is a difficult calculation that you will not be required to make, so you
do not need to learn the formula.</p>


<h1 class="sectionName breakBefore">5.2 &nbsp; Binomial distributions</h1>
<h2 class="pageName">5.2.1 &nbsp; Properties of counts and proportions</h2>

<p class="heading">Properties of a sample proportion</p>
	<p>A sample proportion  from a random sample
	of size <i>n</i> has a distribution that ... </p>
	<ul>
		<li>is centred on the underlying population probability,
			π, and</li>
		<li>has a spread that decreases as the sample size <i>n</i> increases.</li>
	</ul>
	<p class="heading">Count and proportion of successes</p>
	<p>Although the sample proportion in a category, <span class="em black">p</span> , 
		is a good summary statistic, the raw count of sample values in the category, <span class="em black">x</span> <span class="black">&nbsp;=&nbsp;<em>np</em></span>, 
		contains equivalent information and is often easier to use. They have distributions with the same shape (other than the scaling constant <i><span class="black">n</span></i>).</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_propnDist.gif" width="550" height="286"></p>




<h2 class="pageName">5.2.2 &nbsp; Binomial distribution</h2>

<p class="heading">General notation</p>
	<p>In a categorical population, we choose one category of interest and call it <em><strong>success</strong></em>; all other categories are collectively called <em><strong>failures</strong></em>. The population proportion of successes is denoted by <span class="black">π</span>.</p>
	<p>When a random sample of <i><span class="black">n</span></i> values is selected, 
		we denote the number of successes by <span class="em black">x</span>  and the proportion of successes by <span class="em black">p</span> <span class="black">&nbsp;=&nbsp;<em><span style="vertical-align:20%">x</span></em>/<em><span style="vertical-align:-20%">n</span></em></span>. </p>
	<p class="heading">Distribution of a sample proportion</p>
	<p>The number of successes, <span class="em black">x</span> , 
		has a 'standard' discrete distribution called a <strong>binomial distribution</strong> which has two parameters, <span class="em black">n</span>  and <span class="black">π</span>.</p>
	<p>In practical applications, <span class="em black">n</span>  is a known constant, but <span class="black">π</span> may be unknown. The sample proportion, <span class="em black">p</span> , 
		has a distribution with the same shape, but is scaled by <span class="em black">n</span> .</p>
	<ul>
		<li>The distribution of <em>p</em> is centred on π.</li>
		<li>The spread of the distribution of <em>p</em> decreases as <em>n</em> increases.</li>
		<li>The distribution is symmetric when π 
			= 0.5, but becomes more skew as π 
			approaches 0 or 1.</li>
	</ul>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_binomials.gif" width="466" height="515"></p>




<h2 class="pageName">5.2.3 &nbsp; Binomial probability examples</h2>

<p class="heading">Evaluating binomial probabilities</p>
	<p>They may be obtained using ... </p>
	<ul>
		<li>a computer (preferred),</li>
		<li>a mathematical formula, or</li>
		<li>tables of binomial probabilites.</li>
	</ul>
	<p class="heading">A range of counts</p>
	<p>Finding the probability that the number of successes is within an interval involves adding the binomial probabilities for all integer values in the interval.</p>
	<p>Think carefully about the wording of the interval &mdash; does it include the values at the end? Adding or subtracting <sup>1</sup>/<sub>2</sub> to the endpoints of the interval makes it clearer. (This is also particularly useful when using the normal approximations that are described in the following pages.)</p>
	<div class="centred"><table border="0" class="centred" cellpadding="3" cellspacing="0">
<tr>
<th align="center" scope="col">In words...</th>
<th align="center" scope="col">&nbsp;&nbsp;&nbsp;&nbsp;In terms of X&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th align="center" scope="col">&nbsp;&nbsp;&nbsp;&nbsp;Using <sup>1</sup>/<sub>2</sub>&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">More than 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">X &gt; 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-top:1px solid #999999;">X&nbsp;&gt;&nbsp;5.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">Greater than or equal to 5</td>
<td align="center" bgcolor="#FFFFFF">X ≥ 5</td>
<td align="center" bgcolor="#FFFFFF">X &gt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">No more than 5</td>
<td align="center" bgcolor="#FFFFFF">X ≤ 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 5.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">At least 5</td>
<td align="center" bgcolor="#FFFFFF">X ≥ 5</td>
<td align="center" bgcolor="#FFFFFF">X &gt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF">Fewer than 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 5</td>
<td align="center" bgcolor="#FFFFFF">X &lt; 4.5</td>
</tr>
<tr>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">5 or fewer</td>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">X ≤ 5</td>
<td align="center" bgcolor="#FFFFFF" style="border-bottom:1px solid #999999;">X &lt; 5.5</td>
</tr>
</table></div>
<p>The following example illustrates the use of <sup>1</sup>/<sub>2</sub> in this way.</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_binomExample_c.gif" width="550" height="272"></p>





<h2 class="pageName">5.2.4 &nbsp; Mean and standard deviation</h2>

<p class="heading notPrinted">Formulae</p>
<p>For binomial distributions, we can avoid tabulating the probabilities for the
individual counts and finding the mean and standard deviation from these. Instead,
we can use the following compact formulae for a binomial distribution's
mean and standard deviation:</p>
<p class="eqn">E[X] &nbsp; = &nbsp; µ &nbsp; = &nbsp; <em>n</em>π</p>
<p class="eqn">sd(X) &nbsp; = &nbsp; σ &nbsp; = &nbsp; √<span style="text-decoration: overline"><em>n</em>π(1&nbsp;-&nbsp;π)</span> </p>



<h2 class="pageName">5.2.5 &nbsp; Binomial assumptions</h2>

<p class="heading notPrinted"><span class="heading">Assumptions underlying the binomial
distribution</span></p>
<p>The binomial distribution is applicable to a wide range of applications  provided...</p>
<ul>
<li>Each observation has the same probability, π, of being a 'success'.</li>
<li>Each of the <em>n</em> observations is independently obtained.</li>
<li>The variable of interest, <em>X</em>, is the number (or proportion) of
successes in the <em>n</em> observations.</li>
</ul>
<p>&nbsp; </p>


<h1 class="sectionName breakBefore">5.3 &nbsp; Continuous distributions</h1>
<h2 class="pageName">5.3.1 &nbsp; Introduction and examples</h2>

<p class="heading notPrinted"><span class="heading">Introduction</span></p>
<p>For categorical and discrete numerical variables, it is reasonable to talk about
the probabilities of individual values, such as the probability of a success or of <em>X</em> = 0
breakdowns. However for continuous numerical variables, it no longer makes sense
to talk about the probabilities for individual values.</p>
<p>For example, the probability that an apple will weight <strong>exactly</strong> 60 gm
(and not 59.999 gm or 60.001 gm or ...) is zero. Instead we need to talk about the
probabilities that continuous variables are <strong>within ranges</strong>, such
as P(60 &lt; weight &lt; 70).</p>
<p>For a continuous probability distribution, probabilities are found as the area
under a curve called a “probability density function”.</p>
<p>&nbsp; </p>


<h2 class="pageName">5.3.2 &nbsp; Probability density functions</h2>

<p class="heading notPrinted">Histograms and probability density functions</p>
	<p>The situation is a little more complicated for continuous numerical populations and samples. A standard histogram could be used to describe the population in the same way that it might be used for a sample:</p>
	<p class="eqn"><img class="gif" src="../../../en/probDensity/images/histogram.gif" width="192" height="154"></p>
	<p>However with an infinite population, we can narrow the histogram classes beyond what would be reasonable for a finite sample. Indeed, class widths can be reduced indefinitely, resulting in a smooth histogram called a <strong>probability density function</strong>. This is often abbreviated to a <strong>pdf</strong>.</p>
	<p class="eqn"><img class="gif" src="../../../en/probDensity/images/pdf.gif" width="192" height="154"></p>
	<p>Probability density functions are still essentially histograms and share all properties of histograms.</p>




<h2 class="pageName">5.3.3 &nbsp; Probability and area under pdf</h2>

<p class=heading>Probabilities from a histogram</p>
	<p>In the histogram of any finite sample or population, the area above any class <a href="javascript:showNamedPage('density5')">is 
		the proportion of values in the class</a>.</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_histoArea.gif" width="455" height="254"></p>
	<p class="heading">Probabilities from a probability density function</p>
	<p>Since a probability density function (pdf)  is a type of histogram, it satisfies the same property.</p>
	<div class="centred"><div class="boxed">
		<p>The probability that a sampled value is within two values, P(<em>a</em>&nbsp;&lt;&nbsp;<em>X</em>&nbsp;&lt;&nbsp;<em>b</em>), equals the area under the pdf.</p>
	</div></div>
	<p>This is the key to interpreting pdfs.</p>
	<p class="eqn"><img src="../../../en/probDensity/images/s_pdfArea.gif" width="402" height="212"></p>




<h1 class="sectionName breakBefore">5.4 &nbsp; Normal distributions</h1>
<h2 class="pageName">5.4.1 &nbsp; Importance of normal distributions</h2>

<p class="heading">Shape of a probability density function</p>
	<p>A probability density function is usually a fairly smooth curve, though a
single sample histogram provides limited information about its likely shape.</p>
<p class=eqn><img src="../../../en/probDensity/images/unknownPopn.gif" alt="sample &mdash;> popn?" width="362" height="236" class="summaryPict"> </p>
<p class="heading">Normal distributions</p>
<p>One flexible group of continuous probability density functions is the family
of <strong>normal distributions</strong>. Normal distributions:</p>
<ul>
<li>Are symmetric.</li>
<li>Have a parameter called µ that is the mean of the population.</li>
<li> Have a parameter σ that is the population's standard deviation. </li>
</ul>
<p>Changing the parameters µ and σ changes where the distribution is centred
and its spread, but its shape remains otherwise the same.</p>
<p>The parameters are often <strong>estimated</strong> from a sample. Details
will be given later, but the resulting normal pdf will be close in shape to a
histogram of the sample data.</p>
<p class="eqn"><img src="../../../en/probDensity/images/s_bestFit.gif" width="404" height="202"></p>
<p>The sample data rarely gives enough information for us to be <strong>sure</strong> that the underlying population is  normal, but a normal model is often used unless there is <strong>obvious</strong> non-normality in the data.</p>
<p>Even if the sample data are obviously skew, a normal distribution may be a reasonable
model for a nonlinear transformation of the values (e.g. a log transformation).</p>
<p class="heading">Distribution of summary statistics</p>
	<p>A more important reason for the importance of the normal distribution in statistics 
		is that...</p>
	
<div class="centred"><div class="boxed">
<p>Many summary statistics have normal distributions (at least approximately).</p>
</div></div>

	<p>The Central Limit Theorem shows that the mean of a random sample has a distribution that is close to normal when the sample size is moderate or large, <strong>irrespective 
	of the shape of the distribution of the individual values</strong>. The following are also 
	approximately normal when the sample size is moderate or large...</p>
	<ul>
		<li>A sample proportion</li>
		<li>The slope and intercept of a least squares line</li>
		<li>The difference between the means of two samples</li>
	<li>The difference between two proportions</li></ul>




<h2 class="pageName">5.4.2 &nbsp; Shape of normal distributions</h2>

<p class="heading notPrinted">Effect of normal parameters on distribution</p>
	<p>Distributions from the normal family have different locations and spreads, 
		but other aspects of their shape are the same. Indeed, if the scales on the horizontal 
		and vertical axes are suitably chosen, ...</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_normalAxes.gif" width="514" height="295"></p>





<h2 class="pageName">5.4.3 &nbsp; Sketching a normal distribution</h2>

<p class="heading">A common diagram for <span class="red">all</span> normal 
		distributions</p>
	<p>All normal distributions have basically the same shape.</p>
	<ul>
		<li>The distribution almost disappears at 3σ 
			from µ</li>
		<li>The probability (area) further than 2σ 
			from µ 
			is small &mdash; only about <sup>1</sup>/<sub>20</sub> of the total area.</li>
	</ul>
	<p>This should allow you to sketch a normal distribution, given any values of µ and σ.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_sketch.gif" width="505" height="237"></p>




<h2 class="pageName">5.4.4 &nbsp; Some normal probabilities</h2>

<p class="heading notPrinted">Some probabilities for normal distributions</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_empiricalRule.gif" width="499" height="553"></p>
	<p>A more precise version of the middle probability is</p>
	<ul>
		<li>P&nbsp;(within 1.96σ 
			of µ) 
			&nbsp;=&nbsp; 0.95</li>
	</ul>
	<p class="heading">70-95-100 rule of thumb and the normal distribution</p>
	<p>These probabilities are the basis of the <a href="javascript:showNamedPage('centerSpread7')">70-95-100 
		rule of thumb</a> for 
		'bell-shaped' data sets.</p>
	<ul>
		<li>About 70% of values are within <em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
		<li>About 95% of values are within 2<em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
		<li>Almost all values are within 3<em>s</em> of <img src="../../../en/../images/symbol.xBar.png" width="10" height="10" align="baseline"></li>
	</ul>




<h2 class="pageName">5.4.5 &nbsp; Normal probability plots</h2>

<p class="heading">Do the data come from a normal distribution?</p>
	<p>A histogram  may indicate that a sample is unlikely to come from a normal distribution, but a <strong>normal probability plot</strong> can indicate more subtle departures from a normal distribution.</p>
	<ol>
		<li>Sort the data values into order, <em>x</em><sub>(1)</sub>&nbsp;&lt;&nbsp;<em>x</em><sub>(2)</sub>&nbsp;&lt;&nbsp;...&nbsp;&lt;&nbsp;<em>x</em><sub>(<em>n</em>)</sub></li>
		<li>Find ordered values that are spaced out as you would <strong>expect</strong> from a normal distribution, <em>q</em><sub>1</sub>&nbsp;&lt;&nbsp;<em>q</em><sub>2</sub>&nbsp;&lt;&nbsp;...&nbsp;&lt;&nbsp;<em>q</em><sub><em>n</em></sub>. 
			The quantiles of the normal distribution corresponding to probabilities <sup>1</sup>/<sub>(<em>n</em>+1)</sub>, <sup>2</sup>/<sub>(<em>n</em>+1)</sub>, ..., <sup><em>n</em></sup>/<sub>(<em>n</em>+1)</sub> are commonly used.</li>
		<li>Plot <em>x</em><sub>(<em>i</em>)</sub> against <em>q</em><sub><em>i</em></sub></li>
	</ol>
	<p>If the data set is from a normal distribution, the data should be spaced out in a similar way to the normal quantiles, so the crosses in the normal probability 
		plot should lie close to a straight line.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_probPlot.gif" width="359" height="357"></p>
	<p class="heading">How much curvature is needed to suggest non-normality?</p>
	<p>This is a difficult question to answer and we will not address it here.</p>





<h1 class="sectionName breakBefore">5.5 &nbsp; Normal distribution calculations</h1>
<h2 class="pageName">5.5.1 &nbsp; Z-scores</h2>

<p class="heading">Standard deviations from the mean</p>
	<p>Any x-value can be expressed as a number of standard deviations from the mean &mdash; its <strong>z-score</strong>.</p>
	<p class=eqn><img src="../../../en/normalDistn/images/s_zScore.gif" width="498" height="145"></p>
	<p>or equivalently, </p>
	<p class=eqn><span class="black"><em>x</em> &nbsp;=&nbsp; &mu; &nbsp;+&nbsp; <em>z</em> &times; &sigma;</span> </p>
	<p class="heading">Probabilities and z-scores</p>
	<p>Any  probability (area) relating to a normally distributed random variable, <em>X</em>, can be expressed in terms of z-scores:</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_zProb.gif" width="502" height="298"></p>
	<p>Note in particular that:</p>
	<ul>
		<li>P(-1 &lt; z &lt; +1) &nbsp;is approx&nbsp;0.68</li>
		<li>P(-2 &lt; <em> z </em> &lt; +2) &nbsp;is approx&nbsp;0.95</li>
		<li>P(-3 &lt; <em>z</em> &lt; +3) &nbsp;is approx&nbsp;0.997</li>
	</ul>




<h2 class="pageName">5.5.2 &nbsp; Finding normal probabilities</h2>

<p class="heading">Distribution of z-scores</p>
	<p>Calculating a z-score from a value, <em>x</em>, is  called <strong>standardising</strong> it.</p>
	<div class="centred">
		<table border="0" cellspacing="0" cellpadding="10" class="centred">
			<tr>
				<th style="margin:0px; padding:0px" valign="middle"><span class="black">standardised value,</span>&nbsp;&nbsp;&nbsp;</th>
				<td style="margin:0px; padding:0px" valign="middle"><img class="gif" src="../../../en/normalDistn/images/standardiseEqn2.gif" width="103" height="31"></td>
			</tr>
		</table>
	</div>
<p>If <em>X</em> has a normal distribution, then <i>Z</i> has a <strong>standard 
		normal distribution</strong> with mean µ&nbsp;=&nbsp;0 
	and standard deviation σ&nbsp;=&nbsp;1. </p>
	<p class="heading">Probabilities for the standard normal distribution</p>
	<p>After translating a probability about <em>X</em> into one about a z-score, it is easier to evaluate it.</p>
	<p class="eqn"><img src="../../../en/normalDistn/images/s_xProb.gif" width="509" height="436"></p>
	<p>Areas under the standard normal curve can be evaluated in Excel and most statistical programs. Statistical tables can also be used (see later).</p>




<h2 class="pageName">5.5.3 &nbsp; Other probabilities</h2>

<p class="heading">Evaluating other probabilities</p>
	<p>Other probabilities about normal distributions can be found using the following properties:</p>
	<ul>
		<li>The total area under a normal p.d.f. is 1</li>
		<li>The probability of a value in any interval is the area under the normal p.d.f. above this interval.</li>
	</ul>
	<p class="heading">Probability of higher value</p>
	<p class=eqn><img src="../../../en/normalDistn/images/normalAreas.gif" width="550" height="115"></p>
	<p class="heading">Probability of value between two others</p>
	<p class=eqn><img src="../../../en/normalDistn/images/normalAreas2.gif" width="506" height="241"></p>
	<p>In both cases, the conversion can be done either before or after translating the 
		required probability from x-values to z-scores.</p>




<h2 class="pageName">5.5.4 &nbsp; Normal tables (opt) (Optional (not examined))</h2>

<p class="heading notPrinted">Standard normal probabilities without a computer</p>
	<p>Probabilities about z-scores can be found <strong>without a computer</strong>. Most 
		introductory statistics textbooks contain printed tables with left-tail probabilities 
	for the standard normal distribution. </p>
	<p class=eqn><img src="../../../en/normalDistn/images/table.gif" width="482" height="176" alt="pdf = table"> </p>
	<p>These tables can be used after the required probability has been translated 
		into a problem relating to the standard normal distribution.</p>




<h2 class="pageName">5.5.5 &nbsp; Finding normal quantiles</h2>

<p class="heading">Finding an x-value from a probability</p>
	<dl>
		<dt>Quartiles</dt>
		<dd>The <strong>quartiles</strong> of a  distribution are the three values such that there is probability <sup>1</sup>/<sub>4</sub>, <sup>2</sup>/<sub>4</sub> and <sup>3</sup>/<sub>4</sub> of being lower.</dd>
		<dt>Percentiles</dt>
		<dd>The <em>r</em>'th percentile of the distribution is the value with probability <sup><em>r</em></sup>/<sub>100</sub> of being lower.</dd>
		<dt>Quantiles</dt>
		<dd>These are generalised by the term <strong>quantile</strong>. The value with probability <em>p</em> of being lower is called the quantile of the distribution corresponding to probability <em>p</em>.</dd>
	</dl>
	<p class="heading">Finding quantiles</p>
	<p>To find the x-value for which there is probability <em>p</em> of a normal distribution being lower,</p>
	<ul>
		<li>Find the z-score for which there is probability <em>p</em> of being less.</li>
		<li>Translate the z-score to an x-value</li>
	</ul>
	<p>The first step of this process can be done with Excel (or other statistical software) or statistical tables can be used. For example, the 
		diagram below shows how to find the z-score such that there is probability 
		0.9 of being less.</p>
	<p class=eqn><img src="../../../en/normalDistn/images/invTable.gif" width="482" height="176" class="summaryPict"> </p>
	<p>Translating from a z-score to the corresponding x-value is done with the 
		formula,</p>
	<p class=eqn><span class="black"><em>x</em> &nbsp;=&nbsp; &mu; &nbsp;+&nbsp; <em>z</em> &sigma;</span> </p>




<h1 class="sectionName breakBefore">5.6 &nbsp; Normal approximation to binomial</h1>
<h2 class="pageName">5.6.1 &nbsp; Normal approximation to binomial</h2>

<p class="heading">Mean and standard deviation of <em>x</em> and <em>p</em></p>
	<p>The mean and standard deviation are given below for the proportion of successes <span class="em black">p</span> , and number of successes,<span class="em black"> x</span> <span class="black">&nbsp;=&nbsp;<em>np</em></span></p>
	<p class=eqn><img class="gif" src="../../../en/randomPropn/images/normalApprox.gif" width="389" height="126"> </p>
	<p>The fact that both <span class="em black">x</span>  and <span class="em black">p</span>  are approximately normally distributed in large samples is justified below.</p>
	<p class="heading">Proportions and means</p>
	<p>If we assign a code of '1' to the successes and '0' to the failures in the 
		random sample, then the resulting values are called an <strong>indicator variable</strong>. Its mean is identical to the proportion of successes. </p>
	<p class=eqn><img class="gif" src="../../../en/randomPropn/images/propnAsMeanEqn.gif" width="397" height="100"> </p>
	<p>Since the proportion of successes in a sample is a kind of mean, its distribution is close to a normal distribution if the sample size is large enough.<br>
	</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_normalApprox.gif" width="502" height="375"></p>




<h2 class="pageName">5.6.2 &nbsp; Normal approximation examples</h2>

<p class="heading notPrinted">Use of the normal approximation to the binomial distribution</p>
	<p>To avoid adding large numbers of binomial probabilities, the normal approximation can be used to find the probability that a binomial variable is within a certain range when the sample size, <span class="em black">n</span> , is large.</p>
	<p>A common rule-of-thumb for when this kind of normal approximation can be used is:</p>
	
	<div class="centred"><div class="boxed percent50">
		<p><em>n</em>π &gt; 5 &nbsp; &nbsp;and &nbsp; &nbsp; <em>n</em>(1-π) &gt; 5 </p>
	</div></div>
	
	<p>An example is given below:</p>
	<p class="eqn"><img src="../../../en/randomPropn/images/s_normalApproxEx_c.gif" width="550" height="460"></p>
	<p>Note the translation of the range of values into one involving <sup>1</sup>/<sub>2</sub>. It is called a <strong>continuity correction</strong> in this context.</p>





</body>
</html>
