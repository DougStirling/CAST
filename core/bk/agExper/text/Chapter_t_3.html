<html>
<head>
<title>3. Multiple factors</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 3 &nbsp; Multiple factors</h1>
<h2>3.1 &nbsp; Designs for two factors</h2>
<h3>3.1.1 &nbsp; Factorial design for two factors</h3>
<p>In an experiment for two factors, treatments are combinations of levels for the factors. A factorial experiment uses the same number of replicates for all possible treatments and randomly allocates them to the experimental units.</p>
<h3>3.1.2 &nbsp; Examples of factorial experiments</h3>
<p>This page shows examples of factorial experiments for two factors.</p>
<h3>3.1.3 &nbsp; Interaction between factors</h3>
<p>Sometimes the effect of changing one factor depends on the level of the other factor. A factorial experiment is needed to assess this interaction between factors.</p>
<h3>3.1.4 &nbsp; Efficiency</h3>
<p>In an experiment for one factor, a second factor can be varied without reducing the accuracy of the estimate for the first factor. It is far more efficient to assess two factors in a single factorial experiment than in separate experiments for the two factors.</p>
<h2>3.2 &nbsp; Model and parameters</h2>
<h3>3.2.1 &nbsp; Normal model for two factors</h3>
<p>The response is modelled using a normal distribution whose mean depends on the factor levels and whose standard deviation is the same for all treatments.</p>
<h3>3.2.2 &nbsp; Additive model for treatment means</h3>
<p>The mean response can be modelled as the sum of two terms, each depending on one of the two factors.</p>
<h3>3.2.3 &nbsp; Parameterisations for model with one factor</h3>
<p>The response means for the factor levels can be expressed using the mean for a base factor level and differences for the other factor levels.</p>
<h3>3.2.4 &nbsp; Parameters for two factor model</h3>
<p>The response mean can be modelled as the sum of three terms, the mean at base levels of both factors and two terms reflecting the effect of changing the levels of the two factors.</p>
<h2>3.3 &nbsp; Analysis of variance</h2>
<h3>3.3.1 &nbsp; Do the factors affect the response?</h3>
<p>Confidence intervals for the parameter estimates help to understand the data but a formal test is needed to test whether each factor affects the response.</p>
<h3>3.3.2 &nbsp; Sequence of models</h3>
<p>When terms are added to a model for the response, the residual sum of squares usually decreases.</p>
<h3>3.3.3 &nbsp; Explained sums of squares</h3>
<p>The reductions in the residual sum of squares are called explained sums of squares. The explained sums of squares also summarise how the fitted values change when terms are added to the model.</p>
<h3>3.3.4 &nbsp; Sum of squares table</h3>
<p>If each treament is used with the same number of experimental units (so the factors are orthogonal), all explained sums of squares can be shown in a single table.</p>
<h3>3.3.5 &nbsp; Analyisis of variance tests</h3>
<p>The explained sums of squares form the basis of an analysis of variance table that can be used to test the significance of the two factors in the model.</p>
<h3>3.3.6 &nbsp; Formulae</h3>
<p>Simple formulae for the explained sums of squares in an orthogonal design help to explain their interpretation.</p>
<h2>3.4 &nbsp; Interaction between factors</h2>
<h3>3.4.1 &nbsp; Model without interaction</h3>
<p>If two factors do not interact in their effect on the response, the effects of each can be separately described.</p>
<h3>3.4.2 &nbsp; Interaction between factors</h3>
<p>A model in which two factors interact in their effect on the response has a separately adjustable mean for each combination of factor levels. The model can be written using 'main effect' parameters for the two factors and an interaction term.</p>
<h3>3.4.3 &nbsp; Interaction sum of squares</h3>
<p>Adding an interaction term reduces the residual sum of squares. The reduction is the sum of squares explained by the interaction term.</p>
<h3>3.4.4 &nbsp; Test for interaction</h3>
<p>Comparing the mean interaction sum of squares against the mean residual sum of squares gives a test for whether there is interaction.</p>
<h3>3.4.5 &nbsp; Reporting results</h3>
<p>If it is concluded that there is no interaction, the results can be summarised in separate plots of the mean response against X and Z. If there is interaction, the model means for all treatment combinations must be shown in profile plots. </p>
<h3>3.4.6 &nbsp; Experiments with a single replicate</h3>
<p>If there is only a single replicate for each treatment in a factorial experiment for two categorical factors, the effects of the factors can be tested if it is assumed that there is no interaction, but the existence of interaction cannot be tested.</p>
<h3>3.4.7 &nbsp; Tranformations and interaction</h3>
<p>The existence and amount of interaction is affected by nonlinear transformations of the response. Sometimes analysing logarithms of the response values can remove interaction, making the results easier to interpret.</p>
<h2>3.5 &nbsp; Experiments for many factors</h2>
<h3>3.5.1 &nbsp; Factorial design for three factors</h3>
<p>A factorial design has the same number of replicates for all possible treatments (combinations of factor levels). The treatments should be randomly applied to experimental units.</p>
<h3>3.5.2 &nbsp; Model without interaction</h3>
<p>A simple model for the response is the sum of terms for the separate factors and a normally distributed error that represents unexplained variation.</p>
<h3>3.5.3 &nbsp; Interactions</h3>
<p>In many experiments, the effect of altering one factor depends on the values of the others. Interactions can exist between the effects of pairs of factors. A three-factor interaction involves all factors.</p>
<h3>3.5.4 &nbsp; Sums of squares and degrees of freedom</h3>
<p>Adding main effects and interaction terms to the model reduces the residual sum of squares. The reductions are explained sums of squares.</p>
<h3>3.5.5 &nbsp; Analysis of variance</h3>
<p>The explained and residual sums of squares can be arranged in an analysis of variance table and can be used to test the significance of the terms.</p>
<h3>3.5.6 &nbsp; Summarising the model</h3>
<p>The main effects and interactions can be displayed in 2-dimensional plots of the mean response against each explanatory variable.</p>
<h3>3.5.7 &nbsp; Experiments with a single replicate</h3>
<p>If there is only one replicate, the full model with all interactions fits the data perfectly with no residual degrees of freedom. The main effects and interactions cannot be tested in this model. High-order interactions must be negligible (and actually assumed to be zero) in order to perform tests.</p>
<h3>3.5.8 &nbsp; Four or more factors</h3>
<p>Many experimental units are required for complete factorial experiments with four or more factors so it is rare to have more than one replicate. Analysis is however the same as for experiments with three factors.</p>
</html>
