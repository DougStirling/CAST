<html>
<head>
<title>11. En comparant des groupes</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 11 &nbsp; En comparant des groupes</h1>
<h2>11.1 &nbsp; Modèles pour deux groupes</h2>
<h3>11.1.1 &nbsp; Interest in underlying population</h3>
<p>Comme pour les données mono-groupe, les populations sous-jacentes des ensembles de données à deux groupes sont généralement plus d'intérêt que les exemples de données spécifiques.</p>
<h3>11.1.2 &nbsp; Model for two groups</h3>
<p>Des ensembles de données de deux groupes sont souvent modélisés comme des échantillons aléatoires distincts de deux populations normales.</p>
<h3>11.1.3 &nbsp; Parameters of the normal model</h3>
<p> Le modèle normal a quatre paramètres - les moyens et les écarts-types dans les deux groupes.</p>
<h3>11.1.4 &nbsp; Parameter estimates</h3>
<p>Les paramètres du modèle normal peuvent être estimés par les moyens d'échantillonnage et les écarts-types des deux groupes.</p>
<h3>11.1.5 &nbsp; Difference between means</h3>
<p>La différence entre le moyen de la population est d'un intérêt particulier. La différence entre les moyennes de l'échantillon fournit une estimation. Il varie d'un échantillon à et a une distribution.</p>
<h2>11.2 &nbsp; Distribution des sommes et des différences</h2>
<h3>11.2.1 &nbsp; Means and sums of random samples</h3>
<p>La moyenne d'un échantillon aléatoire est approximativement normale avec sd égale à σ divisé par √n. La somme d'un échantillon aléatoire est également à peu près normale, mais son sd est √nσ.</p>
<h3>11.2.2 &nbsp; Sum and differences</h3>
<p>La somme et la différence de deux variables normales indépendantes sont également distribuées normalement. Si elles ont le même écart-type, σ, la somme et de la différence les deux ont 1.414σ de déviation standard. (Leur écart est 2σ².)</p>
<h3>11.2.3 &nbsp; Sums and differences (cont)</h3>
<p>Cette page généralise les résultats à la somme et la différence des variables dont les déviations standard peut être différent.</p>
<h3>11.2.4 &nbsp; Probabilities for sums and differences</h3>
<p>Si deux variables sont indépendants et ont des distributions normales, les probabilités relatives à leur somme et la différence peuvent être trouvés en utilisant les formules pour la moyenne et l'écart type des sommes et des différences.</p>
<h2>11.3 &nbsp; En comparant les moyens en deux groupes</h2>
<h3>11.3.1 &nbsp; Distn of difference between means</h3>
<p>La différence entre les moyennes de deux échantillons provenant d'une population normale a une distribution normale dont la moyenne et l'écart-type peut être trouvé à partir des moyens et s.d.s. population Ceci est la répartition approximative, même lorsque les populations sont non-normale.</p>
<h3>11.3.2 &nbsp; Distribution of estimation error</h3>
<p>Lorsque la différence entre les moyennes des échantillons est utilisée pour estimer la différence entre les moyennes de la population sous-jacente, il est susceptible d'être une erreur. La distribution des erreurs est approximativement normale de moyenne 0. Une formule de son écart-type est donné.</p>
<h3>11.3.3 &nbsp; CI for difference between means</h3>
<p>Un intervalle de confiance de 95% est donnée pour la différence entre les deux moyennes de population. Ses propriétés sont démontrées.</p>
<h3>11.3.4 &nbsp; Testing a hypothesis</h3>
<p>Un test d'hypothèse est développé pour tester si deux moyens de groupe sont les mêmes.</p>
<h3>11.3.5 &nbsp; One-tailed tests for differences</h3>
<p>Si l'hypothèse alternative est pour une moyenne particulière à être plus grande, alors la p-valeur pour le test se trouve de seule queue de la distribution de t.</p>
<h2>11.4 &nbsp; Comparaison de deux proportions</h2>
<h3>11.4.1 &nbsp; Modelling two proportions</h3>
<p>Deux groupes de données catégoriques peuvent être modélisés comme des échantillons provenant de deux populations catégoriques avec des probabilités différentes de «succès».</p>
<h3>11.4.2 &nbsp; Distribution of difference in proportions</h3>
<p>La différence entre deux proportions de l'échantillon a une distribution qui est à peu près normale et dont les paramètres peuvent être estimés à partir des résultats antérieurs sur la moyenne et l'écart type des différences.</p>
<h3>11.4.3 &nbsp; CI for difference in proportions</h3>
<p>L'écart-type de la différence entre deux proportions de l'échantillon peut être estimé. De là, un intervalle de confiance de 95% a été développé pour la différence entre les deux probabilités.</p>
<h3>11.4.4 &nbsp; Testing for difference in probabilities</h3>
<p>Un test d'hypothèse est conçu pour déterminer si deux probabilités de population sont identiques.</p>
<h2>11.5 &nbsp; Test t apparié</h2>
<h3>11.5.1 &nbsp; Paired data examples</h3>
<p>Paires de données sont un type de données à deux variables dans lesquelles deux mesures similaires sont fabriqués à partir de chaque individu. Nous sommes généralement intéressés à tester si les moyens des deux mesures sont les mêmes.</p>
<h3>11.5.2 &nbsp; Analysis of differences</h3>
<p>Pour les données appariées, les différences entre les deux mesures détiennent toutes les informations sur les moyens de savoir si les deux variables sont les mêmes.</p>
<h3>11.5.3 &nbsp; Paired t-test</h3>
<p>Un test d'hypothèse pour une différence entre les moyennes des mesures se fait avec un t-test ordinaire pour que la différence moyenne est nulle.</p>
<h3>11.5.4 &nbsp; Pairing and experimental design</h3>
<p>Pour estimer ou tester la différence entre deux moyens, il est parfois possible de collecter des données à partir de deux échantillons indépendants ou des unités appariées. Si les unités appariées sont similaires, une paire de données donne des résultats plus précis.</p>
<h2>11.6 &nbsp; En comparant plusieurs moyensmeans</h2>
<h3>11.6.1 &nbsp; Model with common standard deviation</h3>
<p>Pour comparer les moyens de plusieurs groupes, un modèle de distributions normales dans tous les groupes est utilisé, mais tous les écarts-types de groupe doit être supposé être le même.</p>
<h3>11.6.2 &nbsp; Estimate of common standard deviation</h3>
<p>Les écarts-types de l'échantillon dans les groupes distincts peuvent être combinés pour donner une estimation globale de l'écart-type commun, σ.</p>
<h3>11.6.3 &nbsp; Inference about two groups ((optional))</h3>
<p>Intervalles de confiance et des tests d'hypothèses antérieures pour l'égalité des deux moyens de groupe peuvent être améliorées lorsque les écarts-types de groupe sont connus pour être les mêmes. Cependant ce raffinement est pas recommandé pour une utilisation générale.</p>
<h3>11.6.4 &nbsp; Assessing differences between groups</h3>
<p>La variabilité entre les moyennes de groupe et de la variabilité au sein des groupes doit être utilisé pour évaluer si les groupes diffèrent.</p>
<h3>11.6.5 &nbsp; Sums of squares</h3>
<p>La variabilité au sein des groupes et entre les groupes sont décrits par des sommes de carrés.</p>
<h3>11.6.6 &nbsp; Coefficient of determination</h3>
<p>Le coefficient de détermination (R²) est le rapport entre les groupes et les sommes totales des carrés. Il est de la proportion de variation qui peut être expliqué par des différences entre les groupes.</p>
<h3>11.6.7 &nbsp; Test for differences between groups</h3>
<p>Le F-ratio est une statistique de test qui est basé sur l'inter- et intra-groupes des sommes de carrés. Les tests p-valeur associées si tous les groupes ont la même moyenne.</p>
<h3>11.6.8 &nbsp; Examples</h3>
<p>Le test F est appliqué à un petit nombre d'ensembles de données.</p>
<h2>11.7 &nbsp; Blocs randomisés</h2>
<h3>11.7.1 &nbsp; Generalising the idea of paired data</h3>
<p>Dans certains ensembles de données, les valeurs se présentent dans des blocs de 3 ou plus apparentées mesures. Bloc randomisé et les données de mesure sont répétées de ce formulaire.</p>
<h3>11.7.2 &nbsp; Importance of using block information</h3>
<p>Ignorant le blocage de valeurs perd des informations importantes à propos de la différence entre les traitements. En comparant les traitements séparément contre un traitement de référence utilisant les différences appariées peut être possible.</p>
<h3>11.7.3 &nbsp; Data with no baseline treatment</h3>
<p>Si il n'y a pas de traitement de référence à laquelle comparer les autres mesures dans chaque bloc, il est possible de tester simultanément si tous les moyens de traitement sont égaux. Encore une fois, en ignorant les blocs perd des informations importantes.</p>
<h3>11.7.4 &nbsp; Randomised block designs</h3>
<p>Les données de cette forme se pose souvent d'une expérience en blocs aléatoires dans lequel les unités expérimentales se produisent dans les blocs et les traitements connexes sont répartis de façon aléatoire dans chaque bloc.</p>
<h3>11.7.5 &nbsp; Model for randomised blocks ((facultatif))</h3>
<p>Bien que les blocs et les traitements se posent de manière différente, ils sont modélisées de manière similaire. Dispositif d'affichage en 3 dimensions des données représente les deux blocs et les traitements de la même manière.</p>
<h3>11.7.6 &nbsp; Removing block effects</h3>
<p> La variation entre les blocs peut être éliminé par l'addition / soustraction d'une valeur pour chaque bloc à bloc des moyens de faire toute égal. Cela réduit la valeur résiduelle (inexpliquée) somme des carrés.</p>
<h3>11.7.7 &nbsp; Sums of squares</h3>
<p>La somme totale des carrés peut être divisée en sommes de carrés pour les blocs et les traitements, et une somme des carrés des résidus.</p>
<h3>11.7.8 &nbsp; Anova table and examples</h3>
<p>Une table d'analyse de variance montre ces sommes de carrés et de degrés de liberté associés. Le rapport F pour les traitements de la table est la base d'un test de moyens d'égalité de traitement. Plusieurs exemples sont donnés.</p>
</body>
</html>
