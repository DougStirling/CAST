<html>
<head>
<title>12. Régression inférence</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../../structure/tocPrintStyles.css" type="text/css">
<script type='text/javascript'>
	function toggleDescriptions() {
		var showNotHide = document.getElementById('descriptionCheck').checked;
		var descriptions = document.getElementsByTagName('p');
		for (var i=0 ; i<descriptions.length ; i++)
			descriptions[i].style.display = showNotHide ? 'block' : 'none';
	}
</script>
</head>

<body>
<div style='position:absolute; top:3em; right:5; color:#FF0000; border:solid 1px #FF0000; background-color:#FFFFCC; padding:4px; margin:0px; line-height:0.8em'>
<input type='checkbox' id='descriptionCheck' checked onChange='toggleDescriptions()'/>Long page<br>descriptions
</div>
<h1>Chapter 12 &nbsp; Régression inférence</h1>
<h2>12.1 &nbsp; Modèles de régression linéaires</h2>
<h3>12.1.1 &nbsp; Interest in generalising from data</h3>
<p>Certains ensembles de données bivariées décrivent populations complètes. D'autres sont «représentant» d'une population ou d'un processus sous-jacent.</p>
<h3>12.1.2 &nbsp; Distribution of Y for each X</h3>
<p>Les données à deux variables peuvent être modélisés par une distribution de spécifier pour chaque réponse possible X.</p>
<h3>12.1.3 &nbsp; Normal linear model</h3>
<p>La réponse est souvent modélisée avec une distribution normale dont la moyenne est une fonction linéaire de X et dont l'écart type est constante.</p>
<h3>12.1.4 &nbsp; Errors and 95% band on scatterplot</h3>
<p>Un modèle linéaire normale peut être décrite en termes de «erreurs». Dans les échantillons à partir du modèle, environ 95% des erreurs sont dans un rayon de 2 écarts-types de zéro, de sorte que près de 95% des points dans un diagramme de dispersion sont à l'intérieur de cette distance de la ligne de régression.</p>
<h3>12.1.5 &nbsp; Model parameters</h3>
<p>Le modèle linéaire normale dispose de 3 paramètres inconnus. Pour de nombreux ensembles de données, ces paramètres ont des interprétations significatives.</p>
<h2>12.2 &nbsp; Estimation des paramètres</h2>
<h3>12.2.1 &nbsp; Point estimates of slope and intercept</h3>
<p>A droite des moindres carrés fournit des estimations de la pente et l'interception du modèle linéaire. Ces estimations sont des valeurs aléatoires - elles varient d'un échantillon à.</p>
<h3>12.2.2 &nbsp; Estimating the error standard devn</h3>
<p> Le troisième paramètre du modèle linéaire normale est la norme erreur type. Il peut être estimée en utilisant les résidus de la droite des moindres carrés.</p>
<h3>12.2.3 &nbsp; Distn of least squares estimates</h3>
<p>L'estimation des moindres carrés de la pente du modèle a une distribution normale qui est centrée sur la valeur réelle.</p>
<h3>12.2.4 &nbsp; Standard error of least squares slope</h3>
<p>La distribution de la pente moins carrés peut être estimée à partir d'un ensemble de données unique.</p>
<h3>12.2.5 &nbsp; 95% confidence interval for slope</h3>
<p>Un intervalle de confiance pour la pente de la modèle peut être obtenu à partir de son estimation des moindres carrés et son erreur standard.</p>
<h3>12.2.6 &nbsp; Properties of confidence interval</h3>
<p>Les intervalles de confiance pour la pente de la modèle ont les mêmes propriétés que les intervalles de confiance pour les moyens ou proportion des populations.</p>
<h3>12.2.7 &nbsp; Influences on accuracy ((avancé))</h3>
<p> L'erreur standard de la carrés pente moins dépend de la norme réponse écart autour de la ligne de modèle, la taille de l'échantillon et l'écart type des données X. Collecte avec une grande propagation des valeurs x donne des estimations plus précises, mais il ya des inconvénients.</p>
<h2>12.3 &nbsp; Paramètres tests de régression</h2>
<h3>12.3.1 &nbsp; Importance of zero slope</h3>
<p>Si la pente du modèle est égal à zéro, la distribution de la réponse ne dépend pas de la variable explicative. Ce cas particulier est particulièrement significatif dans de nombreuses études.</p>
<h3>12.3.2 &nbsp; Testing whether slope is zero</h3>
<p>La valeur p pour tester si la pente d'un modèle linéaire est nulle est la probabilité que son estimation des moindres carrés est aussi loin de zéro la valeur enregistrée.</p>
<h3>12.3.3 &nbsp; Strength of evidence and relationship</h3>
<p>Il est important de distinguer la force d'une relation (résumées par le coefficient de corrélation) et la force de la preuve de l'existence d'une relation (résumée par la valeur p).</p>
<h3>12.3.4 &nbsp; Properties of p-values ((advanced))</h3>
<p>Comme avec d'autres tests, toutes les valeurs p entre 0 et 1 sont également probables si l'hypothèse nulle est titulaire (modèle pente est nulle), mais les valeurs p proches de 0 sont plus probables si l'hypothèse alternative est titulaire (modèle pente est non nulle).</p>
<h2>12.4 &nbsp; Prédire la réponse</h2>
<h3>12.4.1 &nbsp; Estimated response distn at X</h3>
<p>De estimations des 3 paramètres du modèle linéaire, nous pouvons obtenir une distribution de réponse estimé à tout x-valeur.</p>
<h3>12.4.2 &nbsp; Variability of estimate at X</h3>
<p> La réponse prédite à tout X varie d'un échantillon à. La prédiction est plus variable à valeurs x loin de la moyenne des données de «formation».</p>
<h3>12.4.3 &nbsp; Estimating the mean vs prediction</h3>
<p>Une distinction est faite entre l'estimation de la réponse moyenne à X et à prédire la réponse d'un nouvel individu à X. Les erreurs sont plus grandes (en moyenne) au moment de prédire la réponse d'un nouvel individu.</p>
<h3>12.4.4 &nbsp; Confidence and prediction intervals</h3>
<p> Un intervalle de confiance de 95% est utilisée pour estimer la réponse moyenne à X. Un intervalle de prédiction de 95% est similaire, mais donne une plage de valeurs possibles pour une nouvelle valeur de réponse. L'intervalle de prédiction est plus large que l'intervalle de confiance.</p>
<h2>12.5 &nbsp; Hypothèses de modèle linéaire</h2>
<h3>12.5.1 &nbsp; Assumptions in a normal linear model</h3>
<p>Le modèle linéaire normale implique des hypothèses de linéarité, de variance constante, la distribution d'erreur normale et l'indépendance des différentes observations. Résidus peuvent être examinées pour déterminer si ces hypothèses sont appropriées pour un ensemble de données particulier.</p>
<h3>12.5.2 &nbsp; Curvature &mdash; transforming X</h3>
<p> Si la relation entre X et Y est non linéaire, une transformation de X peut linéariser la relation.</p>
<h3>12.5.3 &nbsp; Curvature and non-constant variance &mdash; transforming Y</h3>
<p>Transformer la réponse peut retirer courbure dans la relation, mais affecte également si l'écart-type d'erreur est constante. Heureusement, la même transformation de Y supprime souvent la courbure et l'écart type non constante.</p>
<h3>12.5.4 &nbsp; Transformations and prediction ((advanced))</h3>
<p>Si un modèle linéaire normal décrit la relation entre une transformation de la réponse et une transformation de la variable explicative, les prédictions peuvent être faites en ajustant le modèle linéaire pour les données transformées, puis à effectuer la transformation inverse sur la prédiction.</p>
<h3>12.5.5 &nbsp; Outliers and leverage</h3>
<p>Une valeur aberrante est une valeur de réponse qui est inhabituellement grand ou petit. Un résiduelle extrême suggère une valeur aberrante et résidus standardisés peut être utilisé pour l'évaluer. Toutefois, si la valeur aberrante correspond à une valeur x extrême (un point de levier de haut), il peut ne pas apparaître comme une grande résiduelle.</p>
<h3>12.5.6 &nbsp; Non-normal errors ((facultatif))</h3>
<p>Les erreurs dans un modèle linéaire normale sont supposés avoir des distributions normales. Violation de cette hypothèse est moins important que la non-linéarité, variance ou aberrantes non constante, mais un tracé de probabilité des résidus peut être utilisée pour évaluer la normalité.</p>
<h3>12.5.7 &nbsp; Correlated errors ((facultatif))</h3>
<p>Les erreurs dans un modèle linéaire normale sont supposés indépendants. En données où les observations sont enregistrées séquentiellement, erreurs successives sont parfois observé de corrélation. Erreurs corrélées peuvent survenir quelle que soit la variable x, mais sont le plus souvent vu lorsque la variable x est temps lui-même.</p>
</body>
</html>
