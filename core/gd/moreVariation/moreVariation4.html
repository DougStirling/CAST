<!DOCTYPE HTML>
<html>
<head>
	<title>Variance and degrees of freedom</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="stylesheet" href="../../pageStyles.css" type="text/css">
	<script src="../../releaseInfo.js"></script>
	<script src="../../structure/pageSetup.js"></script>

	<meta name="index" content="variance, degrees of freedom">
</head>


<body>
<script type="text/javascript">writePageStart();</script>

<p class="heading">Variance</p>
<p>The <strong>square</strong> of the standard deviation is called the <strong>variance</strong> 
of the data.</p>
<p class=eqn style="color:#000000"><strong>variance &nbsp; = &nbsp; (standard deviation)<sup>2</sup> &nbsp; = &nbsp; </strong><img class="gif" src="../../en/moreVariation/images/variance.gif" width="74" height="45"> </p>
<p>Since the variance is a kind of average of <strong>squared</strong> differences from the sample mean, the units of the variance are the square of 
		the units of the original values. For example, if the values are weights in kg, the variance is a number of <strong>square kg</strong>. The standard deviation has the same units as the original values (e.g. it is a number of kg in the example above), so the numerical value of the standard deviation is easier to understand. The use of variance as a summary of 
	spread is therefore discouraged.</p>
	<p>However
	  variances play a central role in more advanced statistical methods. Indeed, 
	  an important collection of methods for analysing relationships between variables 
	  is called <strong>analysis of variance</strong>. (Analysis of variance investigates 
	  the <strong>causes</strong> of variability in a measurement &mdash; some variability 
	  may be explained, and perhaps controlled, in terms of other variables whereas 
	  other aspects of variability are unexplained.)</p>
	<p class="heading">Degrees of freedom (optional)</p>
	<p>The divisor (<em>n</em>&nbsp;-&nbsp;1) in the formula for the sample standard 
		deviation is called its <strong>degrees of freedom</strong>. This can be thought 
		of as the number of 'independent pieces of information' that contribute to 
		it.</p>
	<dl>
		<dt>Sample of size <em>n</em>&nbsp;=&nbsp;1</dt>
		<dd>With only a single value, there is no information about the spread of 
			values, so there are 0 degrees of freedom and the sample standard deviation 
			is undefined &mdash; the numerator and denominator of the formula are both zero.</dd>
		<dt>Sample of size <em>n</em>&nbsp;=&nbsp;2</dt>
		<dd>With two values, <em>x</em><sub>1</sub> and <em>x</em><sub>2</sub>, there 
			is only a single piece of information about the spread &mdash; the difference 
			between the values, <em>x</em><sub>1</sub>&nbsp;-&nbsp;<em>x</em><sub>2</sub>, 
			and there is one degree of freedom. With a little algebraic manipulation, 
			the sample standard deviation can be written in terms of this difference 
			as:</dd>
		<dl>
			<p class=eqn><img class="gif" src="../../en/moreVariation/images/sd2.gif" width="104" height="41"> </p>
		</dl>
		<dt>Sample of size <em>n</em></dt>
		<dd>In general, there is one less 'piece of information about the spread' 
			in the sample than the number of data points because the sample mean, <img src="../../images/symbol.xBar.png" width="10" height="10" align="baseline">, 
			is one piece of information that does not give any information about the 
			spread of the data. We therefore say that there are (<em>n</em>&nbsp;-&nbsp;1) 
			degrees of freedom.</dd>
	</dl>
		
	<script type='text/javascript'>writePageEnd();</script>

</body>
</html>
